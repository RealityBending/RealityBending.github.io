<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reality Bending Lab</title>
    <link>https://realitybending.github.io/category/reality-bending-lab/</link>
      <atom:link href="https://realitybending.github.io/category/reality-bending-lab/index.xml" rel="self" type="application/rss+xml" />
    <description>Reality Bending Lab</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sat, 20 Dec 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://realitybending.github.io/media/icon_hu_82f4b62152eab490.png</url>
      <title>Reality Bending Lab</title>
      <link>https://realitybending.github.io/category/reality-bending-lab/</link>
    </image>
    
    <item>
      <title>What is the Best Interoception Questionnaire?</title>
      <link>https://realitybending.github.io/post/2025-12-20-interoception/</link>
      <pubDate>Sat, 20 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-12-20-interoception/</guid>
      <description>&lt;p&gt;Helloüëã! We are &lt;a href=&#34;https://realitybending.github.io/authors/roisin-sharma/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R√≥is√≠n&lt;/a&gt; and &lt;a href=&#34;https://realitybending.github.io/authors/oliver-collins/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Oliver&lt;/a&gt;, two &lt;a href=&#34;https://realitybending.github.io/jobs/assistant/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research Assistants&lt;/a&gt; at the lab, and today we are going to be discussing the tricky topic of self-report interoception questionnaires.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interoception&lt;/strong&gt;, essentially referring to one&amp;rsquo;s sensation of their internal body, is a fundamental phenomenon that we rely on in everyday life, and recent research highlights it as a trans-diagnostic underpinning of a variety of somatic and psychological difficulties.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;While we know interoception is very important, the specifics are still being worked out&lt;/strong&gt;. Debates continue on what exactly interoception is, is not, and what it encompasses in terms of modalities or processes. Is it limited to visceral sensations (i.e., from internal organs)? Does it include proprioception (i.e., body position sense)? Pain? What about tactile sensations (i.e., touch and skin)? Does it include the interaction with higher-order processes like attention and beliefs?&lt;/p&gt;
&lt;p&gt;This chaotic and moving landscape has been accompanied by the development and repurposing of different interoception (and interoception-adjacent) questionnaires, each with their own philosophies and approach. Carefully choosing a good measure of interoception is crucial to avoid adding to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Jingle-jangle_fallacies&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;jingle-jangle fallacy&lt;/strong&gt;&lt;/a&gt; plaguing the field, in which discrepancies and contradictions of results &lt;em&gt;&amp;ldquo;related to interoception&amp;rdquo;&lt;/em&gt; are driven by differences in what aspect of it is actually being measured.&lt;/p&gt;
&lt;p&gt;Moreover, unlike &lt;em&gt;exteroception&lt;/em&gt; (vision, audition, etc.), where researchers can easily manipulate external stimuli to validate a participant&amp;rsquo;s response, interoception presents a unique challenge: the stimuli originate from within the body. Because internal states are difficult to manipulate or observe directly, objective validation is complex. Nonetheless, especially as &amp;ldquo;objective&amp;rdquo; tasks like the Heart Beat Counting Task (HCT; &lt;a href=&#34;https://onlinelibrary-wiley-com.sussex.idm.oclc.org/doi/10.1111/j.1469-8986.1981.tb02486.x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Schandry, 1981&lt;/a&gt;) have their own methodological drawbacks, self-report questionnaires remain a scalable, practical, and widely-used tools for assessing interoception. Let&amp;rsquo;s explore the most popular and established questionnaires.&lt;/p&gt;
&lt;h2 id=&#34;questionnaires-overview&#34;&gt;Questionnaires Overview&lt;/h2&gt;
&lt;h3 id=&#34;-body-perception-questionnaire-bpq&#34;&gt;üò® Body Perception Questionnaire (BPQ)&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;BPQ&lt;/strong&gt; is one of the earliest interoception scales, originally built by &lt;a href=&#34;https://terpconnect.umd.edu/~sporges/body/body.txt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Porges in 1993&lt;/a&gt;. This questionnaire focuses on the autonomic nervous system, involved in stress responses, and thus is mainly concerned with internal sensing when there are problems (e.g., &amp;rsquo;tremor in my lips&amp;rsquo;, &amp;lsquo;general jitteriness&amp;rsquo; being two items for body awareness). This makes the scale beneficial in clinical contexts to investigate maladaptive interoception, particularly in patients who have a dysregulated autonomic nervous system. However, if you are interested in interoception in a wider context, other questionnaires may be more appropriate.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;ans.webp&#34; alt=&#34;The Autonomic Nervous System (ANS)&#34; width=&#34;50%&#34;/&gt;
&lt;figcaption&gt;&lt;i&gt;The Autonomic Nervous System (ANS)&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;-multidimensional-assessment-of-interoceptive-awareness-maia&#34;&gt;üßò‚Äç‚ôÄÔ∏è Multidimensional Assessment of Interoceptive Awareness (MAIA)&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Multidimensional Assessment of Interoceptive Awareness (MAIA)&lt;/strong&gt; (the MAIA-2 being the most recent version) is another widely used questionnaire that accounts for body awareness in positive states - deriving from research on emotional regulation and pain. This questionnaire was created because &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0048230&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mehling et al. (2012)&lt;/a&gt; believed western medicine focused too much on bodily awareness as a maladaptive trait, even though research was increasingly finding health benefits from a sense of embodiment. It was specifically designed to assess mind-body therapies and was finalised based on data from individuals with various therapeutic backgrounds including yoga, tai chi and breath-work. The MAIA reconceptualises bodily awareness not only as an anxiety-related process but also an integral part of mindfulness. This translates to many of the questions focusing on &lt;em&gt;metacognitive beliefs&lt;/em&gt; about one&amp;rsquo;s body and emotions, as well as some targetting more directly other mindfulness-related processes, such as attention regulation and non-reactivity. The MAIA includes subscales encompassing self-regulation abilities which - while important - might be conceptualized as distinct from core interoception.&lt;/p&gt;
&lt;h3 id=&#34;-interoceptive-accuracy-scale-ias&#34;&gt;ü§ß Interoceptive Accuracy Scale (IAS)&lt;/h3&gt;
&lt;p&gt;More recently, the &lt;strong&gt;Interoceptive Accuracy Scale (IAS)&lt;/strong&gt; &lt;a href=&#34;https://doi-org.sussex.idm.oclc.org/10.1177/1747021819879826&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Murphy et al., 2019)&lt;/a&gt; took the opposite route, trying to remove contamination by meta-cognitive processes to focus on interoceptive &lt;em&gt;accuracy&lt;/em&gt; (distinct from interoceptive &lt;em&gt;attention&lt;/em&gt;). It includes 21 questions (&amp;ldquo;I can always accurately perceive when&amp;hellip;&amp;rdquo;) pertaining discrete, clear, and &amp;ldquo;objectifiable&amp;rdquo; interoceptive events, hopefully being meaningful and consistently interpreted across participants (including those who have difficulty perceiving internal sensations).&lt;/p&gt;
&lt;h3 id=&#34;-multimodal-interoception-questionnaire-mint&#34;&gt;üçÉ Multimodal Interoception Questionnaire (Mint)&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Multimodal Interoception Questionnaire (Mint;&lt;/strong&gt; &lt;a href=&#34;https://doi.org/10.31234/osf.io/8qrht_v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Makowski et al., 2025&lt;/strong&gt;&lt;/a&gt;) is the most recent interoception questionnaire, designed with the intention of addressing the caveats and limitations by building on established measures and synthesising the previous research and advances. Fundamentally, the Mint takes a &amp;ldquo;&lt;strong&gt;context-by-modality&lt;/strong&gt;&amp;rdquo; approach to item development, encompassing a wide range of (seven) &lt;strong&gt;modalities&lt;/strong&gt; of interoceptive experience (cardiac, respiratory, gastric, etc.) and also controlling for the &lt;strong&gt;contexts&lt;/strong&gt; in which these may appear (covering negative (&lt;em&gt;anxious&lt;/em&gt;) and positive (&lt;em&gt;sexual&lt;/em&gt;) arousal states). The Mint also incorporates both adaptive and maladaptive aspects of interoception (interoceptive confusion), as well as items targeting different levels of processing.&lt;/p&gt;
&lt;p&gt;Importantly, this questionnaire was developed with the aim of addressing some of the methodological shortcomings of previous interoception questionnaires, such as limiting &lt;em&gt;interpretation Variance&lt;/em&gt;, &lt;em&gt;state Dependency&lt;/em&gt; (the fact that respondents &amp;ldquo;anchor&amp;rdquo; their answers to their current physiological state rather than their general trait), and &lt;em&gt;recency effects&lt;/em&gt; (recent, salient physical experiences disproportionately influencing scores), in particular by providing a clear contextual reference for each item. The validation study displayed shows strong correlations with the above questionnaires (suggesting that it can be used as a comprehensive replacement), while also demonstrating a superior predictive power for a variety of clinical conditions.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;mint.png&#34; alt=&#34;Items of the Multimodal Interoception Questionnaire (Mint)&#34; width=&#34;80%&#34;/&gt;
&lt;figcaption&gt;&lt;i&gt;Items of the Multimodal Interoception Questionnaire (Mint)&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;others&#34;&gt;Others&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;Interoceptive Attention Scale (IATS; Gabriele et al., 2021)&lt;/strong&gt;: Attention to bodily signals. Designed as the orthogonal counterpart of the Interoceptive Accuracy Scale, also using consistent phrasing of all statements (&amp;lsquo;Most of the time my attention is focused on&amp;hellip;&amp;rsquo;).&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Interoceptive Sensations Questionnaire (THISQ; &lt;a href=&#34;https://doi.org/10.1080/08870446.2021.2009479&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vlemincx et al., 2021&lt;/a&gt;)&lt;/strong&gt;: Neutral internal sensations (not emotionally valenced), including cardiorespiratory activation, deactivation, and gastroesophageal sensations.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Interoception Sensory Questionnaire (ISQ; &lt;a href=&#34;https://link.springer.com/article/10.1007/s10803-018-3600-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fiene, 2018&lt;/a&gt;)&lt;/strong&gt;: Designed to assess confusion about interoceptive bodily states unless these states are extreme (Alexisomia).&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Interoceptive Confusion Questionnaire (ICQ; &lt;a href=&#34;https://royalsocietypublishing.org/rsos/article/3/10/150664/36458/Alexithymia-a-general-deficit-of&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brewer, 2016&lt;/a&gt;)&lt;/strong&gt;: Assesses confusion and misinterpretation of bodily signals.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Body Consciousness scale (BCS; Miller et al., 1981)&lt;/strong&gt;: Awareness of the &amp;ldquo;private body&amp;rdquo; (internal sensations) and &amp;ldquo;public body&amp;rdquo;	(observable aspects of body)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;in-summary---which-interoception-questionnaire-should-i-pick&#34;&gt;In summary - which interoception questionnaire should I pick?&lt;/h2&gt;
&lt;p&gt;Interoceptive questionnaires are a product of their time, often molded by specific contextual demands and underlying theoretical frameworks. As our understanding of interoception evolves, so too do the tools we use to measure it. It might seem like the best option is to pick a questionnaire based on the interoception facet you are interested in (e.g., confusion, attention, accuracy, &amp;hellip;), but as the field is still developing, and the theorethical models are in flux, it might be more useful to consider using a broader, more comprehensive, theory-agnostic questionnaire that captures multiple facets and modalities of interoception, such as the &lt;strong&gt;Mint&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;Bergomi, C., Tschacher, W., &amp;amp; Kupper, Z. (2012). The Assessment of Mindfulness with Self-Report Measures: Existing Scales and Open Issues. &lt;em&gt;Mindfulness&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(3), 191‚Äì202. &lt;a href=&#34;https://doi.org/10.1007/s12671-012-0110-9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1007/s12671-012-0110-9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Gabriele, E., Spooner, R., Brewer, R., &amp;amp; Murphy, J. (2021). Dissociations between self-reported interoceptive accuracy and attention: Evidence from the interoceptive attention scale. &lt;em&gt;Biological Psychology&lt;/em&gt;, &lt;em&gt;168&lt;/em&gt;, 108243. &lt;a href=&#34;https://doi.org/10.1016/j.biopsycho.2021.108243&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.biopsycho.2021.108243&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kolacz, J., &amp;amp; Bjorum, E. (2023). Measuring Autonomic Symptoms with the Body Perception Questionnaire. &lt;em&gt;The Traumatic Stress Research Consortium&lt;/em&gt; . &lt;a href=&#34;https://www.traumascience.org/s/TSRCMarch2023Newsletter.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.traumascience.org/s/TSRCMarch2023Newsletter.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kolacz, J., Holmes, L., &amp;amp; Porges, S. W. (2018). Body perception questionnaire (BPQ) manual. Traumatic Stress Research Consortium.&lt;/p&gt;
&lt;p&gt;Makowski, D., Neves, A., Benn, E., Bennett, M., &amp;amp; Poerio, G. (2025). The Mint Scale: A Fresh Validation of the Multimodal Interoception Questionnaire and Comparison to the MAIA, BPQ and IAS. &lt;a href=&#34;https://doi.org/10.31234/osf.io/8qrht_v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.31234/osf.io/8qrht_v1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mehling, Price, Daubenmier, Acree, Bartmess, &amp;amp; Stewart. (2012). The Multidimensional Assessment of Interoceptive Awareness (MAIA). &lt;em&gt;Plos One&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;(11). &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0048230.g001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1371/journal.pone.0048230.g001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mehling, W. E., Acree, M., Stewart, A., Silas, J., &amp;amp; Jones, A. (2018). The Multidimensional Assessment of Interoceptive Awareness, Version 2 (MAIA-2). &lt;em&gt;PLOS ONE&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(12), e0208034. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0208034&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1371/journal.pone.0208034&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Miller, L. C., Murphy, R., &amp;amp; Buss, A. H. (1981). Consciousness of body: Private and public. &lt;em&gt;Journal of Personality and Social Psychology&lt;/em&gt;, &lt;em&gt;41&lt;/em&gt;(2), 397‚Äì406. &lt;a href=&#34;https://doi.org/10.1037/0022-3514.41.2.397&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1037/0022-3514.41.2.397&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Murphy, J., Brewer, R., Plans, D., Khalsa, S. S., Catmur, C., &amp;amp; Bird, G. (2019). Testing the independence of self-reported interoceptive accuracy and attention. &lt;em&gt;Quarterly Journal of Experimental Psychology&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(1), 115‚Äì133. &lt;a href=&#34;https://doi.org/10.1177/1747021819879826&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1177/1747021819879826&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Paola Solano Dur√°n, Morales, J.-P., &amp;amp; Huepe, D. (2024). Interoceptive awareness in a clinical setting: the need to bring interoceptive perspectives into clinical evaluation. &lt;em&gt;Frontiers in Psychology&lt;/em&gt;, &lt;em&gt;15&lt;/em&gt;(1244701). &lt;a href=&#34;https://doi.org/10.3389/fpsyg.2024.1244701&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.3389/fpsyg.2024.1244701&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Porges. (1993). &lt;em&gt;Body Perception Questionnaire&lt;/em&gt;. Umd.edu. &lt;a href=&#34;https://terpconnect.umd.edu/~sporges/body/body.txt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://terpconnect.umd.edu/~sporges/body/body.txt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schandry, R. (1981). Heart Beat Perception and Emotional Experience. &lt;em&gt;Psychophysiology&lt;/em&gt;, &lt;em&gt;18&lt;/em&gt;(4), 483‚Äì488. &lt;a href=&#34;https://doi.org/10.1111/j.1469-8986.1981.tb02486.x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/j.1469-8986.1981.tb02486.x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sherrington C. S. (1906). The integrative action of the nervous system. Yale University Press.&lt;/p&gt;
&lt;p&gt;Vlemincx, E., Walentynowicz, M., Zamariola, G., Van Oudenhove, L., &amp;amp; Luminet, O. (2021). A novel self-report scale of interoception: the three-domain interoceptive sensations questionnaire (THISQ). &lt;em&gt;Psychology &amp;amp; Health&lt;/em&gt;, &lt;em&gt;38&lt;/em&gt;(9), 1‚Äì20. &lt;a href=&#34;https://doi.org/10.1080/08870446.2021.2009479&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1080/08870446.2021.2009479&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From physique to intellect... and back again?</title>
      <link>https://realitybending.github.io/post/2025-11-03-dystopianfutures1/</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-11-03-dystopianfutures1/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;em&gt;Welcome to the &amp;ldquo;Pub Theories on Dystopian Futures&amp;rdquo; series, where we engage in wild speculations about the future of academia and society.&lt;/em&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; AI will commodify and devalue intelligence, leading to natural beauty becoming the next highly prized characteristic in Humans.&lt;/p&gt;
&lt;h2 id=&#34;physical-health-as-primary-desideratum&#34;&gt;Physical health as primary desideratum&lt;/h2&gt;
&lt;p&gt;From a psycho-evolutionary perspective, many human behaviours can be understood as rooted in mating strategies.
At their core, these involve signalling one&amp;rsquo;s genetic fitness to potential partners.
In humans, this often manifests as displays of youthful beauty in women (as a proxy for fertility) and status in men (as a proxy for resource acquisition and protection).
These sexual dimorphisms arise primarily from the biological asymmetry in parental investment between the sexes.&lt;/p&gt;
&lt;p&gt;On top of these individual selective processes, there are also societal or group-level selective pressures, including accidental ones.
For instance, the black plague that killed one in three Europeans in the 14th century exerted selective pressure on immune genes, notably increasing the frequency of protective allele variants (&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/36261521/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Klunk et al., 2022&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Importantly, at a population-level, pre-modern societies preferentially selected for physical characteristics like strength and health over intellectual ones.
For hunter-gatherer men, strength and endurance were the best predictors of family provisioning and protection.
Likewise, for the common farmer of the Feudal era, &lt;strong&gt;it didn&amp;rsquo;t matter whether you were smart or not&lt;/strong&gt;; what mattered was whether you could labour and toil efficiently and survive the harsh conditions.&lt;/p&gt;
&lt;h2 id=&#34;the-rise-of-intelligence&#34;&gt;The rise of intelligence&lt;/h2&gt;
&lt;p&gt;With the Industrial Revolution, and overall advances in medicine, nutrition, and sanitation, life expectancy increased, and the population grew (e.g., the population of Britain increased five times in 150 years).
Societies became more literate, relying on bureaucracies, trade and technologies, and increasingly meritocratic.
This resulted in a shift in selective pressures: intelligence became a prime desirable trait.
Due to these multiple converging factors (notably education, nutrition, and health), average IQ scores increased over the 20th century by about 3 points per decade (the so-called &lt;a href=&#34;https://en.wikipedia.org/wiki/Flynn_effect&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Flynn effect&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Today, IQ is one of the strongest single predictors of positive outcomes, including academic achievement, job performance, socioeconomic mobility, health, emotional stability, happiness, and even longevity (&lt;a href=&#34;https://www.scirp.org/journal/paperinformation?paperid=74943&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lo, 2017&lt;/a&gt;).
As such, being &lt;em&gt;(perceived as)&lt;/em&gt; smart confers advantages in modern societies surpassing those of physical fitness.&lt;/p&gt;
&lt;!-- TODO: mention studies on the relationship between perceived attractiveness and intelligence --&gt;
&lt;p&gt;Interestingly, the recent decades of data seem to provide some evidence for a possible stagnation or even reversal of the Flynn trend&lt;sup&gt;1&lt;/sup&gt;, suggesting we may be approaching a plateau&amp;hellip; or a &lt;strong&gt;regime shift&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-devaluation-of-intelligence&#34;&gt;The devaluation of intelligence&lt;/h2&gt;
&lt;p&gt;Just as the agricultural revolution transformed society by lowering the need for less efficient food production methods, and just as the industrial revolution changed society by lowering the need for manual labour, the AI revolution is changing society by lowering the need for Human intelligence.
If AI commodifies smartness, the competitive edge of human intelligence becomes diluted, relaxing related selective pressures.
Once intelligence is cheaply available, the benefits of being smarter shrink, triggering a decrease in its value as a desirable status-marker trait.&lt;/p&gt;
&lt;p&gt;In the near future, intelligence might no longer the main characteristic prized by society, providing positive outcomes and status.
This raises the question: what comes next? What feature will serve as ground for future Humans to compete on?&lt;/p&gt;
&lt;h2 id=&#34;natural-beauty-and-the-emergence-of-a-kalokagathos-class&#34;&gt;Natural beauty and the emergence of a &lt;em&gt;kalokagathos&lt;/em&gt; class&lt;/h2&gt;
&lt;p&gt;In a world where technology equalises for advantages related to cognitive and physical abilities and health, &lt;strong&gt;the new frontier of human competition may be aesthetic and embodied: beauty&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The ancient Greeks encapsulated this ideal in the term &lt;em&gt;kalokagathos&lt;/em&gt; - the unity of the good, the true, and the beautiful within a single person. For them, beauty was not a shallow and vain superficial quality; it symbolised harmony, virtue, and authenticity.&lt;/p&gt;
&lt;p&gt;As artificial intelligence, virtual realities, and algorithmic filters dominate experience, society may increasingly valorise naturalness - what appears genuine, unmediated, and unfiltered. The value of naturalness, authenticity, and directness&lt;sup&gt;2&lt;/sup&gt; might come as a counter-movement to the rise of artificiality, syntheticity, and virtuality. In this context, the pendulum could swing towards an aesthetic moralism: beauty as truth and goodness. In this world, &lt;strong&gt;natural beauty might become the prime desirable trait&lt;/strong&gt;, with all its paradoxical implications in the form of a post-AI society obsessed with fake naturalness - surgical enhancements and digital manipulations designed to look unaltered, and carefully manufactured authenticity.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;Kalokagathoi&lt;/em&gt;, living embodiment of beauty and virtue, would become the new elite class, dominating not by their power to &lt;em&gt;do&lt;/em&gt;, but through their mere quality to &lt;em&gt;be&lt;/em&gt;, unsullied by technological augmentation.
This value shift towards natural reality might last&amp;hellip; until our technological capabilities allow us to influence the most fundamental aspects of our biology via gene editing, synthetic biology, &amp;hellip; &lt;em&gt;But what comes after that is a story for another pub theory.&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; The reversal of the Flynn effect has been documented in several developed countries, such as Norway, Finland, and the UK, with IQ declines ranging from 0.38 to 4.3 points per decade since the 1990s in some studies. However, this is not universal‚Äîgains continue in other regions‚Äîand causes are debated, including factors like changes in education quality, immigration patterns, environmental toxins, or even the rise of digital distractions like smartphones (&lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/PMC6042097/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bratsberg &amp;amp; Rogeberg, 2018&lt;/a&gt;; &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0160289616300198&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dutton et al., 2016&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; Directness refers to the idea of unmediated experience, e.g., accessibility of the source of an experience. This translates to direct experiences of nature, social interactions without digital mediation, and raw sensory experiences. This concept also applies to products, opposing hand-crafted goods and locally sourced food (for which the &amp;ldquo;source&amp;rdquo; and &amp;ldquo;origin&amp;rdquo; are directly accessible and known) to mass-produced items for which the creation process has been obscured and mediated through complex supply chains.&lt;/p&gt;
&lt;!-- - This mechanism is already at play as a counter-movement to the mass production of goods, with the rise of artisanal, hand-crafted products, and locally sourced products. In Brighton, where I live, many people will be happy to pay three times as much for a regular basic white t-shirt if they *think* it is hand-made sustainably by some local artisan, rather than being a mass-produced item from a sweatshop in Bangladesh. &#34;The overpriced hand-crafted artisan white shirt from Brighton.&#34; --&gt;</description>
    </item>
    
    <item>
      <title>The AI revolution in academia: I see a silver lining for young scientists!</title>
      <link>https://realitybending.github.io/post/2025-09-08-airevolution/</link>
      <pubDate>Mon, 08 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-09-08-airevolution/</guid>
      <description>&lt;p&gt;For many students and early-career researchers, the rise of AI is scary. &lt;strong&gt;The very skills they are spending years learning - writing, coding, summarising - are exactly the things AI is getting frighteningly good at&lt;/strong&gt;. What, then, is the future of research careers in the age of AI?&lt;/p&gt;
&lt;p&gt;While I don&amp;rsquo;t have a full answer to that question, I do think there may be a silver lining for young scientists.
For decades, becoming an established ‚Äúbig shot‚Äù professor was associated with focusing on the &amp;ldquo;big ideas&amp;rdquo;, revelling in intellectual thinking and leaving the scientific grunt work to junior researchers.
Therein lied the prestige: writing opinion pieces, commentaries, critiques and reviews. &lt;strong&gt;The glamour was in thinking, not doing.&lt;/strong&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;In a fascinating twist, the rise of AI may disrupt this landscape. If AI excels at one thing, it is &lt;em&gt;precisely&lt;/em&gt; writing, reviewing and summarising evidence, interpreting findings, and even formulating new hypotheses or planning experiments.
What AI still cannot do, however, is roll up its sleeves and gather real-world data - &lt;strong&gt;the true backbone of empirical science&lt;/strong&gt;&lt;sup&gt;2&lt;/sup&gt;. It can&amp;rsquo;t (yet) run studies, recruit participants, set up experiments, organise data management, or wrestle with messy datasets.&lt;/p&gt;
&lt;p&gt;The centre of gravity in science may thus shift towards &lt;strong&gt;those who can &lt;em&gt;do&lt;/em&gt;&lt;/strong&gt;: Hands-on scientists, who might once have been relegated to the shadows, could see their skills and contributions gain new recognition.
We may see less pressure to write endless papers and grants, and more emphasis on how the science was actually done: how data was collected, preprocessed, managed, and made accessible.
Perhaps the introduction, discussion, and &amp;ldquo;key takeaways&amp;rdquo; sections of papers will become somewhat less important, while methods, results, and limitations gain greater prominence, allowing for more nuance and granularity&lt;sup&gt;3&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Whether this shift will make science better or worse is unclear. And that &amp;ldquo;silver lining&amp;rdquo; might end up as a &amp;ldquo;glorification of the grind&amp;rdquo; and a devaluation of the intellectual aspects of research, devolving the job of &amp;ldquo;Researcher&amp;rdquo; into technician work.
But it might also reshape the academic landscape in a way that proves beneficial for young researchers and those who enjoy the practical aspects of research.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; Sure, thinking &lt;em&gt;is&lt;/em&gt; important, and big shot professors are also &lt;em&gt;doing&lt;/em&gt; a &lt;em&gt;&lt;strong&gt;lot&lt;/strong&gt;&lt;/em&gt;&amp;hellip; &lt;sup&gt;&lt;sub&gt;sometimes.&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; Of note is following the &amp;ldquo;replication crisis&amp;rdquo; in psychology, a lot of voices have called for &amp;ldquo;more theory&amp;rdquo; and more &amp;ldquo;theorically-grounded research&amp;rdquo; (with the goal of cutting some of the nonsense out there). While theories are critical to guide data collection and interpretation, it is still the hard evidence that ultimately is the foundation of scientific knowledge.&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;3&lt;/sup&gt; One of the pervasive issue is that Humans have limited &amp;ldquo;context window&amp;rdquo; (~ working memory). When reading a paper, it is already very hard to keep track of all the results and details in mind and integrate them into a coherent picture. Moreover, with the increasing role of social media, science had to be made more communicable, digestible, punchy, and &amp;ldquo;sexy&amp;rdquo;. This has led to a tendency to oversimplify and overgeneralize findings. AI, with its ability to process and summarize large amounts of information, could perhaps help make more accurate and data-grounded interpretations and summaries. &lt;em&gt;(it might be wishful thinking, but who knows!)&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Attractiveness shapes beliefs about whether faces are real or AI-generated, study finds</title>
      <link>https://realitybending.github.io/post/2025-07-07-newsfakeface/</link>
      <pubDate>Mon, 07 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-07-07-newsfakeface/</guid>
      <description>&lt;p&gt;Our recent paper on facial attractiveness and reality beliefs is in the news:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.psypost.org/attractiveness-shapes-beliefs-about-whether-faces-are-real-or-ai-generated-study-finds/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.psypost.org/attractiveness-shapes-beliefs-about-whether-faces-are-real-or-ai-generated-study-finds/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>How to collect and save data with DataPipe in OSF</title>
      <link>https://realitybending.github.io/post/2025-07-02-datapipeosf/</link>
      <pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-07-02-datapipeosf/</guid>
      <description>&lt;p&gt;Hello there! üëã Let&amp;rsquo;s learn how to set up DataPipe to collect and save data in OSF.&lt;/p&gt;
&lt;p&gt;Lets start with some basics!&lt;/p&gt;
&lt;h2 id=&#34;what-is-datapipe&#34;&gt;What is DataPipe?&lt;/h2&gt;
&lt;p&gt;DataPipe is a tool that allows you to collect and save data in OSF (Open Science Framework). It is designed to help researchers manage their data collection process efficiently, ensuring that data is stored securely and can be easily accessed for analysis.&lt;/p&gt;
&lt;h2 id=&#34;how-to-set-up-datapipe-in-osf&#34;&gt;How to set up DataPipe in OSF&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create an OSF Project&lt;/strong&gt;: Start by creating a new project in &lt;a href=&#34;https://osf.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OSF&lt;/a&gt;. This will be the container for your data and any related files. You can set up an account if you don&amp;rsquo;t have one already, quite easily!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to the OSF homepage and log in or create an account. You can easily sign up through institutional access.&lt;/li&gt;
&lt;li&gt;Click on &amp;ldquo;Create New Project&amp;rdquo; and fill in the necessary details such as project title, description, and visibility settings. Choose &amp;ldquo;Germany - Frankfurt&amp;rdquo; as the server location; this is important for data privacy and compliance with regulations such as GDPR.&lt;em&gt;&lt;strong&gt;DO NOT SET YOUR PROJECT AS PUBLIC&lt;/strong&gt;&lt;/em&gt; as the data being saved will not be anonymized and may contain sensitive information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create OSF Token&lt;/strong&gt;: You will need to create a token to grant DataPipe the necessary permissions to access your OSF project.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to your OSF &amp;ldquo;Settings&amp;rdquo; tab and navigate to the &amp;ldquo;Personal Access Tokens&amp;rdquo; section.&lt;/li&gt;
&lt;li&gt;Click on &amp;ldquo;Create Token&amp;rdquo; and give it a name (e.g., &amp;ldquo;DataPipe Token&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;Set the permissions for the token, ensuring it has access to read and write data in your project.&lt;/li&gt;
&lt;li&gt;Copy the generated token; you will need it later.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Link OSF to DataPipe&lt;/strong&gt;: In &lt;a href=&#34;https://pipe.jspsych.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DataPipe&lt;/a&gt;, you will need to link your OSF project using the token you created.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open DataPipe, click &amp;ldquo;Account&amp;rdquo; in the top-right corner and select &amp;ldquo;Settings&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Click on the &amp;ldquo;Set OSF Token&amp;rdquo; button and paste the token you copied earlier from OSF.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create new experiment on DataPipe&lt;/strong&gt;: Now that your OSF project is linked, you can create a new experiment in DataPipe.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the &amp;ldquo;My Experiments&amp;rdquo; DataPipe tab, click on the &amp;ldquo;Create New Experiment&amp;rdquo; button.&lt;/li&gt;
&lt;li&gt;Give the experiment a name - I recommend using the same name as your OSF project for consistency.&lt;/li&gt;
&lt;li&gt;Add the OSF project ID to the experiment settings. You can find the project ID in the URL of your OSF project (it is the alphanumeric string after osf.io/)&lt;/li&gt;
&lt;li&gt;Create a New OSF Data Component called &amp;ldquo;data&amp;rdquo;. This will create a folder - named &amp;ldquo;data&amp;rdquo; - in your OSF project where all the data collected will be saved.&lt;/li&gt;
&lt;li&gt;Again, choose &amp;ldquo;Germany - Frankfurt&amp;rdquo; as the server location for your DataPipe experiment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configure Data Collection&lt;/strong&gt;: Once the experiment is set up on DataPipe, enable data collection on the &amp;ldquo;Status&amp;rdquo; section. You can optionally enable base64 data collection if you wish to encode any video, audio, or image files as strings. &amp;ldquo;Condition assignment&amp;rdquo; can also be enabled - this makes DataPipe loop through the conditions when it requests the data. When deciding whether these features are suitable, it&amp;rsquo;s best to consider how you will preprocess the data. It&amp;rsquo;s advised that you only enable the minimum needed as a security measure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Save the data from the experiment hosted on GitHub&lt;/strong&gt;: If you are using a GitHub repository to host your experiment, you can save the data collected by writing the following code within the experiment HTML file. Here is what that code might look like&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensure you load the jsPsych DataPipe plugin, along with the rest of your plugins, within the head of the HTML script:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;script&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;https://unpkg.com/@jspsych-contrib/plugin-pipe&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/script&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;After initializing your jsPsych timeline, to generate a random participant ID for your study, you can code the following:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Initialize timeline
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;timeline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nx&#34;&gt;participant_ID&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;jsPsych&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;randomization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;randomID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;This next bit of code should be called at the end of your experiment (albeit before running the timeline) to ensure that all data is saved to the OSF project, using the unique participant ID generated from the step above:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Save data via DataPipe
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;timeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nx&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;jsPsychPipe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nx&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;save&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nx&#34;&gt;experiment_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;xxxxxxxxxx&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// This in generated in the DataPipe interface
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;nx&#34;&gt;filename&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;participant_ID&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;.csv`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nx&#34;&gt;data_string&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;jsPsych&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;On the experiment created in DataPipe, there is an &amp;lsquo;Experiment ID&amp;rsquo; field. This is the ID you need to add to the &lt;code&gt;experiment_id&lt;/code&gt; field in the code above.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;filename&lt;/code&gt; field can be customized to include the participant ID or any other identifier you prefer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If publishing your experiment to GitHub, make sure the link is&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;lsquo;https://[your username].github.io/[your repository name]&amp;rsquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;or &lt;em&gt;&amp;lsquo;https://[your username].github.io/[your repository name]/[name of experiment&amp;rsquo;s html file]&amp;rsquo;&lt;/em&gt; if the html file for your experiment is named anything other than &lt;code&gt;&#39;index.html&#39;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Run Your Experiment&lt;/strong&gt;: With everything set up, you can now run your experiment. DataPipe will automatically collect and save the data to your OSF project as specified.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Give it a try!&lt;/em&gt; If you&amp;rsquo;d like further clarification, the &lt;a href=&#34;https://pipe.jspsych.org/getting-started&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DataPipe website&lt;/a&gt; includes a useful outline.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Sussex Psychological Methods MRes: Tips and Advice</title>
      <link>https://realitybending.github.io/post/2024-03-19-mres/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2024-03-19-mres/</guid>
      <description>&lt;p&gt;Ola! I&amp;rsquo;m &lt;a href=&#34;https://realitybending.github.io/authors/AnafNeves/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ana&lt;/a&gt;. As I&amp;rsquo;m starting to approach the end of the year, it might be a good time to reflect and share my experience of doing a research masters in psychological methods at the University of Sussex, during the 2023/2024 academic year. First, I will talk a little bit about the modules I took; then I will mentioned all the reasons why you should choose to work with the Reality Bending Lab (ReBeL) and lastly, I will share some &lt;strong&gt;gems on how to survive the masters&lt;/strong&gt; üíé. Hopefully this blog will help you decide whether this degree is for you! Shall we start?&lt;/p&gt;
&lt;h2 id=&#34;overview-of-the-modules&#34;&gt;Overview of the Modules&lt;/h2&gt;
&lt;p&gt;Since this is a &lt;strong&gt;research masters&lt;/strong&gt; (MRes) aiming to prepare students for a future career as psychology researchers, the modules will have a significant focus on different research frameworks and practices, statistics and coding. During the Autumn semester you will have three main modules: 1) a (re)introduction to statistical models; 2) an introduction to Qualitative Methods; and 3) an introduction to better quality research practices. This term is super heavy on its content (no jokes) and will feel like a lot to do and learn (see below for tips on how to survive). However, there are plenty of materials to help you through this term, such as the R tutorials from our own in-house celebrity Professor Andy Field.&lt;/p&gt;
&lt;p&gt;The Spring semester is less content heavy and more practical focus. There are again, three main modules: 1) a theoretical and practical module on how to use advanced statistical methods; 2) an introduction to the Bayesian framework; and 3) an introduction to Python programming and how to use it to implement experiments. This has been a delightful term, not because it is &lt;em&gt;easy&lt;/em&gt;, but because the focus is less on &lt;strong&gt;memorising&lt;/strong&gt; and more on &lt;strong&gt;learning how&lt;/strong&gt;. Similarly, there are plenty of amazing materials to help you through this term such as optional zoom meetings to help you understand the materials and continuous communication on discord between lecturers and students.&lt;/p&gt;
&lt;p&gt;Additionally, there will be a research module that runs both in Autumn and Spring, and a dissertation module that starts in January and ends in August (i.e., when the dissertation project is due).&lt;/p&gt;
&lt;h2 id=&#34;the-internship&#34;&gt;The Internship&lt;/h2&gt;
&lt;p&gt;Critically, you will also do an &amp;ldquo;internship&amp;rdquo; as part of this masters (named the &amp;ldquo;research process&amp;rdquo; module ü§∑‚Äç‚ôÄÔ∏è). This is by far &lt;strong&gt;the most exciting part&lt;/strong&gt; of this masters as you will learn first-hand what is like to be a researcher. You can essentially chose any psychology researcher from Sussex to work with, providing you with a great network and experience. Now&amp;hellip; you may be wondering &lt;strong&gt;what lab to choose?&lt;/strong&gt; And oh boy, do I have the answer for you!&lt;/p&gt;
&lt;p&gt;Introducing the &lt;strong&gt;Reality Bending Lab (ReBeL)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Rebel is led by &lt;a href=&#34;https://realitybending.github.io/authors/dominique-makowski/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Dominique Makowski&lt;/a&gt;. He will be your Mr. Miyagi during the Autumn and Spring term (and also your lecturer for the Bayesian Module). His patience, humour, straightforwardness and unmatched theoretical and pragmatic knowledge will be one of the big reasons why you will desire to be a researcher at the end of this masters (PS: no payment has been received in exchange for this testimony). The lab focus a lot on &lt;strong&gt;innovation&lt;/strong&gt; hence you will learn new ways to collect neuroscientific data and use new statistical methods. There will also be a big focus on &lt;strong&gt;collaboration&lt;/strong&gt;. Yes you will work independently, however more likely than not you will have the support of everyone in the lab, and you will be giving support yourself (getting a bit of experience on supervision and mentoring). &lt;strong&gt;Curiosity&lt;/strong&gt; is welcome and encouraged. Ask your questions, get involved in all aspects of the process if possible, and take advantage of the fact you will have a &amp;lsquo;mentor&amp;rsquo; for the whole academic year.&lt;/p&gt;
&lt;p&gt;During my time at ReBeL, I have been involved in various projects, such as &amp;ldquo;Exploring the Correlation between Interoception and Primal World Beliefs&amp;rdquo; and a meta-analysis of a widely used questionnaire of Interoception. These projects have taught me a lot, from how to collect and analyse both physiological and behavioural data, access and collect data for a meta-analysis, and report the work I did in oral and written format. Throughout the year, with the guidance and expertise of everyone involved in the lab, I gained a lot of confidence in my abilities as a researcher. Which is why I found this internship the most influential aspect of my masters.  Ultimately, at the ReBeL lab, you will not only &lt;strong&gt;investigate exciting concepts and topics but you will also have first hand experience on what it actually takes to be a researcher&lt;/strong&gt; (including the need to have a twitter account, apparently).&lt;/p&gt;
&lt;h2 id=&#34;survival-tips&#34;&gt;Survival Tips&lt;/h2&gt;
&lt;p&gt;Now&amp;hellip; You might be wondering.. &amp;ldquo;How in the world will I do all of this in one academic year?&amp;rdquo; Here are some tips that helped me gain the most of this masters without loosing my mind.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unsurprising tip&lt;/strong&gt;: DO THE WEEKLY WORKSHOPS/TUTORIALS. They will provide with the majority of code, steps and knowledge necessary to complete the assignments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Life saving tip&lt;/strong&gt;: do meal prep for the 48-hour assignments. If you are anything like me you will rather lose sleep then a delicious home-made meal. However, with the short time window to complete these assignments, meal prepping will help you feel less anxious about &amp;ldquo;not having enough time&amp;rdquo; to complete it all whilst still giving your mind everything it needs to function (i.e., sleep and nutrients).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Qualitative tip&lt;/strong&gt;: as part of the January assignments, you will be asked to analyse 5 interviews using a qualitative method. If you come from a mostly quantitative background like me, you will be unfamiliar to how long it takes to code qualitative data. Do not make the same mistakes as I did and start that assignment as early as possible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student formatting tip&lt;/strong&gt;: when lectures say &amp;ldquo;I want it in APA format&amp;rdquo; some will expect you to write a piece of work that equates a publication level piece of work. When in doubt, ask them!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Practical life skills tip&lt;/strong&gt;: communication is key with your supervisors. Especially during your internship; be honest about what you can and can not do, your preferred ways of working, your goals and dreams, and mostly important when you need help.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ultimate tip&lt;/strong&gt;: do consider part-time , especially if you want/need to be working more than 20 hours a week on top of doing this masters. It is full on, and even as part-time all the lectures will be taught in the first year and hence there is still a lot of work to do. But it is possible, and can even be &lt;em&gt;enjoyable&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Junior Research Assistant (JRA) at Sussex: is it worth it?</title>
      <link>https://realitybending.github.io/post/2024-03-12-jingjra/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2024-03-12-jingjra/</guid>
      <description>&lt;p&gt;Hi all, I am &lt;a href=&#34;https://realitybending.github.io/authors/jingxiong-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jing&lt;/a&gt;, and I thought I would share my experience as a Psychology Junior Research Assistant (JRA) at the University of Sussex, as many students might wonder how it is really like. Obviously, I cannot speak for all the labs, but I hope my experience can give you a general idea of what to expect.&lt;/p&gt;
&lt;p&gt;I worked as a JRA during summer 2023 at the Reality Bending Lab (ReBeL). And to put it simply, I think it was &lt;strong&gt;the most valuable experience&lt;/strong&gt; during my undergraduate journey &lt;em&gt;(PS: I have &lt;strong&gt;not&lt;/strong&gt; written this at gunpoint)&lt;/em&gt;. During these three months, I was supervised by Dr Makowski to work on a piece of original research, that thought me a lot about programming, cognitive neuropsychology, physio recordings and how real research is done. Additionally, know that it is possible to stay in the same lab next academic year, to do your final year &lt;strong&gt;dissertation with a strong head start&lt;/strong&gt; in terms of skills and knowledge.&lt;/p&gt;
&lt;img src=&#34;poster.jpg&#34; align=&#34;right&#34; width=&#34;40%&#34;&gt; 
&lt;p&gt;I had the pleasure of joining the Reality Bending Lab (ReBeL) along with &lt;a href=&#34;https://realitybending.github.io/authors/auz-moore/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Auz&lt;/a&gt;, as the first two members since the lab moved to the UK. The title of my project was &lt;strong&gt;&amp;ldquo;Exploring the Correlation between Interoception and Primal World Beliefs&amp;rdquo;&lt;/strong&gt;, which involved collecting &lt;strong&gt;physiological data&lt;/strong&gt; (e.g., heart rate, respiration, &amp;hellip;) in various tasks, analysing them, and investigating the relationship between various measures. The project started from scratch, where I learned how to use the &lt;strong&gt;JavaScript package JsPsych&lt;/strong&gt; to build the entire paradigm via coding. I also received detailed training on how to run a lab-based experiment, something I used to be worried but am now &lt;strong&gt;extremely confident about&lt;/strong&gt;. After collecting the data from 20 participants (&lt;em&gt;summer time goes by veryyyy fast!&lt;/em&gt;), I learned how to make and visualize Bayesian correlations in R. The output of this project was made into an academic poster, where I had to be creative and selective, to be presented at the poster session (see below). Additionally, we created the &lt;a href=&#34;https://github.com/RealityBending/SussexPhysioProtocol&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;&amp;ldquo;Sussex Psychophysiological Research Protocol&amp;rdquo;&lt;/em&gt;&lt;/a&gt;, a document aiming at providing guidelines for the best practices in psychophysiological research, to benefit future research done at Sussex. It might not seem like much, but it felt like doing real contributions to research, which was great!&lt;/p&gt;
&lt;p&gt;Something important I learned is, beyond pure academic excellence, research is also about community and networking. It was a great occasion to &lt;strong&gt;informally meet many researchers&lt;/strong&gt;, and make bonds with other students. What is cool is that the JRA journey doesn&amp;rsquo;t stop abruptly and continues into the next academic year, as all candidates are invited to present their work at the &lt;strong&gt;JRA conference&lt;/strong&gt; held by the university in October. This was an amazing opportunity to get a glimpse of what a scientific conference might be, feel proud about your work, connecting with fellow students, learning how to talk about research with other staff members, and gaining public speaking skills. For those who are more ambitious, why not submit your work to the national level, and present it in the British Conference for Undergraduate Research (BCUR)?&lt;/p&gt;
&lt;p&gt;In summary, I see the JRA as a golden key to open countless possibilities for your &lt;strong&gt;future career path&lt;/strong&gt;. For those considering applying to &lt;strong&gt;postgraduate studies&lt;/strong&gt; or research assistants, the strong research experience you gained will &lt;strong&gt;put you at the top of the list&lt;/strong&gt;. Even for those who decided to not do research in the future, it will still be rewarding as it gives a clear idea of what career you do not want. Don&amp;rsquo;t miss on it!&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;- Jing&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2024-03-12-jingjra/ceremony_hu_79578bb193b81a68.webp 400w,
               /post/2024-03-12-jingjra/ceremony_hu_1defa5a8c38bfddd.webp 760w,
               /post/2024-03-12-jingjra/ceremony_hu_2287f73e27748a4c.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2024-03-12-jingjra/ceremony_hu_79578bb193b81a68.webp&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New location and new logo!</title>
      <link>https://realitybending.github.io/post/2023-02-01-new_logo/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-02-01-new_logo/</guid>
      <description>&lt;p&gt;New year, new start. And as I am officially starting a new faculty position at the &lt;strong&gt;University of Sussex&lt;/strong&gt; in Brighton, UK, the lab is moving too.&lt;/p&gt;
&lt;p&gt;To give a bit of perspective, we started as the &amp;ldquo;Reality Bending League&amp;rdquo;, which was the unofficial name of the team working with me (&amp;ldquo;League&amp;rdquo; was chosen to keep the lab&amp;rsquo;s acronym, &lt;strong&gt;ReBeL&lt;/strong&gt;). It then became a semi-official group in 2021, when I became a semi-independent PI after being awarded a transition grant from &lt;a href=&#34;https://www.ntu.edu.sg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NTU&lt;/a&gt;. And with 2023 comes our fully official start.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;old_logo.png&#34; alt=&#34;Vintage logo&#34;/&gt;
  &lt;figcaption&gt;ReBeL logo (2020-2022).&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;To mark this (re)birth anniversary, we are changing our logo. As much as I loved the old one - which was &lt;a href=&#34;https://realitybending.github.io/post/2021-06-30-logo_meaning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;packed with symbols&lt;/strong&gt;&lt;/a&gt;, it was arguably a bit too&amp;hellip; &lt;em&gt;&lt;strong&gt;extravagant&lt;/strong&gt;&lt;/em&gt;. Something more sleek and minimal felt good with respect to the lab&amp;rsquo;s newly acquired legitimacy. I know that many will prefer the old-&amp;hellip; sorry, the &lt;em&gt;&lt;strong&gt;vintage&lt;/strong&gt;&lt;/em&gt;- logo, and I must say it wasn&amp;rsquo;t easy for me to move forward with the change. Perhaps it will make a come-back in the future in another form, who knows!&lt;/p&gt;
&lt;p&gt;The new logo contains 3 symbols. The &lt;strong&gt;curved spoon&lt;/strong&gt; is a reference to the Matrix scene where a kid shows Neo how to bend a spoon, which is a &lt;strong&gt;metaphor for reality&lt;/strong&gt; (hence of the name of the lab, reality bending).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;Matrix1.gif&#34;/&gt;
&lt;/figure&gt;
&lt;p&gt;In the movie, Neo becomes able to &lt;strong&gt;control reality by becoming aware of its illusory nature&lt;/strong&gt;, and of the predominant role of one&amp;rsquo;s Self in its generation.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;Matrix2.gif&#34;/&gt;
  &lt;figcaption&gt;&#34;Try to realize the truth... There is no spoon. Then you&#39;ll see that it is not the spoon that bends, it is only yourself.&#34;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The &lt;strong&gt;second meaning&lt;/strong&gt; of the logo is the &lt;em&gt;Psi&lt;/em&gt; Greek letter, symbol of psychology, formed by the spoon and the white vertical line.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;APA.png&#34;/&gt;
  &lt;figcaption&gt;The logo of the APA features the Psi letter.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Thirdly, the black rectangles represent &lt;strong&gt;open doors&lt;/strong&gt;, which is a good illustration of progress, research, discovery and&amp;hellip; consciousness expansion? Interestingly, Jim Morrison named its band &amp;ldquo;The Doors&amp;rdquo; in reference to a quote by William Blake, who said that when &lt;em&gt;&lt;strong&gt;&amp;ldquo;the doors of perception were cleansed then everything would appear to man as it is, Infinite&amp;rdquo;&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;TheDoors.jpg&#34;/&gt;
&lt;/figure&gt;
&lt;p&gt;To share a blooper, here is an alternative direction for the logo that wasn&amp;rsquo;t selected, that incorporated the spoon and the open door in another way. Unfortunately, some said it looked too much like the Pixar lamp, or like a spermatozoid&amp;hellip;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;logo_alternative.png&#34; alt=&#34;Alternative logo&#34;/&gt;
  &lt;figcaption&gt;A tentative version of the logo.&lt;/figcaption&gt;
&lt;/figure&gt;
</description>
    </item>
    
  </channel>
</rss>
