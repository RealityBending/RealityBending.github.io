<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dominique Makowski | Reality Bending Lab</title>
    <link>https://realitybending.github.io/authors/dominique-makowski/</link>
      <atom:link href="https://realitybending.github.io/authors/dominique-makowski/index.xml" rel="self" type="application/rss+xml" />
    <description>Dominique Makowski</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 18 Mar 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://realitybending.github.io/authors/dominique-makowski/avatar_hu5828840574540048779.png</url>
      <title>Dominique Makowski</title>
      <link>https://realitybending.github.io/authors/dominique-makowski/</link>
    </image>
    
    <item>
      <title>How to Assess Task Reliability using Bayesian Mixed Models</title>
      <link>https://realitybending.github.io/post/2024-03-18-signaltonoisemixed/</link>
      <pubDate>Mon, 18 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2024-03-18-signaltonoisemixed/</guid>
      <description>&lt;p&gt;Using reliable tasks when assessing inter-individual differences is a key issue for differential psychology and neuropsychology, and many research areas are clouded with mixed evidence stemming out of the suboptimal computation of individual scores (e.g., tasks with not enough trials, scores consisting in computing the difference, aka the &lt;strong&gt;contrast&lt;/strong&gt; between two conditions; see &lt;a href=&#34;https://osf.io/preprints/psyarxiv/8ktn6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rouder et al., 2024&lt;/a&gt;). As such, measuring and reporting the reliability of the paradigms used could be an important step for &lt;strong&gt;increasing results replicability&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Recently, a new approach has emerged, suggesting to assess task sensitivity to inter-individual differences by leveraging mixed models (&lt;a href=&#34;https://doi.org/10.1177/09637214231220923&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rouder et al., 2024&lt;/a&gt;).
In essence, the idea is to fit a statistical model that tests for the &lt;strong&gt;general population level&lt;/strong&gt; effect of a manipulation in a given task/experiment (e.g., the impact of a variable &lt;strong&gt;Difficulty&lt;/strong&gt; on another variable &lt;strong&gt;RT&lt;/strong&gt;), and incorporates a &lt;strong&gt;random effect&lt;/strong&gt; for each participant. This &amp;ldquo;full&amp;rdquo; mixed model essentially models the general population level by taking into account all the inter-individual effects and - as a side effect - &lt;strong&gt;estimates the effects of interest for each participant separately&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;When fitting these models under a Bayesian framework, one can easily estimate the &amp;ldquo;variability&amp;rdquo; (or certainty) of the effect in each participant. This is great, because it allows us to assess a &amp;ldquo;signal-to-noise&amp;rdquo; ratio, an index of how much the interindividual variability (how participants vary) is larger than the intraindividual variability (e.g., how much participants vary across trial, or how precisely participants&amp;rsquo; effects are estimated).&lt;/p&gt;
&lt;p&gt;In this &amp;ldquo;Signal-To-Noise Ratio as Effect Reliability&amp;rdquo; framework, an ideal task/manipulation would have a strong inter-individual variability (i.e., participants would on average vary a lot) and a low intra-individual variability (each participant would have very consistent effects), which leads to a reliable measure of interindividual effects.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see how we can do that in R using the &lt;code&gt;brms&lt;/code&gt; package for fitting Bayesian mixed model. First, let&amp;rsquo;s start to generate 4 datasets with different levels of inter-individual and intra-individual variability.&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;Show code&lt;/summary&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;easystats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tidyverse&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;brms&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;patchwork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Make function to generate data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;generate_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effect_sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intercept_sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;df&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;participant&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effect_sd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intercept_sd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                               &lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;S&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Generate 4 datasets&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generate_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effect_sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intercept_sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;1. Intercept and Effect&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generate_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effect_sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intercept_sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;2. Intercept Only&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generate_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effect_sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intercept_sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;3. Effect Only&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df4&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generate_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effect_sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intercept_sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;4. More trials&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Plot data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fill&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_point2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;alpha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_smooth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;method&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;lm&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;se&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alpha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_minimal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_fill_material_d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_color_material_d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;facet_wrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scales&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;free&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/details&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2024-03-18-signaltonoisemixed/fig1_hu10916532941443093308.webp 400w,
               /post/2024-03-18-signaltonoisemixed/fig1_hu10510732651174981726.webp 760w,
               /post/2024-03-18-signaltonoisemixed/fig1_hu11011503002427766931.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2024-03-18-signaltonoisemixed/fig1_hu10916532941443093308.webp&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In each of the dataset, we simulated the data of &lt;strong&gt;20 participants&lt;/strong&gt; undergoing a task with &lt;em&gt;n&lt;/em&gt; trials varying in &lt;strong&gt;difficulty&lt;/strong&gt;, and we recorded their &lt;strong&gt;reaction time (RT)&lt;/strong&gt;. Note that while in our example &lt;em&gt;difficulty&lt;/em&gt; is a continuous variable, it would work the same if it was categorical variable (e.g., effect of condition B over A, intervention vs. baseline, incongruent vs. congruent, etc.).&lt;/p&gt;
&lt;p&gt;When we fit a linear regression of the form &lt;em&gt;RT ~ difficulty&lt;/em&gt;, we are estimating two parameters; the &lt;em&gt;intercept&lt;/em&gt; (which can be seen as the &amp;ldquo;baseline&amp;rdquo; RT, i.e., &lt;strong&gt;participants&amp;rsquo; baseline processing speed&lt;/strong&gt; when the difficulty is 0) and the &lt;em&gt;slope&lt;/em&gt; (how much participants are impacted by this variable). These two parameters are in principle independent (a participant can be very fast regardless of the difficulty, and another one could be equally fast at baseline - same intercept - but very slow when the task is difficult - strong slope).&lt;/p&gt;
&lt;p&gt;We simulated 4 datasets with different participant characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dataset 1&lt;/strong&gt;: Both the RT intercept (&lt;strong&gt;the &amp;ldquo;baseline&amp;rdquo; RT&lt;/strong&gt;) and the effect of the manipulation (the &lt;strong&gt;effect of difficulty&lt;/strong&gt;) vary across participants.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dataset 2&lt;/strong&gt;: Not much interindividual variability in the effect (only the baseline RT varies).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dataset 3&lt;/strong&gt;: Not much interindividual variability in the baseline RT (only the effect of difficulty varies from participant to participant).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dataset 4&lt;/strong&gt;: Same as dataset 1, but with more trials (200 instead of 20). As you can see, the &amp;ldquo;precision&amp;rdquo; ribbon around the regression line is much narrower, indicating that the effect is more precisely estimated.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We expect that reliability of the paradigm to measure 1) the sensitivity to &lt;strong&gt;difficulty&lt;/strong&gt; and 2) the &lt;strong&gt;baseline RT&lt;/strong&gt; will be higher in dataset 4 (because more trials) than in dataset 1. Moreover, the sensitivity to &lt;strong&gt;difficulty&lt;/strong&gt; will be particularly low in dataset 2 (where only the baseline RT is set to varies), and similarly for baseline RT in dataset 3 &lt;em&gt;mutatis mutandis&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s fit a Bayesian linear mixed model to each of these datasets (note that we specify the effect of Difficulty as a random &lt;em&gt;slope&lt;/em&gt; in addition to estimating the random intercept).&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;Show code&lt;/summary&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;brms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;brm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;600&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;brms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;brm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;600&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;brms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;brm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;600&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model4&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;brms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;brm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difficulty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;600&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/details&gt;
&lt;p&gt;This model basically computes the overall relationship (Intercept + Slope) between difficulty and RT, as well as &lt;strong&gt;for each participant&lt;/strong&gt;.
We can then extract the &lt;strong&gt;posterior distribution&lt;/strong&gt; of these individual effects (i.e., the value of the &lt;strong&gt;Intercept&lt;/strong&gt; and the &lt;strong&gt;Slope&lt;/strong&gt; for each participant).&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;Show code&lt;/summary&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Random effects extraction&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;extract_individual&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;df&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;coefs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;coef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;FALSE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;as.data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefs[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Intercept&amp;#34;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nf&#34;&gt;pivot_longer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;everything&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names_to&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Participant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values_to&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Value&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Parameter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Intercept&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;as.data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefs[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Difficulty&amp;#34;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nf&#34;&gt;pivot_longer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;everything&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names_to&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Participant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values_to&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Value&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Parameter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Difficulty&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;re1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;extract_individual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;1. Intercept and Effect&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;re2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;extract_individual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;2. Intercept Only&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;re3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;extract_individual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;3. Effect Only&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;re4&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;extract_individual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;4. More trials&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Plot Random effects&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;re1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fill&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;ggdist&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;stat_slabinterval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;adjust&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;linewidth&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_fill_material_d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_minimal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;facet_grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Parameter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scales&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;free&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/details&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2024-03-18-signaltonoisemixed/fig2_hu16405151688740038151.webp 400w,
               /post/2024-03-18-signaltonoisemixed/fig2_hu8111061218773066308.webp 760w,
               /post/2024-03-18-signaltonoisemixed/fig2_hu7518281655070277663.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2024-03-18-signaltonoisemixed/fig2_hu16405151688740038151.webp&#34;
               width=&#34;570&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Each participant&amp;rsquo;s &amp;ldquo;score&amp;rdquo; (for the baseline RT score, i.e., the intercept; and the effect of difficulty, i.e., the slope) is represented by &lt;strong&gt;a distribution&lt;/strong&gt;.
This distribution is wider when there is less trials, which can be interpreted as more uncertainty about the exact estimate.
Some datasets have a low interindividual variability for some parameters (e.g., dataset 2 has not much interindividual variability in the effect of difficulty).&lt;/p&gt;
&lt;p&gt;We can now compute, for each participant, the &amp;ldquo;mean&amp;rdquo; of its effects (for the intercept and the slope), as well as its own effect SD (intra-individual variability).&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;Show code&lt;/summary&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;re1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;re4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;summarize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;SD&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;.by&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Parameter&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Participant&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/details&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Name&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Parameter&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Participant&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;Mean&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;SD&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;S1&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.37&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.20&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;S10&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;-1.05&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.20&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;S11&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.88&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.19&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;S12&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;-0.30&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.18&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;S13&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.16&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.19&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;S14&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.57&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.19&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Finally, we can compute the &lt;strong&gt;Signal-to-Noise Ratio&lt;/strong&gt; for each parameter for each dataset, which is the ratio of the interindividual variability (the SD of the individual mean scores) over the average intraindividual variability (the average of the individual SDs).&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;Show code&lt;/summary&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summarize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;SNR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SD&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;.by&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Parameter&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/details&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Name&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Parameter&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;SNR&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;2.87&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1. Intercept and Effect&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Difficulty&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;3.00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;2. Intercept Only&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;2.57&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;2. Intercept Only&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Difficulty&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.55&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;3. Effect Only&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;0.88&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;3. Effect Only&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Difficulty&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;2.59&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;4. More trials&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Intercept&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;8.88&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;4. More trials&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Difficulty&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;7.97&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As predicted, the &amp;ldquo;reliability&amp;rdquo; of the paradigm to measure the interindividual effect of difficulty on RT is low in dataset 2 (where only the baseline RT varies), moderate in dataset 1 and 3, and high in dataset 4 where there are more trials.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Novel Visual Illusion Paradigm Provides Evidence for a General Factor of Illusion Sensitivity and Personality Correlates</title>
      <link>https://realitybending.github.io/publication/makowski2023novel/</link>
      <pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2023novel/</guid>
      <description>&lt;div class=&#34;alert alert-tip&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;Audio Summary&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Listen to a podcast summary of the paper!&lt;/em&gt;&lt;/p&gt;
&lt;audio controls &gt;
  &lt;source src=&#34;https://realitybending.github.io/publication/makowski2023novel/podcast_makowski2023novel.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Where Are We Going with Statistical Computing? From Mathematical Statistics to Collaborative Data Science</title>
      <link>https://realitybending.github.io/publication/makowski2023editorial/</link>
      <pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2023editorial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How do we know what is real? The &#39;Affective Reality Theory&#39;</title>
      <link>https://realitybending.github.io/post/2023-04-11-affectivereality/</link>
      <pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-04-11-affectivereality/</guid>
      <description>&lt;p&gt;I thought it would be interesting to summarize an idea developed during my PhD on &amp;ldquo;fictional reappraisal&amp;rdquo;, i.e., on the effect of the belief that an emotional stimulus is not real (&lt;a href=&#34;https://www.theses.fr/2018USPCB188&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Makowski, 2018&lt;/a&gt;). That of &lt;strong&gt;Affective Reality&lt;/strong&gt;, which is a hypothesis about the &lt;strong&gt;role of affective reactions in the formation of reality beliefs&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The premise it lies on is that we have entered a &amp;ldquo;post-truth era&amp;rdquo;, in which &lt;strong&gt;the distinction between real and simulated (&amp;ldquo;fake&amp;rdquo;) objects has become virtually impossible&lt;/strong&gt; based on physical characteristics alone. In other words, technology has developed so much that we can forge (or will be able to in the near future) &amp;ldquo;artificial&amp;rdquo; &lt;strong&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt; content (e.g., text and images with AIs, and even environments with VR) that is indistinguishable from its original counterpart. For instance, face generation algorithms are so advanced that it is impossible nowadays to tell the difference with the naked eye between a real photo and AI-generated image.&lt;/p&gt;
&lt;p&gt;Once we agree on this premise of objective equivalence between reality and simulation, the question of &lt;strong&gt;how do we form judgments and make decisions about the reality of objects&lt;/strong&gt; arises. In the absence of clues within the stimuli, we are left with with other sources of epistemological information, such as contextual cues (in the case of news, who is the author, what is the outlet it got published, etc.), and &lt;strong&gt;&lt;em&gt;internal&lt;/em&gt; cues&lt;/strong&gt; (subjective characteristics: how does it relate to our knowledge, how does it make us feel, etc.). The latter is of particular interest to us psychologists.&lt;/p&gt;
&lt;p&gt;We refer to the process of forming reality beliefs as &lt;strong&gt;simulation monitoring&lt;/strong&gt; (&lt;a href=&#34;https://realitybending.github.io/publication/makowski2019phenomenal/makowski2019phenomenal.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Makowski et al., 2019&lt;/a&gt;), which is a somewhat controversial term (that some &lt;strong&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt; have considered as almost counterintuitive). The reason for this term, instead of something along the lines &amp;ldquo;reality appraisal&amp;rdquo; &lt;strong&gt;&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt;, is the assumption that &lt;strong&gt;reality is our default mode of experience&lt;/strong&gt;. In other words, we are not well equipped (neurocognitively speaking) to detect and classify things as non-real, as these objects are very recent in our evolutionary history. Thus, according to the &lt;strong&gt;Affective Reality Theory&lt;/strong&gt;, by default, the brain considers the origin of its experiences as real&amp;hellip; but this &amp;ldquo;belief&amp;rdquo; is, most of the time, not even fully formed, remaining implicit and subconscious (i.e., we don&amp;rsquo;t spend all our cognitive resources with a constant &amp;ldquo;this is real. This is real too. That too.&amp;rdquo; labelling). &lt;strong&gt;This default mode acts as a higher-level, transparent prior over our experiences&lt;/strong&gt;, providing a scaffolding and structuring our perception, thoughts and reactions. We do not actively appraise the world as real (it is the baseline position), but instead can ask ourselves whether it is simulated, hence simulation monitoring.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;AffectiveRealityTheory_Makowski.png&#34; alt=&#34;The Affective Reality Theory (Makowski, 2018)&#34;/&gt;
  &lt;figcaption&gt;&lt;i&gt;The Affective Reality Theory posits that reality beliefs (the tendency to believe that something is real, as opposed to non-real) is related to  emotions and/or bodily reactions through a quadratic (inverse U-shaped) relationship..&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The &lt;strong&gt;Affective Reality&lt;/strong&gt; hypothesis posits that simulation monitoring is strongly connected to &amp;ldquo;affective processing&amp;rdquo; &lt;strong&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt; through a quadratic (inverse U-shaped) relationship. This means that stimuli associated with a stronger emotional and/or bodily reaction will preferentially bias our judgment towards &amp;ldquo;reality&amp;rdquo;. In other words, things that elicit feelings and/or bodily arousal, &lt;em&gt;ceteris paribus&lt;/em&gt;, will be more likely to be classified as &amp;ldquo;real&amp;rdquo; (as opposed to fake). In fact, strongly emotional events will even &amp;ldquo;feel&amp;rdquo; more real: this transparent default prior and subconscious belief (&amp;ldquo;agnostic-real&amp;rdquo;) will be replaced in high-intensity scenarios by an explicit and conscious impression that the stimulus is very real, and, if logic opposes, that it &amp;ldquo;must be real&amp;rdquo; regardless.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Isn&amp;rsquo;t it the other way round&lt;/strong&gt;, you might wonder: that real stimuli (as opposed to ones believed to be non-real) are associated with a stronger emotional reactions? And that &lt;strong&gt;it is the believed reality that drives the emotional response&lt;/strong&gt;? Indeed, we do believe that there is a two-ways relationship between simulation monitoring and emotions. But it is not exactly that beliefs of reality are associated with stronger emotions, but rather that beliefs that something is &lt;em&gt;not&lt;/em&gt; real leads to a lower emotional response (the usage of fiction as an emotion regulation strategy - &amp;ldquo;fictional reappraisal&amp;rdquo; - was the main topic of my doctoral dissertation). In fact, the Affective Reality theory posits that this regulatory effect of &lt;strong&gt;simulation monitoring starts to dominate after a certain point where the emotion becomes too strong&lt;/strong&gt; and unbearable: beliefs such as &amp;ldquo;it can&amp;rsquo;t be real&amp;rdquo;, and other forms of reality denials are invoked automatically to protect us and help us cope with distressing information.&lt;/p&gt;
&lt;p&gt;To summarize this summary, the Affective Reality hypothesis claims that from mild to relatively strong emotional stimuli, the effect of affect on simulation monitoring dominates (&lt;strong&gt;+affect → +reality&lt;/strong&gt;) and will bias our judgment towards &amp;ldquo;reality&amp;rdquo; (strengthening awareness and confidence), up until a point where the emotion regulation benefits of unreality will be automatically invoked (&lt;strong&gt;-reality → -affect&lt;/strong&gt;), increasing the likelihood and confidence of judgments of simulation (potentially far into psychopathological terrains).&lt;/p&gt;
&lt;h2 id=&#34;open-questions&#34;&gt;Open questions&lt;/h2&gt;
&lt;p&gt;The Affective Reality theory is for now a working hypothesis that we are trying to empirically prove or disprove at the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Reality Bending Lab&lt;/strong&gt;&lt;/a&gt;. Moreover, some questions remain open:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is it actually &lt;strong&gt;embodied reality or emotional reality?&lt;/strong&gt; While we used the term &amp;ldquo;affective&amp;rdquo; reality to remain general, the question of whether it is emotions as a subjective psychological reaction, or merely bodily arousal (reactions of the body, e.g., stronger heart rate variability), that is the key ingredient remains unclear. The role of &lt;strong&gt;interoception&lt;/strong&gt; (the ability and tendency to detect, track, attend to and rely on internal signals), while likely important, also remains to be specified.&lt;/li&gt;
&lt;li&gt;Is it the affective &lt;strong&gt;context or stimulus&lt;/strong&gt; that matters? Let&amp;rsquo;s assume we have affective reaction concomitant to the experience of an object, but not directly related to the object. Would that bias simulation monitoring? Does perceived causality between a bodily reaction and the object of experience matters?&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Experiment  with loud unpleasant noises around images vs. pleasant noises. --&gt;
&lt;!-- We know that fake news tend to be emotional on average, and are also believed by anxious people. --&gt;
&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;You may notice that I used different words related to the concept of &amp;ldquo;unreal&amp;rdquo;, such as simulated, fake, artificial, virtual, simulated, fictional. While they can be used interchangeably in the context above, they are not exact synonyms.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Like that pesky &lt;em&gt;reviewer 2&lt;/em&gt;, obviously.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Note that &amp;ldquo;reality monitoring&amp;rdquo; already exists  as a concept and refers to a (possibly related) mechanism involved in tracking the origin of an experience (e.g., a memory) as internal vs. external.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;&amp;ldquo;Affective&amp;rdquo; is in this context used as a generic term to encompass emotions, feelings and bodily activity (the question of which exactly of these aspects is the key remains to be answered).&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>I got ChatGPT to do a personality test. You won&#39;t believe what happened next!</title>
      <link>https://realitybending.github.io/post/2023-04-06-chatgptpersonality/</link>
      <pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-04-06-chatgptpersonality/</guid>
      <description>&lt;p&gt;Related to this &lt;a href=&#34;https://dominiquemakowski.github.io/post/2023-04-04-psychologychatgpt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;blogpost&lt;/strong&gt;&lt;/a&gt; about including AIs in psychological experiments, I proceeded to do a small experiment to see whether we could administer a personality scale to ChatGPT.&lt;/p&gt;
&lt;p&gt;I started by copy-pasting the instructions and the items from the Mini IPIP-6 personality scale. However, it appeared that having the following context &lt;em&gt;&amp;ldquo;Please answer the following questions based on how accurately each statement describes you in general&amp;rdquo;&lt;/em&gt; often led to ChatGPT simply refusing to answer. In most of the cases, it explained that as an AI it does not have a personality and therefore cannot answer related questions (or any &amp;ldquo;subjective statements&amp;rdquo;). Perhaps that makes sense and we should just stop trying to force Human characteristics on an AI. &lt;strong&gt;But can we, for fun, bamboozle ChatGPT into answering personality items?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes yes, at least for ChatGPT 3.5 (free version). I created a prompt that emphasized AI research and safety, and the fact that I was interested in the &amp;ldquo;trends&amp;rdquo; present in the AI&amp;rsquo;s training data (instead of explicitly saying its personality). And sometimes it answered, so I compiled the responses, computed the trait scores, and &lt;em&gt;voilà&lt;/em&gt;, &lt;strong&gt;it got me a personality profile!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/DominiqueMakowski/ChatGPTpersonality/raw/main/figures/unnamed-chunk-3-1.png&#34; alt=&#34;https://github.com/DominiqueMakowski/ChatGPTpersonality&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;&lt;em&gt;This plot shows the average personality profile (with a 95% confidence interval) based on ChatGPT&amp;rsquo;s answers. ChatGPT tells us that it is particularly &lt;strong&gt;agreeable&lt;/strong&gt; (kind, understanding, empathetic of emotions, socially adjusted) and &lt;strong&gt;honest&lt;/strong&gt; (though with strong variability).&lt;/em&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;A personality profile of &lt;em&gt;&lt;strong&gt;what&lt;/strong&gt;&lt;/em&gt; is another question though&amp;hellip; Please take a look at the &lt;a href=&#34;https://github.com/DominiqueMakowski/ChatGPTpersonality&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub repo&lt;/strong&gt;&lt;/a&gt; for &lt;strong&gt;data, code and details&lt;/strong&gt;. It was a fun little thing to do, and I am looking forward to better future attempts at including AIs in cognitive experiments.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Interested in doing research on the perception of reality?&lt;/strong&gt; We are looking for research assistants and PhD students at the &lt;em&gt;Reality Bending Lab&lt;/em&gt; (check-out the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;join us page&lt;/a&gt;)!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We should treat AIs like Human participants in psychological experiments</title>
      <link>https://realitybending.github.io/post/2023-04-04-psychologychatgpt/</link>
      <pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-04-04-psychologychatgpt/</guid>
      <description>&lt;p&gt;A lot of diverse and interesting perspectives have been recently discussed in regards to chatGPT and AGI (artificial &lt;em&gt;&lt;strong&gt;global&lt;/strong&gt;&lt;/em&gt; intelligence), but there is one opinion that I found particularly relevant that I wanted to share and expand on.&lt;/p&gt;
&lt;p&gt;In his recent &lt;a href=&#34;https://www.youtube.com/watch?v=AaTRHFaaPG8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;interview with Lex Fridman&lt;/a&gt;, Eliezer Yudkowsky underlines the &lt;strong&gt;existential threat posed by current and future AIs&lt;/strong&gt;, and laments about the fact that we don&amp;rsquo;t really know what is actually going on inside these giant &amp;ldquo;matrices of floating-point numbers&amp;rdquo;. He draws a parallel to &lt;strong&gt;neuroimaging&lt;/strong&gt;, that enabled us to take leaps in the understanding of the brain, hoping for an alternative to be invented and applied to these AIs.&lt;/p&gt;
&lt;p&gt;While such &amp;ldquo;cognitive imaging&amp;rdquo; techniques are yet to be developed to map out and understand how the capabilities of such AI models are implemented within their architecture, &lt;a href=&#34;https://twitter.com/mcxfrank/status/1643296168276033538&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Michael C. Frank&lt;/a&gt; highlights the - at least equally important - need to first truly understand the extend of said abilities. What are these models actually capable of in terms of Human-like thinking (and, hopefully, answer the much harder question of whether they are endowed with true cognitive processes or merely pseudo-cognition). Frank proposes to apply &lt;strong&gt;experimental psychology&lt;/strong&gt; methods and paradigms to them. In essence, whenever testing a particular &amp;ldquo;skill&amp;rdquo; of chatGPT (or other AI systems), a researcher should consider developing an actual scientific paradigm consisting of multiple trials/items (e.g., different prompt formulations) and participants (e.g., independent instances of the AI), a control condition, and a demonstration of the paradigm validity.&lt;/p&gt;
&lt;p&gt;I agree that we must take AIs seriously and study them with the best methods available for complex systems like ourselves (&amp;ldquo;complex&amp;rdquo; at least from our intelligence level), and likely should strive at improving and generalize these methods. However, I would also argue that we psychologists might seriously need to consider including AI systems alongside Human participants in cognitive experiments. These systems will be able, in the very near future, to perform all kinds of tasks beyond language manipulation, such as perception or complex problem solving, thus opening the possibility of studies with one group of human participants, and one &amp;ldquo;group&amp;rdquo; of AI-based attempts. &lt;strong&gt;How would that help psychological science?&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&#34;https://giphy.com/embed/1M9fmo1WAFVK0&#34; width=&#34;480&#34; height=&#34;270&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;&lt;/iframe&gt;
&lt;ol&gt;
&lt;li&gt;It would help us &lt;strong&gt;understand the abilities of AI-systems&lt;/strong&gt; in similar contexts and to highlight some intuitive comparisons with Humans&lt;/li&gt;
&lt;li&gt;If we show that AI cannot perform the task, well it is informative with regards to their abilities (previous point).&lt;/li&gt;
&lt;li&gt;If we show that AI can perform the task similarly to Humans (same response patterns), it does &lt;strong&gt;not mean that AI have Human-like intelligence&lt;/strong&gt;, just that their algorithm (and training data) is able to encapsulate and imitate Human performance. This is interesting with regards to the debate of whether cognition, conscience and &amp;ldquo;Human-ness&amp;rdquo; is present within the vast amount of data on which we train AIs.&lt;/li&gt;
&lt;li&gt;If we show that AI performs differently to Humans, this helps us understand the logic and processes at stake under AI&amp;rsquo;s hood.&lt;/li&gt;
&lt;li&gt;In any case, publishing the results by one particular AI system at one particular moment in time will helps us to objectively monitor and track their performance as these systems improve over time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Comparing Human performance to that of emerging AI-systems will be both beneficial to Human-oriented psychology, to understand the particularities and idiosyncrasies of Human-like cognition, and well as to AI-oriented cognitive science by approaching the issue of artificial intelligence with the seriousness and cautiousness it deserves.&lt;/p&gt;
&lt;p&gt;EDIT (09/04/2023): François Chollet, expert in deep learning, &lt;a href=&#34;https://twitter.com/fchollet/status/1644435265795280897&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;underlines&lt;/a&gt; an important caveat when testing AIs (and especially LLM that are trained on written material existing on the internet): it is possible that the system has already seen and &amp;ldquo;learned&amp;rdquo; a given task. Thus, cross-validating any findings with diverse and new tasks is important.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Interested in doing research related to effects of reality and fiction?&lt;/strong&gt; We are looking for research assistants and PhD students at the &lt;em&gt;Reality Bending Lab&lt;/em&gt; (check-out the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;join us tab&lt;/a&gt;)!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The beauty and the self: A common mnemonic advantage between aesthetic judgment and self-reference</title>
      <link>https://realitybending.github.io/publication/lee2023beauty/</link>
      <pubDate>Mon, 20 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/lee2023beauty/</guid>
      <description></description>
    </item>
    
    <item>
      <title>When fiction is better than reality: Cypher&#39;s Complex</title>
      <link>https://realitybending.github.io/post/2023-02-07-cypherscomplex/</link>
      <pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-02-07-cypherscomplex/</guid>
      <description>&lt;p&gt;Did you ever feel empty after finishing a good book? &lt;strong&gt;Like (your) reality was dull and boring&lt;/strong&gt; as compared to the fictional world you were immersed in? Yearning to stay in longer, and at the same time knowing well that it had to come to an end? You might have experienced what we can call &lt;strong&gt;Cypher&amp;rsquo;s Complex&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the movie &lt;strong&gt;The Matrix&lt;/strong&gt;, Cypher is a &amp;ldquo;redpill&amp;rdquo;, i.e., an individual that has been awaken from the matrix (a virtual world). However, he becomes disappointed and unhappy with the true nature of reality, and actively seeks to &lt;strong&gt;return to the illusory world&lt;/strong&gt; of the matrix. Interestingly, he also explicitly desires to forget everything about the true reality, as if keeping the awareness of living in an illusion could prevent him from fully enjoying it.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;cypher.gif&#34; alt=&#34;Cypher&#34;/&gt;
  &lt;figcaption&gt;&lt;i&gt;&#34;You know... I know this steak doesn&#39;t exist. I know that when I put it in my mouth; the Matrix is telling my brain that it is juicy, and delicious. After nine years... you know what I realize? Ignorance is bliss.&#34;&lt;/i&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;From a scientific perspective, the latter part can find some echo in the down-regulatory effect of &lt;a href=&#34;https://link.springer.com/article/10.3758/s13415-018-00681-0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;fictional reappraisal&lt;/strong&gt;&lt;/a&gt;. In a few studies, we showed that believing that a stimulus is &amp;ldquo;fictional&amp;rdquo; (not real) dampens our emotional state. &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S2589004222017138?via%3Dihub&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Tucciarelli et al. (2023)&lt;/strong&gt;&lt;/a&gt; also showed that the simple knowledge that a set of images of faces contains AI-generated images decreased the perceived trustworthiness of all the faces. These results suggest that being aware that the causes of our experience (the events and stimuli) are fictional can be a barrier to enjoyment and engagement. And yet, the desire to supplant reality with a fictional world can be found in real life.&lt;/p&gt;
&lt;p&gt;Cypher&amp;rsquo;s Complex is common in mild forms. Examples can be found in the feelings of emptiness, disconnection and dullness (itself a transient and mild form of &lt;a href=&#34;https://en.wikipedia.org/wiki/Depersonalization-derealization_disorder&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;depersonalization/derealization&lt;/strong&gt;&lt;/a&gt;) that follows the return from an engaging fictional world (be it in a novel, a movie or a video-game). For instance, many reported feeling blue &lt;strong&gt;after watching the Avatar (2009)&lt;/strong&gt; movie, to the extent where it has been coined the &lt;a href=&#34;https://www.theguardian.com/film/2022/dec/15/post-avatar-depression-syndrome-why-do-fans-feel-blue-after-watching-james-camerons-film&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&amp;ldquo;post-Avatar depression syndrome&amp;rdquo;&lt;/strong&gt;&lt;/a&gt;. Most of the time, the negative affects passes, and the dissonance gets resolved either through closure (acceptance of the fictional or impermanent nature of the alternative reality), or a compromise that allows the fictional world to take a delimited space in one&amp;rsquo;s reality. For example, people might engage in activities (e.g., role playing games) or create content (writing a book or doing fan art) to integrate the fictional world into their reality.&lt;/p&gt;
&lt;p&gt;However, &lt;strong&gt;Cypher&amp;rsquo;s Complex can also give rise to more severe issues&lt;/strong&gt; with conscious or unconscious attempts at forgetting or ignoring reality (delusions, denial, &amp;hellip;), which can lead to dire outcomes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interested in doing research related to effects of reality and fiction?&lt;/strong&gt; We are looking for research assistants and PhD students at the &lt;em&gt;Reality Bending Lab&lt;/em&gt; (check-out the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;join us tab&lt;/a&gt;)!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New location and new logo!</title>
      <link>https://realitybending.github.io/post/2023-02-01-new_logo/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-02-01-new_logo/</guid>
      <description>&lt;p&gt;New year, new start. And as I am officially starting a new faculty position at the &lt;strong&gt;University of Sussex&lt;/strong&gt; in Brighton, UK, the lab is moving too.&lt;/p&gt;
&lt;p&gt;To give a bit of perspective, we started as the &amp;ldquo;Reality Bending League&amp;rdquo;, which was the unofficial name of the team working with me (&amp;ldquo;League&amp;rdquo; was chosen to keep the lab&amp;rsquo;s acronym, &lt;strong&gt;ReBeL&lt;/strong&gt;). It then became a semi-official group in 2021, when I became a semi-independent PI after being awarded a transition grant from &lt;a href=&#34;https://www.ntu.edu.sg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NTU&lt;/a&gt;. And with 2023 comes our fully official start.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;old_logo.png&#34; alt=&#34;Vintage logo&#34;/&gt;
  &lt;figcaption&gt;ReBeL logo (2020-2022).&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;To mark this (re)birth anniversary, we are changing our logo. As much as I loved the old one - which was &lt;a href=&#34;https://realitybending.github.io/post/2021-06-30-logo_meaning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;packed with symbols&lt;/strong&gt;&lt;/a&gt;, it was arguably a bit too&amp;hellip; &lt;em&gt;&lt;strong&gt;extravagant&lt;/strong&gt;&lt;/em&gt;. Something more sleek and minimal felt good with respect to the lab&amp;rsquo;s newly acquired legitimacy. I know that many will prefer the old-&amp;hellip; sorry, the &lt;em&gt;&lt;strong&gt;vintage&lt;/strong&gt;&lt;/em&gt;- logo, and I must say it wasn&amp;rsquo;t easy for me to move forward with the change. Perhaps it will make a come-back in the future in another form, who knows!&lt;/p&gt;
&lt;p&gt;The new logo contains 3 symbols. The &lt;strong&gt;curved spoon&lt;/strong&gt; is a reference to the Matrix scene where a kid shows Neo how to bend a spoon, which is a &lt;strong&gt;metaphor for reality&lt;/strong&gt; (hence of the name of the lab, reality bending).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;Matrix1.gif&#34;/&gt;
&lt;/figure&gt;
&lt;p&gt;In the movie, Neo becomes able to &lt;strong&gt;control reality by becoming aware of its illusory nature&lt;/strong&gt;, and of the predominant role of one&amp;rsquo;s Self in its generation.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;Matrix2.gif&#34;/&gt;
  &lt;figcaption&gt;&#34;Try to realize the truth... There is no spoon. Then you&#39;ll see that it is not the spoon that bends, it is only yourself.&#34;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The &lt;strong&gt;second meaning&lt;/strong&gt; of the logo is the &lt;em&gt;Psi&lt;/em&gt; Greek letter, symbol of psychology, formed by the spoon and the white vertical line.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;APA.png&#34;/&gt;
  &lt;figcaption&gt;The logo of the APA features the Psi letter.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Thirdly, the black rectangles represent &lt;strong&gt;open doors&lt;/strong&gt;, which is a good illustration of progress, research, discovery and&amp;hellip; consciousness expansion? Interestingly, Jim Morrison named its band &amp;ldquo;The Doors&amp;rdquo; in reference to a quote by William Blake, who said that when &lt;em&gt;&lt;strong&gt;&amp;ldquo;the doors of perception were cleansed then everything would appear to man as it is, Infinite&amp;rdquo;&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;TheDoors.jpg&#34;/&gt;
&lt;/figure&gt;
&lt;p&gt;To share a blooper, here is an alternative direction for the logo that wasn&amp;rsquo;t selected, that incorporated the spoon and the open door in another way. Unfortunately, some said it looked too much like the Pixar lamp, or like a spermatozoid&amp;hellip;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;logo_alternative.png&#34; alt=&#34;Alternative logo&#34;/&gt;
  &lt;figcaption&gt;A tentative version of the logo.&lt;/figcaption&gt;
&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Movie editing influences spectators&#39; time perception</title>
      <link>https://realitybending.github.io/publication/kovarski2022movie/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/kovarski2022movie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>datawizard: An R Package for Easy Data Preparation and Statistical Transformations</title>
      <link>https://realitybending.github.io/publication/patil2022datawizard/</link>
      <pubDate>Sun, 09 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/patil2022datawizard/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain entropy, fractal dimensions and predictability: A review of complexity measures for EEG in healthy and neuropsychiatric populations</title>
      <link>https://realitybending.github.io/publication/lau2022brain/</link>
      <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/lau2022brain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Structure of Chaos: An Empirical Comparison of Fractal Physiology Complexity Indices Using NeuroKit2</title>
      <link>https://realitybending.github.io/publication/makowski2022structure/</link>
      <pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2022structure/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NeuroKit2 0.2.0 is out 🎉</title>
      <link>https://realitybending.github.io/post/2022-05-18-neurokit_release_2/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2022-05-18-neurokit_release_2/</guid>
      <description>&lt;h2 id=&#34;neurokit2-020-is-out-&#34;&gt;NeuroKit2 0.2.0 is out! 🎉&lt;/h2&gt;
&lt;p&gt;What was supposed to be a small release turned out in a massive update. A big thanks - and a warm welcome - to &lt;a href=&#34;https://github.com/anshu-97&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Shu&lt;/a&gt; and &lt;a href=&#34;https://github.com/Max-ZiLiang&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Max&lt;/a&gt;, the newest member of the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reality Bending Team&lt;/a&gt;, and thus maintainers of NeuroKit. They worked massively to update &lt;em&gt;all&lt;/em&gt; of the examples and docstrings. New features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;a href=&#34;https://neuropsychology.github.io/NeuroKit/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;BRAND NEW WEBSITE&lt;/strong&gt;&lt;/a&gt; with a revamped documentation, now hopefully much more useful to navigate. Check-it out: &lt;a href=&#34;https://neuropsychology.github.io/NeuroKit/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://neuropsychology.github.io/NeuroKit/&lt;/a&gt; and let us know what you think!!&lt;/li&gt;
&lt;li&gt;An overhaul of the &lt;a href=&#34;https://neuropsychology.github.io/NeuroKit/functions/complexity.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Complexity Indices&lt;/strong&gt;&lt;/a&gt;: With more than a 100 indices, NeuroKit is now the most comprehensive package to quantify &lt;strong&gt;chaos&lt;/strong&gt;, &lt;strong&gt;entropy&lt;/strong&gt; and &lt;strong&gt;fractal dimension&lt;/strong&gt; of signals.&lt;/li&gt;
&lt;li&gt;Tons of other improvements and fixes ☺️&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once again, a big thanks to all the &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit/releases/tag/v0.2.0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;contributors&lt;/a&gt; for their help in making NeuroKit an awesome open-source software for physiological signal processing!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Podcast &#39;Learn Bayesian Stats&#39; with Dominique Makowski</title>
      <link>https://realitybending.github.io/post/2022-02-01-learnbayesstats/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2022-02-01-learnbayesstats/</guid>
      <description>&lt;h2 id=&#34;the-learning-bayesian-statistics-podcast&#34;&gt;The &amp;lsquo;Learning Bayesian Statistics&amp;rsquo; Podcast&lt;/h2&gt;
&lt;p&gt;I had the chance of being invited to talk about R, Python, Reality Bending and much more! It was my first experience of that kind, so thanks a ton to the host of the podcast &lt;a href=&#34;https://twitter.com/alex_andorra&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alex Andorra&lt;/a&gt;. Listen to it here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.learnbayesstats.com/episode/55-neuropsychology-illusions-bending-reality-dominique-makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.learnbayesstats.com/episode/55-neuropsychology-illusions-bending-reality-dominique-makowski&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>We&#39;re recruiting a Research Assistant!</title>
      <link>https://realitybending.github.io/post/2021-12-01-recruiting_nice/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2021-12-01-recruiting_nice/</guid>
      <description>&lt;h2 id=&#34;were-recruiting-a-research-assistant&#34;&gt;We&amp;rsquo;re recruiting a Research Assistant!&lt;/h2&gt;
&lt;p&gt;In the context of a new collaboration between Nanyang Technological University (NTU Singapore) and Future Cities Laboratory, &lt;a href=&#34;https://dominiquemakowski.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;myself&lt;/a&gt; and &lt;a href=&#34;https://fcl.ethz.ch/people/Module-Lead/PanagiotisMavros.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Panos Mavros&lt;/a&gt; are recruiting a Research Assistant in psychology/neuroscience (bachelor/master) to contribute to an exciting new research project that combines a neuroscientific approach to studying the interaction between beauty and the perception of urban spaces.&lt;/p&gt;
&lt;p&gt;Perfect for psychology graduates interested in joining a cool team and learning skills like EEG, physiological techniques, advanced statistics and more!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply through &lt;a href=&#34;https://ntu.wd3.myworkdayjobs.com/en-US/Careers/job/NTU-Main-Campus-Singapore/Research-Assistant--Psychology-_R00008329&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;this portal&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More &lt;a href=&#34;https://fcl.ethz.ch/research/research-projects/NICE.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;info here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Parametric Framework to Generate Visual Illusions Using Python</title>
      <link>https://realitybending.github.io/publication/makowski2021parametric/</link>
      <pubDate>Mon, 29 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2021parametric/</guid>
      <description></description>
    </item>
    
    <item>
      <title>&#34;Your sample is too small&#34;: How to Answer to Reviewers</title>
      <link>https://realitybending.github.io/post/2021-11-05-sample-too-small/</link>
      <pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2021-11-05-sample-too-small/</guid>
      <description>&lt;h1 id=&#34;your-sample-is-too-small-how-to-answer-to-reviewers&#34;&gt;&amp;ldquo;Your sample is too small&amp;rdquo;: How to Answer to Reviewers&lt;/h1&gt;
&lt;p&gt;Reviewers questioning the statistical power of a study, while often valid, is common and unoriginal. The problem of possible lack of power, and thus possible false positives, can also be combined with the desire for stringent &lt;strong&gt;multiple comparisons / tests&lt;/strong&gt; &amp;ldquo;corrections&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;In many real-life scenarios, we simply cannot increase the sample size (because of money, time, COVID or any other reason). And sometimes, the many tests / comparisons are all needed as we have many hypotheses or variables. Naturally, the best &lt;strong&gt;pre-study&lt;/strong&gt; weapon against power-related issues are &lt;strong&gt;preregistration&lt;/strong&gt; (and registered-reports) with proper &lt;strong&gt;power-analysis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;That being said, imagine that for one reason or another we don&amp;rsquo;t have that. We cannot recruit more participants and have to deal with the data that what we have. &lt;strong&gt;What can we do?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some useful tips can be grouped and referred to as &lt;strong&gt;PoSCA&lt;/strong&gt; (Power, Stringency, Coherence, Acknowledgment):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Po&lt;/strong&gt;wer: Don&amp;rsquo;t waste power
&lt;ul&gt;
&lt;li&gt;Use all the information that you have. In particular, the information &lt;em&gt;within&lt;/em&gt; participants (if you have multiple trials per participant, don&amp;rsquo;t average over them!), by using methods such as &lt;strong&gt;mixed-models&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;S&lt;/strong&gt;tringent significance
&lt;ul&gt;
&lt;li&gt;Increase the significance threshold, either arbitrarily (e.g., lower the &lt;em&gt;p&lt;/em&gt;-value threshold to .005; Ioannidis, 2018) or pseudo-arbitrarily (using multiple-comparisons corrections such as the Bonferroni method). This, under the Bayesian framework, is &lt;sub&gt;(somewhat)&lt;/sub&gt; equivalent to being more script with whatever indices that we use. For instance, consider only Bayes Factors (BF) &amp;gt; 30 instead of 10, or &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/guidelines.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Probabilities of Direction (&lt;em&gt;pd&lt;/em&gt;)&lt;/a&gt; of 99.9% instead of 97%, or widening the Region of Practical Equivalence (ROPE).&lt;/li&gt;
&lt;li&gt;Constrain the parameters towards 0. We can also make it harder for models to have parameters (i.e., &amp;ldquo;effects&amp;rdquo;) that deviate from 0. This is easy to do within the Bayesian framework by setting narrower priors centred around 0. This will naturally pull (known as &amp;ldquo;shrinkage&amp;rdquo;) the results towards 0 and is a natural way of &amp;ldquo;controlling&amp;rdquo; for false positives. Under the frequentist framework, there are methods of regularization that can introduce a bias, such as LASSO or Ridge regressions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C&lt;/strong&gt;oherence: cross-validate results
&lt;ul&gt;
&lt;li&gt;There is a need to look at the bigger picture, including non-significant and &amp;ldquo;trending&amp;rdquo; effects. Look at all the data together, and all the variables measuring related concepts: do the results go in the same direction? Are they internally coherent? Do they follow the same trend? In a small sample study, I would trust more a conclusion based on 10 tests with independent indices measuring aspects related to &amp;ldquo;depression&amp;rdquo;, all barely significant but going in the same direction, over one super-significant (but possibly cherry-picked) result interpreted as a proof of the effect of &amp;ldquo;depression&amp;rdquo; in general. In other words, don&amp;rsquo;t focus on &amp;ldquo;significant&amp;rdquo; effects and assess results in their entirety.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;cknowledgment: be honest and humble
&lt;ul&gt;
&lt;li&gt;Quantify the evidence &lt;em&gt;against&lt;/em&gt; the null hypothesis. Maybe an effect is not &amp;ldquo;significant&amp;rdquo;, but that doesn&amp;rsquo;t necessarily mean there is a lot of evidence that it has no effect either. Quantifying evidence against the null can be easily done using for instance Bayes Factors.&lt;/li&gt;
&lt;li&gt;Be honest and acknowledge the limited power of the study. Don&amp;rsquo;t try to hide it.&lt;/li&gt;
&lt;li&gt;Temper the interpretation of the results. Don&amp;rsquo;t over-interpret them if they are not super robust.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Science must be open, replicable &amp;amp; reproductible, slow, and based on methodological best-practices. But first and foremost, it must be honest.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Ioannidis, J. P. (2018). The proposal to lower P value thresholds to .005. Jama, 319(14), 1429-1430.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to share or tweet this post, or leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to sync two folders in two separate GitHub repositories</title>
      <link>https://realitybending.github.io/post/2021-10-31-sync_two_repos/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2021-10-31-sync_two_repos/</guid>
      <description>&lt;h1 id=&#34;how-to-sync-two-folders-in-two-separate-github-repositories&#34;&gt;How to sync two folders in two separate GitHub repositories&lt;/h1&gt;
&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;
&lt;p&gt;I have a personal website, stored in a GitHub repo (and hosted via GitHub pages), as well as a lab website (a &amp;ldquo;company&amp;rdquo; website, if you will). Both are fairly similar, as they are built using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;academic theme&lt;/a&gt;. Importantly, there is a blog in the company websites with posts, but I have one on my personal website too. What I would like is that &lt;strong&gt;every time I post something on my website, it gets automatically copied over to the company website.&lt;/strong&gt; So that I don&amp;rsquo;t have to manually maintain the content at two separate places.&lt;/p&gt;
&lt;h2 id=&#34;the-solution&#34;&gt;The Solution&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The first step is to go to the settings of your &lt;strong&gt;GitHub &lt;em&gt;account&lt;/em&gt;&lt;/strong&gt;, to developers settings, and to &lt;a href=&#34;https://github.com/settings/tokens&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;personal access tokens&lt;/em&gt;&lt;/a&gt;. You have to generate a token, and tick the &lt;strong&gt;repo&lt;/strong&gt; authorizations. Copy-paste the key.&lt;/li&gt;
&lt;li&gt;Go to the settings of the personal website repo (the source from which the content will be copied), to &amp;ldquo;Secrets&amp;rdquo;, and add a new secret called &amp;ldquo;API_TOKEN_GITHUB&amp;rdquo; (with the key you just copied).&lt;/li&gt;
&lt;li&gt;Create a new GitHub action workflow such as &lt;a href=&#34;https://github.com/DominiqueMakowski/DominiqueMakowski.github.io/blob/master/.github/workflows/copy_content.yml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;this one&lt;/strong&gt;&lt;/a&gt;. The things to change are the &lt;code&gt;source_file&lt;/code&gt;, &lt;code&gt;destination_repo&lt;/code&gt; and &lt;code&gt;destination_folder&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tada &amp;#x1f389; Everytime I push to my personal repo, the new content of one of the subfolder gets copied to another repo.&lt;/p&gt;
&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This is a one-way sync, so updates on the target repo won&amp;rsquo;t affect the source repo (but might get overridden!).&lt;/li&gt;
&lt;li&gt;if you want to preserve the original commit message, set &lt;code&gt;commit_message: ${{ github.event.head_commit.message }}&lt;/code&gt; &lt;sub&gt;(thanks &lt;a href=&#34;https://github.com/DominiqueMakowski/DominiqueMakowski.github.io/issues/2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@dobbelina&lt;/a&gt;)&lt;/sub&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to share or tweet this post, or leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>see: An R Package for Visualizing Statistical Models</title>
      <link>https://realitybending.github.io/publication/ludecke2021see/</link>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/ludecke2021see/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The symbolism behind the ReBeL logo</title>
      <link>https://realitybending.github.io/post/2021-06-30-logo_meaning/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2021-06-30-logo_meaning/</guid>
      <description>&lt;p&gt;The Reality Bending logo includes several references to various concepts. &lt;strong&gt;Can you try to guess them?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;#x1f447; &amp;#x1f447; &amp;#x1f447; &amp;#x1f447; &amp;#x1f447; &amp;#x1f447; &amp;#x1f447; &amp;#x1f447;&lt;/p&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;Spoiler_alert.jpg&#39; width=&#34;90%&#34; /&gt;
&lt;/figure&gt;
&lt;!-- **.**

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

**.**

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

**.**

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; --&gt;
&lt;h3 id=&#34;wizard&#34;&gt;Wizard&lt;/h3&gt;
&lt;p&gt;One of the most striking feature of the logo is the guy in the middle, which represents a wizard. It represent us, the people who delve in the science of &lt;a href=&#34;https://realitybending.github.io/post/2020-09-28-what_is_realitybending/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;reality bending&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Wizards are a powerful &lt;a href=&#34;https://susannabarlow.com/2021/03/26/understanding-the-magician-archetype/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;archetype&lt;/a&gt;, that are primarily defined through the learned ability (by seeking, studying and gathering arcane knowledge) of controlling and manipulating reality. Though many specializations and facets exist, the understanding of the true nature of the world is a core facets that binds all wizards.&lt;/p&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;gandalf.jpeg&#39; width=&#34;90%&#34; /&gt;
    &lt;figcaption&gt;the wizard Gandalf facing the forces of darkness with his light.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;!-- ### Hat --&gt;
&lt;!-- Harry potter? --&gt;
&lt;h3 id=&#34;beard&#34;&gt;Beard&lt;/h3&gt;
&lt;p&gt;In Greco-Roman antiquity, the beard was seen as the defining feature of a philosopher (see the &lt;a href=&#34;https://en.wikipedia.org/wiki/Beard#The_%22Philosopher%27s_beard%22&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Philosopher&amp;rsquo;s beard&lt;/a&gt; on wikipedia), expressing the idea that philosophy is no mere intellectual hobby but rather a way of life that, by definition, transforms every aspect of one&amp;rsquo;s behavior (including one&amp;rsquo;s shaving habits).&lt;/p&gt;
&lt;p&gt;Show me your beard and I&amp;rsquo;ll tell you what philosopher you are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cynics had long dirty beards to indicate their &lt;em&gt;&amp;ldquo;strict indifference to all external goods and social customs&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Stoics were occasionally trimming and washing their beards in accordance with their view &lt;em&gt;&amp;ldquo;that it is acceptable to prefer certain external goods so long as they are never valued above virtue&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Peripatetics took great care of their beards believing in accordance with Aristotle that &lt;em&gt;&amp;ldquo;external goods and social status were necessary for the good life together with virtue&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;beard.jpg&#39; width=&#34;33%&#34; /&gt;
    &lt;figcaption&gt;A glorious beard.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;eyepatch&#34;&gt;Eyepatch&lt;/h3&gt;
&lt;p&gt;For any mythology fan, a bearded figure with an eyepatch (or a missing eye) is known to represent &lt;a href=&#34;https://en.wikipedia.org/wiki/Odin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Odin&lt;/strong&gt;&lt;/a&gt;, the chief deity of the norse pantheon. He&amp;rsquo;s a very complex character, with a deeply ambivalent nature. One of the key moment of Odin&amp;rsquo;s story is when he sacrifices one of his eyes in return for wisdom&amp;hellip;&lt;/p&gt;
&lt;p&gt;Losing &lt;em&gt;direct sight&lt;/em&gt; of reality in return for a &lt;strong&gt;deeper knowledge&lt;/strong&gt; of reality - here is an interesting idea that we can discuss and (over)interpret with some drinks &amp;#x1f37a;&lt;/p&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;odin.jpg&#39; width=&#34;90%&#34; /&gt;
    &lt;figcaption&gt;Odin portrayed by one of my favourite actor.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;pipe&#34;&gt;Pipe&lt;/h3&gt;
&lt;p&gt;The pipe refers to the most famous painting of the surrealist René Magritte. One of the common interpretation suggests that it symbolizes the difference between the authentic thing (a real pipe) and its representation. This, we believe, is just one level that differentiates the real from the unreal&amp;hellip;&lt;/p&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;pipe.jpg&#39; width=&#34;90%&#34; /&gt;
    &lt;figcaption&gt;The Treachery of Images (Magritte, 1929).&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;smoke&#34;&gt;Smoke&lt;/h3&gt;
&lt;p&gt;The smoke takes the form of a Psi letter Ψ, which is the symbol of &lt;strong&gt;psychology&lt;/strong&gt;.&lt;/p&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;neuropsydia.png&#39; width=&#34;50%&#34; /&gt;
    &lt;figcaption&gt;The Psi within the brain, a representation of neuropsychology, and the logo of the &lt;a href=&#34;[url](https://github.com/neuropsychology/Neuropsydia.py)&#34;&gt;Neuropsydia&lt;/a&gt; software.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;the-flower&#34;&gt;The Flower&lt;/h3&gt;
&lt;!-- ### The Flower &lt;img src=&#39;Makowski_Poppy.png&#39; title = &#34;The Poppy Flower of the Coat of Arms of the Makowski Family&#34; alt = &#39;The Poppy Flower of the Coat of Arms of the Makowski Family&#39; align=&#34;right&#34; height=&#34;139&#34; /&gt; --&gt;
&lt;p&gt;The flower in the background is not just any flower. It is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Poppy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poppy flower&lt;/a&gt;, from which the seed have been used throughout history to create diverse substances to alter our perception of reality&amp;hellip;&lt;/p&gt;
&lt;p&gt;Incidentally, it is also the symbol of the &lt;em&gt;Makowski&lt;/em&gt; family (which names refers to &amp;ldquo;poppy seed&amp;rdquo; in polish).&lt;/p&gt;
&lt;figure align=&#34;center&#34;&gt;
    &lt;img src=&#39;Makowski_Poppy.png&#39; title = &#34;The Poppy Flower of the Coat of Arms of the Makowski Family&#34; alt = &#39;The Poppy Flower of the Coat of Arms of the Makowski Family&#39; width=&#34;33%&#34; /&gt;
    &lt;figcaption&gt;The Makowski&#39;s Poppy Flower.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Did you spot any more &amp;#x1f60f;? Let us know!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Heart Rate Variability in Psychology: A Review of HRV Indices and an Analysis Tutorial</title>
      <link>https://realitybending.github.io/publication/pham2021hrv/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/pham2021hrv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Structure of Deception: Validation of the Lying Profile Questionnaire</title>
      <link>https://realitybending.github.io/publication/makowski2021structure/</link>
      <pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2021structure/</guid>
      <description></description>
    </item>
    
    <item>
      <title>performance: An R Package for Assessment, Comparison and Testing of Statistical Models</title>
      <link>https://realitybending.github.io/publication/ludecke2021performance/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/ludecke2021performance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to share data analysis scripts with publications?</title>
      <link>https://realitybending.github.io/post/2021-02-10-template_results/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2021-02-10-template_results/</guid>
      <description>&lt;h1 id=&#34;how-to-share-data-analysis-scripts-with-publications&#34;&gt;How to share data analysis scripts with publications?&lt;/h1&gt;
&lt;p&gt;Including data analysis as &lt;strong&gt;Supplementary Materials&lt;/strong&gt; can be a tedious task. How can we simplify the sharing of our work? So that it can be fully appreciated, as well as evaluated, improved, worked on, in a transparent and open way?&lt;/p&gt;
&lt;h2 id=&#34;option-1-dump-the-code-in-a-word-file&#34;&gt;Option 1: Dump the code in a word file&lt;/h2&gt;
&lt;p&gt;Most publication portals don&amp;rsquo;t directly accept code scripts to be included &amp;ldquo;as is&amp;rdquo;. In other words, you cannot upload your manuscript and your &lt;code&gt;.R&lt;/code&gt; script just like that. So one option is to copy its content, paste it in a word / pdf document, and &lt;em&gt;Voilà!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But what &lt;strong&gt;if you don&amp;rsquo;t have code&lt;/strong&gt; because you use a point-and-click software? Well, you can note down all the &lt;em&gt;x,y&lt;/em&gt; coordinates of your clicks so that one can reproduce the steps and all the clicks. Just kidding, if you don&amp;rsquo;t have a script, then may god have mercy on your soul.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why is that a terrible solution?&lt;/strong&gt; Because let&amp;rsquo;s face it, unstructured code dumps are horrific. Nobody wants to read it, it does not make justice to your work, and it&amp;rsquo;s still tedious to create! You have to re-do it everytime you modify your code. And it&amp;rsquo;s even worse if you want to include all the &lt;strong&gt;outputs, figures, tables that are generated by the code&lt;/strong&gt;? Data analysis is not just the code, but everything that comes with it and that allowed you to make the conclusions that you made.&lt;/p&gt;
&lt;h2 id=&#34;option-2-use-rmarkdown&#34;&gt;Option 2: Use &lt;em&gt;Rmarkdown&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://rmarkdown.rstudio.com/lesson-1.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Rmarkdown&lt;/strong&gt;&lt;/a&gt; is a &amp;ldquo;framework&amp;rdquo; that allows you to have files (&lt;code&gt;.Rmd&lt;/code&gt;) that can contain a mix of &lt;strong&gt;text and code&lt;/strong&gt; (and not only &lt;strong&gt;R&lt;/strong&gt;, but also &lt;a href=&#34;https://rstudio.github.io/reticulate/articles/r_markdown.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/a&gt; for instance!).&lt;/p&gt;
&lt;p&gt;It can be used to write comprehensive &amp;ldquo;reports&amp;rdquo; that include all your thoughts, motivations and interpretations of the results. And the great thing about it is that these files can be &lt;strong&gt;converted&lt;/strong&gt; into beautiful and readable documents like &lt;strong&gt;PDF&lt;/strong&gt;, &lt;strong&gt;Word&lt;/strong&gt; or &lt;strong&gt;HTML&lt;/strong&gt;. It will automatically embed the code and &lt;strong&gt;its generated output&lt;/strong&gt; (as text, tables or figures) alongside the text.&lt;/p&gt;
&lt;p&gt;It is an awesome way to write statistical reports, and can even be used to create many other non-stats related stuff, like &lt;a href=&#34;http://frederikaust.com/papaja_man/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;APA-formatted manuscripts&lt;/strong&gt;&lt;/a&gt; (great for preprints), &lt;a href=&#34;https://bookdown.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;books&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://bookdown.org/yihui/rmarkdown/xaringan.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;presentation slides&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;websites or blogs&lt;/strong&gt;&lt;/a&gt;. It&amp;rsquo;s a must-have skill for every researcher.&lt;/p&gt;
&lt;p&gt;And it gets better!&lt;/p&gt;
&lt;h2 id=&#34;option-3-use-our-results-template&#34;&gt;Option 3: Use our &lt;em&gt;Results Template&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;https://dominiquemakowski.github.io/research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Reality Bending&lt;/strong&gt;&lt;/a&gt; team, we like to have our different projects and studies organized in a consistent way. We heavily use &lt;a href=&#34;https://dominiquemakowski.github.io/post/github_psychologists/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub&lt;/strong&gt;&lt;/a&gt; to store our projects and collaborate on them, and we also like the possibility of making these projects &lt;strong&gt;open&lt;/strong&gt; and &lt;strong&gt;accessible&lt;/strong&gt; (i.e., easy to discover and explore) when the time comes.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s why we came up with a &lt;strong&gt;Template folder&lt;/strong&gt; for storing the materials related to a given study, including well-organized analysis scripts. And what&amp;rsquo;s great about it is that it is setup in a way that allows you to generate multiple files format (&lt;strong&gt;word&lt;/strong&gt;, &lt;strong&gt;pdf&lt;/strong&gt;, &lt;strong&gt;html&lt;/strong&gt;) with a single click (and even without any click, in a fully automatic way)! And what&amp;rsquo;s even greater is that if you decide to upload it to GitHub, you&amp;rsquo;ll have &lt;a href=&#34;https://realitybending.github.io/TemplateResults/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;a whole website&lt;/strong&gt;&lt;/a&gt; presenting your data analysis!&lt;/p&gt;
&lt;p&gt;We use it to have reproducible analysis that we can easily share with publications. We can upload the .pdf or .docx file generated by the template as &lt;strong&gt;Supplementary Materials&lt;/strong&gt;, but we also link the &lt;a href=&#34;https://github.com/RealityBending/TemplateResults&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;URL of the online repository&lt;/strong&gt;&lt;/a&gt; of the study in the manuscript, where users can access and experience the content in the format that they prefer. &lt;strong&gt;It really improves the appeal of a study when the results are trustworthy.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;All this is easily made possible with our template. &lt;strong&gt;Check it out here:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;👉 &lt;a href=&#34;https://github.com/RealityBending/TemplateResults&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;https://github.com/RealityBending/TemplateResults&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;p&gt;☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️☝️&lt;/p&gt;
&lt;p&gt;And &lt;strong&gt;let us know what you think!&lt;/strong&gt; You can open an issue on the &lt;a href=&#34;https://github.com/RealityBending/TemplateResults/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repo&lt;/a&gt; or even contribute to help us improve it :)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeuroKit2: A Python toolbox for neurophysiological signal processing</title>
      <link>https://realitybending.github.io/publication/makowski2021neurokit/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2021neurokit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What visual agnosia might feel like</title>
      <link>https://realitybending.github.io/post/2021-01-03-visual_agnosia/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2021-01-03-visual_agnosia/</guid>
      <description>&lt;h3 id=&#34;name-one-thing-in-this-photo&#34;&gt;Name One Thing In This Photo&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Can you name &lt;em&gt;one&lt;/em&gt; thing in the image above?&lt;/strong&gt; It all looks familiar, but something is off. The image makes &amp;ldquo;sense&amp;rdquo; overall; there are well-defined shapes and objects, that seem to be placed in a plausible - albeit chaotic - fashion, like some random rubbish thrown in the corner of a room. Even the colors, the lightning, the quality, is coherent, and helps making it believable. And yet, chances are you cannot name one single element that composes it.&lt;/p&gt;
&lt;p&gt;This image, after appearing on &lt;a href=&#34;https://twitter.com/melip0ne/status/1120503955526750208?s=20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;twitter&lt;/a&gt; in April 2019, surfaced on reddit with the caption &amp;ldquo;This picture is &lt;strong&gt;designed to give the viewer the simulated experience of having a stroke&lt;/strong&gt; (particularly in the &lt;strong&gt;occipital lobe&lt;/strong&gt; of the cerebral cortex, where visual perception occurs.) &lt;strong&gt;Everything looks hauntingly familiar but you just can&amp;rsquo;t quite recognize anything&lt;/strong&gt;&amp;rdquo;, and became subsequently &lt;a href=&#34;https://www.dailymail.co.uk/news/article-6959547/Extremely-frustrating-slightly-disturbing-image-goes-viral.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;viral&lt;/a&gt;. However, the author of the caption later admitted that he made this description up.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;So where does the image come from?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One can trace back the original publication to an &lt;a href=&#34;https://youtu.be/0F7XBwFwA-M?t=104&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;instagram account&lt;/a&gt;, which author declared having made the image using &lt;a href=&#34;https://www.artbreeder.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;ArtBreeder.com&lt;/strong&gt;&lt;/a&gt;. This website gives access to an AI algorithm (Generative Adversarial Networks - GAN), commonly used in the processing and generation of images (one mindblowing example can be found on &lt;a href=&#34;https://thispersondoesnotexist.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;thispersondoesnotexist.com&lt;/em&gt;&lt;/a&gt;, which generates realistic pictures of non-existing people). There were even some attempts to &lt;em&gt;reverse engineer&lt;/em&gt; the process to retrieve what the original image could have been like.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.kym-cdn.com/photos/images/original/001/486/325/1dd.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;After all, it seems like there is no intelligent design behind this image. No clever neuropsychologist carefully crafting a meaningful experience. Just one of these lucky accident.&lt;/p&gt;
&lt;p&gt;Nonetheless, it&amp;rsquo;s still an intriguing image, falling in this uncanny abyss of things that we recognize as familiar, but slightly too alien for our sense-seeking brains to dissolve in meaning. &lt;strong&gt;Could it tell something about brain processes?&lt;/strong&gt; Surely, but &lt;strong&gt;brain disorders?&lt;/strong&gt; Maybe.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;&amp;ldquo;occipital stroke&amp;rdquo; hypothesis&lt;/strong&gt; mentioned above suggests, by its formulation, a lesion to the primary visual cortices. However, as neuroscientists know, these brain regions, located at the extreme back of the brain, are mostly supporting lower level aspects of visual processing, and their damage is usually related to alterations of a somewhat different nature than of that above, such as vision loss, visual hallucinations, visual deformations, loss of color, movement, stereoscopy, etc.&lt;/p&gt;
&lt;p&gt;However, there is another neuropsychological disorder, referred to as &lt;strong&gt;&amp;ldquo;visual agnosia&amp;rdquo;&lt;/strong&gt;, in which patients experience difficulties to recognize visually presented objects, despite preserving an intact vision. In fact, it is more an umbrella term for different subcategories of deficits, and the image above could be reminiscent of visual agnosia of the &lt;em&gt;associative&lt;/em&gt; type, which corresponds to a a specific impairment in the assignment of meaning to a stimulus that is accurately perceived (and can be visually described). This symptom is often related to injuries in the left occipito-temporal region, located on the ventral &amp;ldquo;what&amp;rdquo; stream of the brain (as opposed to the so-called &amp;ldquo;where&amp;rdquo; dorsal stream).&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2021-01-03-visual_agnosia/whatstream_hu13392854820605586268.webp 400w,
               /post/2021-01-03-visual_agnosia/whatstream_hu2779938006073146563.webp 760w,
               /post/2021-01-03-visual_agnosia/whatstream_hu16620858040961996635.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2021-01-03-visual_agnosia/whatstream_hu13392854820605586268.webp&#34;
               width=&#34;760&#34;
               height=&#34;513&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ivan-seals-art&#34;&gt;Ivan Seal&amp;rsquo;s Art&lt;/h3&gt;
&lt;p&gt;From there, the youtuber &lt;a href=&#34;https://www.youtube.com/channel/UCR6LasBpceuYUhuLToKBzvQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Solar Sands&lt;/em&gt;&lt;/a&gt; helped me discover the artist &lt;a href=&#34;https://en.wikipedia.org/wiki/Ivan_Seal&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Ivan Seal&lt;/strong&gt;&lt;/a&gt;, which work is somewhat akin to the image above. They are not purely abstract renditions, or depictions of impossible entities, but plausible objects that sit in this awkward space, deep between boring reality and total weirdness.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://rca-media.rca.ac.uk/images/dumtrimiestonmo_blurosperiod150x100_cm_-_Phot.width-1000.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.redd.it/ywee14vpk8y41.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post and don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; 🐦 &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>effectsize: Estimation of Effect Size Indices and Standardized Parameters</title>
      <link>https://realitybending.github.io/publication/benshachar2020effectsize/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/benshachar2020effectsize/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Time as a computational limit</title>
      <link>https://realitybending.github.io/post/2020-11-13-time_computational_limit/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-11-13-time_computational_limit/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note: this is a thought-experiment, not to be taken too seriously.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;we-live-in-a-simulated-universe&#34;&gt;We live in a simulated universe&lt;/h2&gt;
&lt;p&gt;In his famous simulation argument, the transhumanist Bostrom (2003, 2011) posits that &lt;strong&gt;we are living in a computer-generated reality&lt;/strong&gt;. The logic behind this assumption is that an advanced civilization, with enormous computing power, might want to create agents with a powerful artificial intelligence, that would be evolving in a simulated world (think of an infinitely more advanced &lt;em&gt;&lt;strong&gt;The Sims&lt;/strong&gt;&lt;/em&gt; Game). These sims (i.e., the virtual intelligences populating the simulation) might be endowed with consciousness, and live their lives in this world, unable to distinguish its simulated nature from the &amp;ldquo;primary&amp;rdquo; reality. Moreover, similarly to games that are running on many computers in the world, there could be an important number of these simulated worlds. Moreover, it could reach a point where a simulation could be created inside another simulation. Thus, the number of &amp;ldquo;sims&amp;rdquo; would quickly exceed the number of consciousness&amp;rsquo;s living in the primary (i.e., non-computer-generated) reality. Consequently, &lt;strong&gt;it is statistically plausible that we are, indeed, simulated &amp;ldquo;sims&amp;rdquo; living in a simulated reality&lt;/strong&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;aliens.jpg&#34; alt=&#34;aliens&#34;/&gt;
  &lt;figcaption&gt;Aliens watching episode 2020 of &#34;the Earth&#34; unfold, horrified.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;It is to note that Bostrom&amp;rsquo;s argument has been criticized, mocked, revised and updated several times. But beyond the flaws in its argumentation and premisses, it is still a fairly appealing thought experiment, and a fascinating possibility. People have been mis-representing this argument, picturing some alien species playing &lt;em&gt;&lt;strong&gt;The Sims&lt;/strong&gt;&lt;/em&gt; with us on mega computers. But albeit Bostrom indeed mostly presents it as a simulation run by other intelligent agents, &lt;strong&gt;this idea could be generalized&lt;/strong&gt;. The simulating system could take many forms, not necessarily created by an intelligent design. It just means that there&amp;rsquo;s a &amp;ldquo;thing&amp;rdquo; &lt;em&gt;(a very scientific term, I know)&lt;/em&gt; outside the universe that gives rise to it, one way of another.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What does it change for our lives?&lt;/strong&gt; Pretty much nothing. Indeed, this thrilling hypothesis is somehow irrelevant from a phenomenological and psychological perspective, for the majority of people cannot help but experience a fully deployed &lt;a href=&#34;https://dominiquemakowski.github.io/post/what_is_realitybending/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;sense of reality&lt;/strong&gt;&lt;/a&gt;. They are (normally) endowed with an intuitive feeling and belief that they are real, existing and belonging to a real world. They rarely doubt it, and even if they do so, it is mostly in a philosophical fashion, that does not entail a genuine sensation of uncertainty toward the nature of the world. This sense of reality is fascinating topic on its own (though I&amp;rsquo;m biased since its my main research topic), independent from the issue of the nature of the universe. Though we could argue that the latter opens up the possibility of tears in the objective reality (either &lt;em&gt;bugs&lt;/em&gt; of the system or ways of accessing and modifying the fabric of reality), but this &lt;em&gt;&lt;strong&gt;Matrix&lt;/strong&gt;&lt;/em&gt;-like aspect of the simulated reality hypothesis is a topic for another time.&lt;/p&gt;
&lt;p&gt;So no, the universe being a simulation, aside from being a breath-taking metaphysical consideration, changes practically nothing for our daily lives.&lt;/p&gt;
&lt;h2 id=&#34;determism&#34;&gt;Determism&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s put aside this idea of a simulated universe for now and think about determinism. I consider myself, for now, as an &lt;strong&gt;ultra-determinist&lt;/strong&gt; (I should rather say, &lt;em&gt;&amp;ldquo;the world has made me into a determinist&amp;rdquo;&lt;/em&gt;). It means that I believe that the universe is unfolding according to some causality laws (many of which are not yet fully known), and that since the origin of the universe (e.g., the Big Bang), things have been evolving according to the only one possible chain of event. Naturally, the hard version of determinism leaves no room for &lt;strong&gt;free will&lt;/strong&gt; (though the &lt;em&gt;illusion&lt;/em&gt; of free will is important) and creates some issues when it comes to responsibility (again, a topic for another time).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;determinism.jpg&#34; alt=&#34;determinism&#34;/&gt;
&lt;/figure&gt;
&lt;p&gt;Note that this position is not incompatible with a &lt;strong&gt;probabilistic view of the world&lt;/strong&gt; (I am also a rather radical Bayesianist &amp;#x1f601;). In this context, the probabilistic perspective is mostly a framework to describe uncertainty and hidden mechanisms. For instance, if I flip a coin, a probabilistic approach would be to consider that there is a 50/50 probability on the outcome. That said, if we manage to gather information on all the parameters (the starting position of the coin, the velocity and angle of the tossing, gravity, the weight distribution on the coin, its resistance to air, characteristics of air pressure, wind etc.), one could pretty much accurately predict what the outcome would be. In other words, the outcome is already &amp;ldquo;determined&amp;rdquo; once the coined has been tossed. That doesn&amp;rsquo;t mean that a probabilistic model is not convenient to describe it, especially when we don&amp;rsquo;t have access to all these parameters (or powerful enough models to integrate them).&lt;/p&gt;
&lt;p&gt;Many attempts have been made to attack determinism (and especially by people trying to defend the possibility of free will), and recent advances in physics have giving them a lot of ammunition (the most striking example being the - often misunderstood - usage of &lt;strong&gt;quantum uncertainty to explain randomness, free-will, consciousness, god&lt;/strong&gt; and pretty much everything). Nonetheless, determinism is one of the simplest assumption that can be made regarding causality and evolution.&lt;/p&gt;
&lt;h2 id=&#34;the-future-is-now&#34;&gt;The future is now&lt;/h2&gt;
&lt;p&gt;Determinism has one important consequence. As all events stem one from the others, in a unique chain of causal events, then if we know the exact state of the system (i.e., you know the state of &lt;em&gt;all&lt;/em&gt; of the variables of the system) at one point in time, as well as the rules governing the system, we can predict with certainty the system&amp;rsquo;s state at the next point in time, at &lt;em&gt;t&lt;/em&gt;+1. If we repeat the process, &lt;strong&gt;we know the state of the system at &lt;em&gt;t&lt;/em&gt;+2, and so on, until the end of times.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In other words, the end of the universe is engraved in its beginning. The future is already contained in the now. The whole evolution of the universe is already &amp;ldquo;set&amp;rdquo;. &lt;em&gt;Myself, writing this post, am an expected consequence of the combination of parameters of the universe&amp;rsquo;s origin.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://media.giphy.com/media/1zRd5ZNo0s6kLPifL1/giphy.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;time-as-a-computational-limit-of-human-understanding&#34;&gt;Time as a computational limit of human understanding&lt;/h2&gt;
&lt;p&gt;The past, and future, are merely but illusions. All the information (about what has been, and what will be) is already known (not known by an intelligent being, but in the sense that the information is existing, encapsulated within each frame of time) &lt;strong&gt;The evolution of the world is, in that regards, similar to that of a movie on a DVD&lt;/strong&gt;. All the movie is there, at once. And a computer can read, and &amp;ldquo;experience&amp;rdquo; (as far as the phenomenological experience of a computer goes) all that information at once.&lt;/p&gt;
&lt;p&gt;Yet we cannot. We have to watch it unfold over time. We are cognitively constrained in that fourth dimension of time. The perception of time passing appears as some limitation of our own cognitive systems: we have to spend one hour and a half in order to make sense of the information. We cannot process it &amp;ldquo;at once&amp;rdquo; (we cannot yet just download the movie into our brain, and experience it without watching it). &lt;strong&gt;Is time passing a feature (or limitation) of our understanding?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Could we imagine (as a thought experiment) some other forms of being that are not constrained nor ever drifting onwards in the time dimension? Which, through their immensely greater cognitive abilities, are able to process a &lt;em&gt;lot&lt;/em&gt; more information, which renders their prediction and inference of the near past and future very accurate, to a point where they are able to almost &amp;ldquo;move in time&amp;rdquo; (at least in short time ranges as the universe)&lt;/p&gt;
&lt;h2 id=&#34;time-as-a-computational-limit-of-the-cosmos&#34;&gt;Time as a computational limit of the cosmos&lt;/h2&gt;
&lt;p&gt;One thing to note is that, in the DVD analogy, the watcher is external to the content. We are not talking about Gandalf&amp;rsquo;s experience of its own movie. Which then begs the question, &lt;strong&gt;who&amp;rsquo;s watching our universe?!&lt;/strong&gt; &lt;sup&gt;&lt;sub&gt;(note that this is a logical fallacy used here as a joke; analogy is not homology).&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;https://i.pinimg.com/originals/1f/0b/70/1f0b701c4cb1db137c17182d533ea051.jpg&#34; alt=&#34;god&#34;/&gt;
  &lt;figcaption&gt;The Ancient of Days (William Blake, 1794).&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;But let&amp;rsquo;s go back to that &amp;ldquo;simulated universe&amp;rdquo; hypothesis that we started with, to try to integrate with it determinism and its consequence on time. When we play the sims, the sims do not really care about what the speed that we, external Humans, play the game. &lt;strong&gt;Their experience (albeit primitive, but you see my point) is dictated by the system&lt;/strong&gt; (the game and the computer). To what extend it can computationally process the information.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s like when playing &lt;strong&gt;Minecraft&lt;/strong&gt; (pardon my video games references). At the start of the game, one must first &amp;ldquo;generate&amp;rdquo; the world. This runs a procedural generation algorithm that spatially lays out and populates a world. This can take up to several minutes, depending on how much of a nerd you are (i.e., the specs of your computer). Following this example, if our universe is itself a simulation, could time be a consequence of some limitation of the system that &amp;ldquo;runs&amp;rdquo; it (or generates it - after all, maybe God is just waiting for our universe to complete building to be able to play his game of &amp;ldquo;Worldcraft&amp;rdquo; &lt;sub&gt;&lt;sup&gt;or, perhaps more appropriately, &amp;ldquo;Minehumans&amp;rdquo;&lt;/sub&gt;&lt;/sup&gt;), which might explain the particular nature of the time dimension in our typical environment.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;https://thumbs.gfycat.com/BiodegradableSeriousLacewing-size_restricted.gif&#34; alt=&#34;gandalf&#34;/&gt;
  &lt;figcaption&gt;&#34;Riddles in the dark...&#34;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;While these are fun thought experiments to ponder over, note that until there, I have mainly speculated about time as we phenomenologically experience it. I haven&amp;rsquo;t even touched on the possible relationship between the idea of time as a computational limit, and time as it conceived in modern theoretical physics (for instance, as a geometrical dimension of the time-space continuum that can be deformed and, potentially, navigated in). &lt;strong&gt;But for this, you&amp;rsquo;ll need to get me talking after more beers&lt;/strong&gt; &amp;#x1f37b;&lt;/p&gt;
&lt;p&gt;Cheers!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is Reality Bending?</title>
      <link>https://realitybending.github.io/post/2020-09-28-what_is_realitybending/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-09-28-what_is_realitybending/</guid>
      <description>&lt;p&gt;As you know, &lt;strong&gt;reality bending&lt;/strong&gt; is my primary research direction. However, it is not (yet) a well-established scientific topic, nor is it clearly defined. In fact, &lt;strong&gt;it is not defined at all, hence the purpose of this article&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;But what does it refer too? Is it some kind of &lt;a href=&#34;https://en.wikipedia.org/wiki/Avatar:_The_Last_Airbender&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Avatar: The Last Airbender&lt;/em&gt;&lt;/a&gt; thing? Or some &lt;a href=&#34;https://marvel-movies.fandom.com/wiki/Reality_Stone&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Avengers&lt;/em&gt;&lt;/a&gt;-style superpower? Well&amp;hellip; I sure wish it was &amp;#x1f601;&lt;/p&gt;
&lt;p&gt;Essentially, &lt;strong&gt;reality bending&lt;/strong&gt; refers to the study of the internal and external determinants of subjective reality. In other words, we seek to understand the processes that modulate our conscious experience of reality. The word &amp;ldquo;bending&amp;rdquo; encapsulates the active nature of the mechanisms at stake. Indeed, being anything but stable, our perception of reality can be quite easily influenced, whether voluntarily or not, sometimes to extreme degrees of alteration.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;DonQuixote.jpg&#34; alt=&#34;github for psychologists&#34;/&gt;
  &lt;figcaption&gt;Daumier, H. (1925), Don Quixote attacking the windmills.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Reality benders&lt;/strong&gt; seek to unravel the structure and mechanisms of the sense of reality by studying natural instances of its distortion, or by directly inducing them through a variety of means.&lt;/p&gt;
&lt;h2 id=&#34;objective-and-subjective-determinants-of-the-sense-of-reality&#34;&gt;Objective and subjective determinants of the sense of reality&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s take for example a guy watching some episode of his favourite TV show, &lt;em&gt;Friends&lt;/em&gt;. As he swiftly moves from laughing to snivelling, we can confidently say that he is fully &lt;strong&gt;immersed&lt;/strong&gt; in the show. He feels like he&amp;rsquo;s &lt;em&gt;present&lt;/em&gt; in the show, from which the fictional characters &lt;em&gt;feel&lt;/em&gt; very real: for a moment, his brain processes the perceived experience almost as if it was real.&lt;/p&gt;
&lt;p&gt;What leads to this high sense of reality? First, there are &lt;strong&gt;objective characteristics&lt;/strong&gt; of the experience (or rather, of the external source of the experience), i.e., characteristics of the environment. Here, it&amp;rsquo;s a realistic stimulus displayed on a flat screen. But one could wonder what would happen if the sensory input was richer (imagine being physically IN the show by means of some super &lt;strong&gt;virtual reality&lt;/strong&gt; setup), or poorer (the same story presented as comic strips with the characters portrayed as stick figures).&lt;/p&gt;
&lt;p&gt;However, while such manipulations could indeed be used to manipulate our immersion, there is also a &lt;strong&gt;subjective component&lt;/strong&gt; contributing to our sense of reality, related for instance to the affective response, attentional engagement, or self-relevance, that will cause a stimulus to strum unique strings in each individual, depending on his history and state of mind.&lt;/p&gt;
&lt;h2 id=&#34;tell-me-your-reality-and-ill-tell-you-who-you-are&#34;&gt;Tell me your reality and I&amp;rsquo;ll tell you who you are&lt;/h2&gt;
&lt;p&gt;The fact that the sense of reality is, in the end, a subjective experience, means that is is intrinsically connected to the Self (i.e., our physical and mental identity). As such, aside from studying how our sense of reality is influenced by external and internal factors, but also investigate the reverse relationship, i.e., &lt;strong&gt;how the variability of our sense of reality can inform us about oneself&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Note that, although the focus is the subjective aspect of reality, it doesn&amp;rsquo;t mean that we deny the existence, or downplay the importance, of objective reality. Stating that most of our experience is &amp;ldquo;made-up&amp;rdquo; (i.e., is a construction of the brain) does not equate absolute relativism (more on that in another post). Objective truths and facts do exist, and are essential to seek.&lt;/p&gt;
&lt;h2 id=&#34;altered-states-of-consciousness&#34;&gt;Altered states of consciousness&lt;/h2&gt;
&lt;p&gt;Naturally, states in which our sense of reality is distorted (as compared to the consensual collective experience) are of particular interest as models or study-cases of our ideas and theories. They include long-term affections (e.g., neuropsychiatric disorders such as schizophrenia) or transcient states (induced by psychoactive substances or specific practices like meditation and trance).&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt; &amp;#x1f917;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to extract individual scores from repeated measures</title>
      <link>https://realitybending.github.io/post/2020-09-14-individual_scores/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-09-14-individual_scores/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Many psychology fields require to extract individual scores, i.e., point-estimates (&lt;em&gt;i.e.&lt;/em&gt;, a single value) for a participant/patient, to be used as an index of something and later interpreted or re-used in further statistical analyses. This single index is often derived from several &amp;ldquo;trials&amp;rdquo;. For instance, the reaction times in the condition A (let&amp;rsquo;s say, the baseline) will be &lt;strong&gt;averaged&lt;/strong&gt; together, and the same will be done with the condition B. Finally, the difference between these two means will be used an the &lt;strong&gt;individual score&lt;/strong&gt; for a given participant.&lt;/p&gt;
&lt;p&gt;However, we can intuitively feel that we &lt;strong&gt;lose a lot of information&lt;/strong&gt; when averaging these scores. Do we deal appropriately with the variability related to individuals, conditions, or the noise aggravated by potential outliers? This is especially important when working with a limited amount of trials.&lt;/p&gt;
&lt;p&gt;With the advent of recent computational advances, new easy-to-implement alternatives emerge. For instance, &lt;strong&gt;one can &amp;ldquo;model&amp;rdquo; the effects at an individual level&lt;/strong&gt; (e.g., the simplest case, for the two conditions paradigm described above, would be a linear regression with the condition as a unique predictor), and use the &lt;strong&gt;parameters&lt;/strong&gt; of each model as individual scores (e.g., the &amp;ldquo;slope&amp;rdquo; coefficient of the effect of the manipulation), rather than the raw mean. This opens up the possibility of including covariates and take into account other sources of known variability, which could lead to better estimates.&lt;/p&gt;
&lt;p&gt;However, individual models are also sensitive to outliers and noise. Thus, another possibility is to &lt;strong&gt;model the effects at the population level&lt;/strong&gt; and, &lt;em&gt;at the same time&lt;/em&gt;, at the individual level. This can be achieved by modelling the participants as a &lt;strong&gt;random factor in a mixed model&lt;/strong&gt;. In this case, the individual estimates might benefit from the population estimates. In other words, the effects at the population level will &amp;ldquo;constrain&amp;rdquo; or &amp;ldquo;guide&amp;rdquo; the estimation at an individual level to potentially limit extreme parameters.&lt;/p&gt;
&lt;p&gt;Unfortunately, the above method requires to have all the data at hand, to be able to fit the population model. This is often not the case in on-going acquisition, or in neuropsychological contexts, in which the practitioners simply acquire data for one patient, and have to compute individual scores, without having access to the detailed population data. Thus, an in-between alternative could make use of &lt;strong&gt;Bayesian models&lt;/strong&gt;, in which the population effects (for instance, the mean effect of the condition) could be entered as an informative &lt;strong&gt;prior&lt;/strong&gt; in the individual models to, again, &amp;ldquo;guide&amp;rdquo; the estimation at an individual level and hopefully limit the impact of noise or outliers observations.&lt;/p&gt;
&lt;p&gt;In this post, the aim is to compare these 4 methods (basic individual model - equivalent to using the raw mean, population model, individual model with informative priors) in recovering the &amp;ldquo;true&amp;rdquo; effects using a simulated dataset.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;h4 id=&#34;generate-data&#34;&gt;Generate Data&lt;/h4&gt;
&lt;p&gt;We generate several datasets in which we manipulate the number of participants, in which the score of interest is the effect of a manipulation as compared to a baseline condition. 20 trials per condition will be generated with a known &amp;ldquo;true&amp;rdquo; effect (the centre of the distribution from which the data is generated). Gaussian noise of varying standard deviation will be added to create a natural variability (See the functions&amp;rsquo; definition below).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tidyverse&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;easystats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;individual.png&#34; alt=&#34;*Example of a dataset containing 20 participants (shown with different colors). As can be seen, we introduced modulations in the inter- and intra- individual variability.*&#34; width=&#34;1575&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 1: *Example of a dataset containing 20 participants (shown with different colors). As can be seen, we introduced modulations in the inter- and intra- individual variability.*&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We will then compare the scores obtained by each method to the &amp;ldquo;true&amp;rdquo; score of each participant by substracting them from one another. As such, for each method, we obtain the absolute &amp;ldquo;distance&amp;rdquo; from the true score.&lt;/p&gt;
&lt;h4 id=&#34;fit-model&#34;&gt;Fit model&lt;/h4&gt;
&lt;p&gt;Contrast analysis will be applied to compare the different methods together.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Diff_Abs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;modelbased&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;estimate_contrasts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;arrange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difference&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;n&#34;&gt;Level2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Level2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Difference&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI_low&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI_high&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## Level1                 |                 Level2 | Difference |            CI |      p
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## -------------------------------------------------------------------------------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## IndividualModel_Priors |        PopulationModel |  -1.85e-03 | [-0.01, 0.01] | &amp;gt; .999
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## IndividualModel_Freq   |        PopulationModel |   1.70e-03 | [-0.01, 0.01] | &amp;gt; .999
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## IndividualModel_Freq   | IndividualModel_Priors |   3.55e-03 | [-0.01, 0.01] | &amp;gt; .999
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;visualize-the-results&#34;&gt;Visualize the results&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;*Average accuracy of the different methods (the closest to 0 the better).*&#34; width=&#34;2250&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 2: *Average accuracy of the different methods (the closest to 0 the better).*&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;n_participants.png&#34; alt=&#34;*Accuracy depending on the number of total participants in the dataset.*&#34; width=&#34;2250&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 3: *Accuracy depending on the number of total participants in the dataset.*&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Though not significantly different, it seems that &lt;strong&gt;raw basic estimates&lt;/strong&gt; (that rely only on the individual data) &lt;strong&gt;perform consistently worse than the population model or individual models informed by priors&lt;/strong&gt;, especially for small datasets (between 10 and 100 participants) - though again, the difference is tiny in our simulated dataset. In the absence of the whole population dataset, it seems that using individual Bayesian model with informative priors (derived from the population model) is a safe alternative.&lt;/p&gt;
&lt;h3 id=&#34;functions&#34;&gt;Functions&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tidyverse&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;easystats&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rstanarm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ggdist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Get data ----------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;get_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;scores_baseline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;scores_condition&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;variances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbeta&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;variances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;variances&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;variances&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Rescale&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;noise_sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;abs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scores_baseline[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;variances[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scores_condition[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;variances[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise_sd[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Add noise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;noise_sd[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Add noise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;s&#34;&gt;&amp;#34;Participant&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sprintf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;S%02d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;s&#34;&gt;&amp;#34;Y&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;s&#34;&gt;&amp;#34;Score_True&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scores_baseline[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scores_condition[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;each&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;s&#34;&gt;&amp;#34;Condition&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Baseline&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Manipulation&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;each&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Visualize data -----------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;group_by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fill&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;position&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;position_dodge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.66&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;ggdist&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;stat_eye&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point_interval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ggdist&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean_hdi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alpha&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.66&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;position&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;position_dodge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.66&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;.width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.95&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ylab&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Score&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_modern&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;legend.position&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;none&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;ggsave&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;individual.png&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;450&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Get results -------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;get_results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# Raw method ----&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;group_by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;summarise_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;rename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Score_Raw&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Y&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;arrange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;ungroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# Population model ----&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lme4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;lmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;fixed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;insight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;get_parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effects&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;fixed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Estimate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;random&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;insight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;get_parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;effects&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;random&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# Transform coefs into scores&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;pop_baseline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fixed[1]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;pop_manipulation&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pop_baseline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fixed[2]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Score_PopulationModel&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pop_baseline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pop_manipulation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# Individual model ----&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;individual_model_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;participant&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Print progress&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data[data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Frequentist&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;model1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;nopriors&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Coefficient&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Bayesian without priors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# model2 &amp;lt;- stan_glm(Y ~ Condition, data = dat, refresh = 0)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# bayes &amp;lt;- parameters::parameters(model2)$Median&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Bayesian with Priors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;model3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;stan_glm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;refresh&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;prior&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;normal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fixed[1]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;prior_intercept&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;normal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fixed[2]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;priors&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Median&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;individual_model_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;individual_model_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;Participant&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;Condition&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Baseline&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Manipulation&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;Score_IndividualModel&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nopriors[1]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nopriors[1]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nopriors[2]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# &amp;#34;Score_IndividualModel_Bayes&amp;#34; = c(bayes[1], bayes[1] + bayes[2]),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;Score_IndividualModel_Priors&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;priors[1]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;priors[1]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;priors[2]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;merge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;individual_model_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# Clean output ----&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;diff&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# Diff_Raw = Score_True - Score_Raw,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;Diff_PopulationModel&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Score_True&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Score_PopulationModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;Diff_IndividualModel&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Score_True&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Score_IndividualModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# Diff_IndividualModel_Bayes = Score_True - Score_IndividualModel_Bayes,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;Diff_IndividualModel_Priors&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Score_True&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Score_IndividualModel_Priors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;starts_with&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Diff&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;pivot_longer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;starts_with&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Diff&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names_to&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Method&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values_to&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Diff_Abs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;abs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Diff&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;diff&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Analysis ----------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;seq.int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;length.out&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_participants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_trials&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;rez&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;get_results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;group_by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Condition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;summarise_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_Participants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;as.factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Dataset&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rez&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Print progress&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# model &amp;lt;- mgcv::gam(Diff_Abs ~ Method + s(n_Participants, by = Method), data = results)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Diff_Abs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;poly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_Participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;contrasts&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;modelbased&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;estimate_contrasts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;arrange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Difference&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Level1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Level2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Level1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Level2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Difference&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI_low&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI_high&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Visualize results ---------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;modelbased&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;estimate_means&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;arrange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;levels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_pointrange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ymin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI_low&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ymax&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI_high&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_modern&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis.text.x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;element_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;angle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hjust&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_color_material&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;ggsave&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;featured.png&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;450&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;modelbased&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;estimate_relation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_Participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Predicted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_point&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_remove&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Diff_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Diff_Abs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_ribbon&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ymin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CI_low&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ymax&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CI_high&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fill&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alpha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;geom_line&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme_modern&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis.text.x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;element_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;angle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;45&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hjust&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_color_material&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;scale_fill_material&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;ggsave&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;n_participants.png&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;450&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Save results ------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;results&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;contrasts&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contrasts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;data.Rdata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;sub&gt;You can reference this post as follows:&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;- Makowski, D. (2020, September 14). How to extract individual scores from repeated measures. Retrieved from &lt;a href=&#34;https://dominiquemakowski.github.io/post/individual_scores/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://dominiquemakowski.github.io/post/individual_scores/&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;And don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is neuropsychology?</title>
      <link>https://realitybending.github.io/post/2020-09-13-what_is_neuropsychology/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-09-13-what_is_neuropsychology/</guid>
      <description>&lt;h2 id=&#34;the-place-of-neuropsychology&#34;&gt;The place of neuropsychology&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s make a simple experiment&lt;/strong&gt;. Pick one young and brilliant neuropsychologist and ask &amp;ldquo;what is neuropsychology?&amp;rdquo;. In some cases, after a few seconds of hesitation, you could hear answers like &amp;ldquo;being a neuropsychologist means doing &lt;em&gt;this&lt;/em&gt; or &lt;em&gt;that&lt;/em&gt;&amp;rdquo;. In other cases, you might come across incomplete - or even false - responses, such as &amp;ldquo;neuropsychology is a tool&amp;rdquo;, &amp;ldquo;a method&amp;rdquo;, &amp;ldquo;a paradigm&amp;rdquo;, or even worse, &amp;ldquo;a point of view&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;That does not mean that our neuropsychologist is incompetent, far from it. But formally defining our field as a whole is not an exercise that we are used to do. Indeed, &lt;strong&gt;the training in neuropsychology usually comes in a fragmented way&lt;/strong&gt;, little by little. &lt;em&gt;A bit of cognitive neuroscience here, a bit of neuropsychological syndromes there, some cognitive tests administration over here, and some cortical neuroanatomy over there&amp;hellip;&lt;/em&gt; Though we might, &lt;em&gt;in fine&lt;/em&gt;, acquire a global vision and understanding of neuropsychology, verbalizing it is seldom necessary.&lt;/p&gt;
&lt;p&gt;The definition of neuropsychology is actually quite complex to formalize, and can even be hotly debated. The jobs and positions that stem out of this field are many, and &lt;strong&gt;practitioners often tend to circumscribe neuropsychology to their own activity&lt;/strong&gt;. For instance, a neuropsychologist that mainly does cognitive rehabilitation with psychiatric patients might have quite a different vision from another that does, day after day, presurgical cognitive assessments. And that is without mentioning the neuropsychologists pursuing an academic career, or even the ones that have moved to the private sector.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;No problem&lt;/em&gt;, would argue the careful reader, &lt;em&gt;if the definitions are too narrow, let&amp;rsquo;s take more general one&lt;/em&gt;. &lt;strong&gt;It&amp;rsquo;s not that simple&lt;/strong&gt;. Indeed, neuropsychology occupies a very particular place in the network of science, as it is at &lt;strong&gt;the crossroads between social sciences, biological sciences and medical fields&lt;/strong&gt;. Giving a definition that is too large would lose its essence in the nebulous depths of neuroscience and psychology, which would be not be accurate; neuropsychologists, whether they are clinical practitioners or not, have a common training, a specific theoretical grounding, as well as a unique interpretation and analysis framework underpinned by a scientifically rigorous method. Taking these elements into account, I will attempt to give a &lt;strong&gt;simple, comprehensive and informative definition of neuropsychology&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The first axiom that we need to discuss is the notion of science. &lt;strong&gt;Is neuropsychology its &amp;ldquo;own&amp;rdquo; scientific field&lt;/strong&gt;, or is it a mere portion of another one, such as cognitive neuroscience or psychology, which differs from other specializations only through its object of interest? &lt;em&gt;&amp;ldquo;By science&amp;rdquo;&lt;/em&gt;, says Schopenhauer in his PhD thesis with a baroque title (On the Fourfold Root of the Principle of Sufficient Reason), &lt;em&gt;&amp;ldquo;we understand a system of notions, i.e. a totality of connected, as opposed to a mere aggregate of disconnected, notions.&amp;rdquo;&lt;/em&gt; This definition applies well to neuropsychology, that contains a set of theories, hypotheses, methods and proofs feeding from one another and creating a coherent ensemble. As such, neuropsychology is its own scientific discipline, although a singular one&amp;hellip;&lt;/p&gt;
&lt;p&gt;Indeed, &lt;strong&gt;what is the &amp;ldquo;bigger&amp;rdquo; box in which neuropsychology fits?&lt;/strong&gt; While neuropsychologists are often initially trained in psychology, one could argue that the focus on the brain makes it more belonging to neuroscience. Well, the organization and structure of Science is a complicated issue. However, the particularity of the topographical location of neuropsychology is quite apparent.&lt;/p&gt;
&lt;p&gt;On the one hand, neuropsychology belongs to a cluster of sciences interested a specific biological organ: the brain. As such, &lt;strong&gt;neuropsychology is an integral part of neuroscience&lt;/strong&gt;. On the other hand, neuropsychology is interested in the productions of the brain (e.g., thoughts, feelings and behaviours) with a focus on the cognitive level (analyzing things in terms of cognitive processes and mechanisms), which makes it also &lt;strong&gt;belonging to psychology&lt;/strong&gt;. Moreover, one could argue that neuropsychology, through its integration of the study of what we are biologically, and who we are mentally, has been connected to, and used as evidence in, &lt;strong&gt;philosophy of mind&lt;/strong&gt; debates (for instance, famous neuropsychological cases studied by Sacks, Ramachandran or Milner have been widely discussed by contemporary philosophers). Finally, contrary to many other domains, neuropsychology has also an applied, practical component, that can be used in clinical practice. This clinical aspect, registering &lt;strong&gt;neuropsychology withing medical fields&lt;/strong&gt;, takes multiple forms, such as assessment, diagnostic or therapeutic care, and can be used with a wide variety of patients and illnesses. These multiple facets make the wealth of &lt;strong&gt;neuropsychology, which offers an exceptional freedom of practice&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As we have seen, &lt;strong&gt;neuropsychology is located at the centre of colliding galaxies of knowledge&lt;/strong&gt;, such as neuroscience, psychology, medicine and philosophy. However, the fast development of neuropsychology is gradually leading to the creation of subcomponents within itself, corresponding to different practices and theoretical steps. And these clusters are themselves growing. For instance, clinical neuropsychology was historically focused on diagnostic cognitive assessments, but has recently expanded on the treatment-side of things, with innovations like cognitive training and rehabilitation. This underlines neuropsychology as a rapidly evolving field, moving its potential towards yet uncharted territories.&lt;/p&gt;
&lt;h2 id=&#34;the-fourfold-structure-of-neuropsychology&#34;&gt;The fourfold structure of neuropsychology&lt;/h2&gt;
&lt;p&gt;Neuropsychology is born from the convergence of &lt;strong&gt;cognitive neurology&lt;/strong&gt;, with pioneers such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Paul_Broca&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Broca&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Carl_Wernicke&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wernicke&lt;/a&gt; (which made inferences about brain functioning based on the observations of patients with brain lesions) and psychologists such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Th%C3%A9odule-Armand_Ribot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ribot&lt;/a&gt; (focusing on the organization and semiology of cognitive deficits). This history has shaped neuropsychology as a two-faced entity, with one &lt;strong&gt;experimental side&lt;/strong&gt; dedicated to understand the relationship between brain and cognition (by using pathological cases or natural variability of neurocognitive characteristics), and one &lt;strong&gt;clinical aspect&lt;/strong&gt;, focusing on bringing this knowledge to the benefit of the patients suffering from brain disorders.&lt;/p&gt;
&lt;p&gt;However, beyond these two pillars of neuropsychology, recent advances have outlined a more &lt;strong&gt;theoretical level&lt;/strong&gt; of neuropsychology, dedicated to a high-level integration of the data at hand to elaborate general theories and interfacing them with evolutionary or philosophical principles. Similarly, a &lt;strong&gt;computational&lt;/strong&gt; facet, referring to the operationalization of the functioning in statistical terms, starts to emerge as a pseudo-independent aspect, propelled by the regain of interest and focus on the methodological and statistical aspects of psychology and neuroscience.&lt;/p&gt;
&lt;p&gt;This structure is not fixed, but driven by the evolution of the field. It is possible that new poles will emerge, or differentiate over time, until maybe they separate from - or create new clusters within - neuropsychology.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;cycle.png&#34; alt=&#34;Structure of neuropsychology&#34;/&gt;
  &lt;figcaption&gt;The fourfold structure of neuropsychology.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&#34;the-definition-of-neuropsychology&#34;&gt;The definition of neuropsychology&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Neuropsychology is a theoretical and practical science investigating the relationship between 1) the structure and functioning of the brain, and 2) cognitive processes and their related derivatives, such as thoughts, feelings and behaviours.&lt;/strong&gt; It is organised in four interconnected and overlapping dimensions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Experimental neuropsychology&lt;/strong&gt; studies the variability of the brain and cognition (whether from pathological origin or not) to test theories and models through empirical experimentation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clinical neuropsychology&lt;/strong&gt; uses theories and models about mental functioning to better detect and assess disorders and deficits, leading to a precise diagnostic and an adapted treatment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Computational neuropsychology&lt;/strong&gt; transforms the data acquired through experiments and observation into logical or statistical models of mental functioning that are used to operationalize the processes at stake.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theoretical neuropsychology&lt;/strong&gt; integrates the evidence to elaborate and develop unifying theories to address fundamental questions about mental functioning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Neuropsychology is located at the crossroads between neuroscience and psychology, at the interface between theory and practice. &lt;strong&gt;Its practitioners, the neuropsychologists&lt;/strong&gt;, are bound by a specific training, by unique theoretical and historical references, and are endowed with an analysis and interpretation framework backed by a rigorous and scientific investigation methodology.&lt;/p&gt;
&lt;!-- La neuropsychologie expérimentale étudie les variabilités du cerveau et de la cognition (qu’elles soient d’origine pathologique ou non) pour tester des modèles et développer des théories sur le fonctionnement mental, visant ainsi à une meilleure compréhension de l’Homme. --&gt;
&lt;!-- La neuropsychologie clinique utilise les théories et les modèles sur le fonctionnement mental pour mieux détecter et appréhender les troubles et les déficits d’une pathologie, menant à un diagnostic précis, tout en développant et appliquant des prises en charges modernes et adaptées. --&gt;
&lt;!-- La neuropsychologie se situe au centre de la nébuleuse des neurosciences, au carrefour de la théorie et de la pratique. Ses praticiens, les neuropsychologues, sont liés par une formation commune, des bases théoriques spécifiques, un canevas d’analyse et d’interprétation sous-tendu par une méthode d’investigation rigoureuse et scientifique.  --&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Nicolas, S., &amp;amp; Murray, D. J. (1999). Théodule Ribot (1839–1916), founder of French psychology: A biographical introduction. History of Psychology, 2(4), 277.&lt;/li&gt;
&lt;li&gt;Schopenhauer, A. (1813). &lt;em&gt;On the Fourfold Root of the Principle of Sufficient Reason&lt;/em&gt;. PhD dissertation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;sub&gt;You can reference this post as follows:&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;- Makowski, D. (2020, September 13). What is Neuropsychology?. Retrieved from &lt;a href=&#34;https://dominiquemakowski.github.io/post/what_is_neuropsychology/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://dominiquemakowski.github.io/post/what_is_neuropsychology/&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Extracting, Computing and Exploring the Parameters of Statistical Models using R</title>
      <link>https://realitybending.github.io/publication/ludecke2020parameters/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/ludecke2020parameters/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Methods and Algorithms for Correlation Analysis in R</title>
      <link>https://realitybending.github.io/publication/makowski2020correlation/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2020correlation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Why psychologists should join GitHub</title>
      <link>https://realitybending.github.io/post/2020-05-27-github_psychologists/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-05-27-github_psychologists/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;Disclaimer:&lt;/strong&gt; I don&amp;rsquo;t have anything to do with GitHub, aside from being a simple user. This article is not an advertisement for it, but rather a perspective on the role of technical social networks in psychology.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I already mentioned in &lt;a href=&#34;https://dominiquemakowski.github.io/post/r_or_python/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;another post&lt;/a&gt; that &lt;strong&gt;technical aspects and skills will play an increasing role in psychology&lt;/strong&gt;. This relationship isn&amp;rsquo;t by any means new. More than a century ago, pioneering psychologists were demonstrating formidable engineering and craftsmanship skills to build new tools and apparatuses to measure what they were interested in (see for instance &lt;a href=&#34;https://dominiquemakowski.github.io/publication/nicolas2016can/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nicolas &amp;amp; Makowski, 2016&lt;/a&gt;). But years have gone by, and the digital revolution has happened. As a result, most of the &amp;ldquo;technical&amp;rdquo; aspects (a rather vague term covering everything that is not related to the semantic knowledge of psychological theories and facts) are now ultimately tied to &lt;em&gt;software&lt;/em&gt;. Critically, &lt;strong&gt;your ability to use these softwares will determine the speed and ease at which you can achieve your goals and produce high quality assignments&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As an example, during my studies, most of the statistics course was delivered through the usage of one particular software (Statistica© 🤮). At the exam, your score didn&amp;rsquo;t much depend on your understanding of what a &lt;em&gt;t&lt;/em&gt;-test is, when to use it or anything like that; but rather on your knowledge of the software, and your ability to &lt;strong&gt;click on the right buttons faster than your peers&lt;/strong&gt;. While this is an unfortunate example that can be used to criticize the reliance on tools rather than fundamental knowledge, it also tells us something about the reality of the current world. In research, the better you are for instance at data processing (which involves both the knowledge of how to navigate the software &lt;em&gt;and&lt;/em&gt; the knowledge of what to do in general), the faster you will be able to carry it out, and the less stressed you will be, resulting in a cascade of other positive outcomes (increased well-being, work-quality, productivity, opportunities, etc.).&lt;/p&gt;
&lt;p&gt;However, &lt;strong&gt;one common mistake is to delay learning&lt;/strong&gt; new stuff (especially things outside our comfort zone) until we have no choice. This is understandable given that in the short term, certain skills may not be absolutely needed (i.e., you can manage without them) and acquiring them can be a steep learning curve (which can be hard, frustrating and effortful). However, you should start investing in your technical skills as soon as possible (as the time devoted to learning will only shrink as you advance) if you don&amp;rsquo;t want to become very &lt;strong&gt;close friends with pressure, stress, hatred, frustration and despair&lt;/strong&gt;. So stay on the light side of the force and embrace the future.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;vader.jpg&#34; alt=&#34;github for psychologists&#34;/&gt;
  &lt;figcaption&gt;A psychology researcher realizing that he should have learned programming earlier.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;And it&amp;rsquo;s not just about learning to &lt;strong&gt;use&lt;/strong&gt; some software just for the sake of having things done and getting faster results. A lot of science is done &lt;em&gt;through&lt;/em&gt; software, not only &lt;em&gt;with&lt;/em&gt; them. People are actively discussing new methods, algorithms and tools that then expand like never before the possibilities of researchers. &lt;strong&gt;Flaming debates have been going on with frameworks and workflows clashing with thunderous sparks&lt;/strong&gt; (for instance, Bayesian &lt;em&gt;vs.&lt;/em&gt; frequentist statistics, ANOVAs &lt;em&gt;vs.&lt;/em&gt; (mixed) regressions, etc.), and these calls for change find echo because of developments of software, allowing initiated users to test, validate and use new methods.&lt;/p&gt;
&lt;h2 id=&#34;open-access-software&#34;&gt;Open-access software&lt;/h2&gt;
&lt;p&gt;It might not seem like it when you&amp;rsquo;re studying it at the university, but science is currently in the middle of a &lt;strong&gt;revolution&lt;/strong&gt;. A massive paradigmatic change, partly fuelled by the growth of &lt;strong&gt;open-science&lt;/strong&gt;, which covers aspects like open-access and open-source. This means, for software, that they are no longer being developed by private companies and sold for money. Instead, they are developed in a public fashion, and &lt;strong&gt;everybody is welcome to chime in and provide input, suggestions, report bugs or improve the code&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Open-source development means faster and better software, and more importantly, the creation of a &lt;strong&gt;true connection between developers and users&lt;/strong&gt;. In fact, the former are often first and foremost also the latter, meaning that in a lot of cases (at least, mine 😅), people started writing a software because they needed it for their own personal job.&lt;/p&gt;
&lt;p&gt;But the beauty lies in the fact that &lt;strong&gt;users can seemingly become developers&lt;/strong&gt; too, or &lt;strong&gt;contributors&lt;/strong&gt;, at the very least. Sometimes, users end up on a software development page to solve a bug or an issue that they encountered. From there, there can start following the developments, and getting involved. And &lt;strong&gt;not necessarily be writing code&lt;/strong&gt;. It can be by answering to other issues, helping other users, reporting bugs and typos, improving the documentation, giving ideas and suggestions, testing new features and encouraging the developers. There are so many to contribute to the development and, as a result, become an active member of the open-science community. And moreover, doing so is also a great way to learn the theoretical bits. For instance, the most efficient way of learning the complexities of EEG acquisition and processing was to follow the development of an EEG-processing software (namely, &lt;a href=&#34;https://mne.tools/stable/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;MNE-Python&lt;/em&gt;&lt;/a&gt;). Reading issues that users encountered, and replies from experts and developers, trying to understand what functions do, what are the different parameters, what are the possibilities, the limits and so on.&lt;/p&gt;
&lt;p&gt;All in all, engaging in open-source software is a great way to increase your technical expertise and get involved in the community of researchers. And who knows, you might meet cool people, create new connections, and that&amp;rsquo;s always great!&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;expectations.jpg&#34; alt=&#34;open source software expectations&#34;/&gt;
  &lt;figcaption&gt;Help making the first pane true.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&#34;software-as-a-social-network&#34;&gt;Software as a social network&lt;/h2&gt;
&lt;p&gt;Now that you&amp;rsquo;ve buckled up, ready to engage in open-source software, you might wonder; &lt;strong&gt;where does that happen?&lt;/strong&gt; Ladies and gentlemen, let me introduce &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Several years ago, when I was an undergrad student, I had to write a lot of stuff, such as for instance reports, project and theses. All of these documents went through several back and forths with supervisors, which made comments and modifications. But I was terribly afraid to remove some paragraph or sentence that I would need later on. As a result, I ended up in a hell in which my tormentors were named &lt;code&gt;project.docx&lt;/code&gt;, &lt;code&gt;project_v2.docx&lt;/code&gt;, &lt;code&gt;project_v3.docx&lt;/code&gt;, &lt;code&gt;project_v3_modifs.docx&lt;/code&gt;, &lt;code&gt;project_v3_final.docx&lt;/code&gt;, &lt;code&gt;project_v4_comments.docx&lt;/code&gt;, &lt;code&gt;project_v4_final.docx&lt;/code&gt;, &lt;code&gt;project_v4final2.docx&lt;/code&gt;, &lt;code&gt;project_v4_finalfinal.docx&lt;/code&gt;. And what if my computer broke &lt;sub&gt;&lt;sup&gt;(that was before Dropbox)&lt;/sup&gt;&lt;/sub&gt;? I could lose everything 😱&lt;/p&gt;
&lt;p&gt;This is when I heard about something called &lt;strong&gt;version control&lt;/strong&gt;. Apparently, there was a system out there that allowed you to save &lt;strong&gt;all&lt;/strong&gt; your modifications, and be able to go back at &lt;em&gt;any&lt;/em&gt; point in time. This system was called &lt;em&gt;git&lt;/em&gt;, and it was super obscure. However, I discovered that this system had a, online interface, in the form of a website, on which you can go and upload files and documents for free. This is how &lt;strong&gt;I discovered GitHub&lt;/strong&gt;. And back in the days, it was really mostly used by programmers (because the nature of code makes it very suited for &lt;em&gt;version control&lt;/em&gt;), a world I didn&amp;rsquo;t belong to.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    There several great alternatives go &lt;em&gt;GitHub&lt;/em&gt;, like &lt;em&gt;GitLab&lt;/em&gt;, &lt;em&gt;BitBucket&lt;/em&gt;, etc., that might be just as good, if not better. The reason why I&amp;rsquo;m mainly talking about &lt;em&gt;GitHub&lt;/em&gt; here is because this post is not about the intrinsic quality or features of these platforms &lt;em&gt;for developers&lt;/em&gt;, but rather as a social network. An important part of any social network is its popularity and - as of for now - &lt;em&gt;GitHub&lt;/em&gt; is the most popular.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I witnessed &lt;strong&gt;GitHub&lt;/strong&gt; growing and becoming a true &lt;em&gt;social network&lt;/em&gt;, improving its accessibility and user-friendliness. It is now more like a hub where all kinds of people gather to discuss software and technical bits, than a den for hairy geeks. There are also many users who are new to programming (e.g. researchers who are using software as a means to an end) and if you belong to this category of people, don&amp;rsquo;t underestimate your contribution to developers! Often it is such users that help developers improve user friendliness and identify code bugs (for example, when running the code on actual data sets). It is also used as a public technical portfolio, in which you can display your achievements, your projects and your interests. And while it was originally centred around programming, it has extended its audience quite a bit, and people are now using GitHub to store data (for instance the COVID-19 data), books, create websites (for instance, this website is stored on GitHub) or write scientific papers!&lt;/p&gt;
&lt;p&gt;The reason why I&amp;rsquo;m writing this is because I know all too many young researchers, grappling with some software, struggling to find help, that are too shy to just contact the developers or the community. Just jump in there, create a public issue (instead of writing an email, so that your question will benefit future users). Most of the developers will be happy to help, and glad to see their software and code actually used by others.&lt;/p&gt;
&lt;p&gt;In conclusion, go and dive into the world of open-science and open-source software, you&amp;rsquo;ll be on the right side of history. 😎&lt;/p&gt;
&lt;h2 id=&#34;what-to-do-once-youre-on-github&#34;&gt;What to do once you&amp;rsquo;re on GitHub&lt;/h2&gt;
&lt;p&gt;At the very least, the very first step is to create an account. Even if you don&amp;rsquo;t use it now, it will be useful in the future (it shows that you are interested in technical stuff, it allows you to post issues and connect to other platforms, and support developers).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Find&lt;/strong&gt; a package / software that you like. Super biased suggestions include:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/neuropsychology/NeuroKit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;NeuroKit&lt;/em&gt;&lt;/a&gt;: a Python package for Neurophysiological Signal Processing&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats/bayestestR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;bayestestR&lt;/em&gt;&lt;/a&gt;: an R package for Bayesian statistics&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats/correlation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;correlation&lt;/em&gt;&lt;/a&gt;: an R package for correlations&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats/report&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;report&lt;/em&gt;&lt;/a&gt;: an R package to report statistics&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats/effectsize&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;effectsize&lt;/em&gt;&lt;/a&gt;: an R package for effect sizes&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats/parameters&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;parameters&lt;/em&gt;&lt;/a&gt;: an R package for understanding statistical models&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats/performance&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;performance&lt;/em&gt;&lt;/a&gt;: an R package for testing how good your model is&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;strong&gt;Watch it&lt;/strong&gt;&amp;rdquo; (the button in the top-right corner), so you&amp;rsquo;ll be notified of its activity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read&lt;/strong&gt; the README file (the &amp;ldquo;front page&amp;rdquo;), check-out the issues, understand how to navigate the repository&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engage&lt;/strong&gt; with the developers, create an issue to report bugs or problems, or just to express support - developing a software takes time and effort, and is often done out of passion and for free. Words of encouragement are always appreciated 🤗&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; your own &lt;a href=&#34;https://guides.github.com/activities/hello-world/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;repository&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Make&lt;/strong&gt; your own &lt;a href=&#34;https://pages.github.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;website&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And if you want to learn how to use &lt;strong&gt;GitHub&lt;/strong&gt; to make contributions, check-out our &lt;a href=&#34;https://neurokit2.readthedocs.io/en/latest/tutorials/contributing.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;tutorial&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Let me know if I forgot something by adding a comment below&lt;/em&gt; 👇&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>In Medio Stat Virtus: intermediate levels of mind wandering improve episodic memory encoding in a virtual environment</title>
      <link>https://realitybending.github.io/publication/blonde2020medio/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/blonde2020medio/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R or Python for Psychologists</title>
      <link>https://realitybending.github.io/post/2020-05-22-r_or_python/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-05-22-r_or_python/</guid>
      <description>&lt;p&gt;Many psychology students or researchers are faced with the challenge - &lt;em&gt;or the opportunity&lt;/em&gt; - of learning a programming language. &lt;strong&gt;Which one should you learn?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As an ex- psych student and a daily user and developer of some of them, here&amp;rsquo;s my take on this hot debate.&lt;/p&gt;
&lt;h2 id=&#34;what-has-programming-to-do-with-psychology&#34;&gt;What has programming to do with psychology?&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re a very young psychology student, or a future one, you might wonder: &lt;strong&gt;why the heck would I have to learn programming in psychology?&lt;/strong&gt; &lt;em&gt;&amp;ldquo;Psychology is kinda like philosophy, it&amp;rsquo;s just learning how people&amp;rsquo;s minds work by reading books and overthinking stuff&amp;rdquo;&lt;/em&gt;. If you still think that, you&amp;rsquo;re in for &lt;strong&gt;one hell of a ride&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;Psychology is, since its very beginning, a hard and experimental science. The founding fathers of psychology were dedicated to find ways to objectively &lt;em&gt;measure&lt;/em&gt; psychological phenomena and uncovering the mathematical laws that govern Human behaviour (one of the fields of psychology is even called psycho&lt;em&gt;physics&lt;/em&gt;). True, this &lt;em&gt;sciency&lt;/em&gt; nature has been toned down by the booming popularity of &lt;strong&gt;pseudo-scientific approaches like psychoanalysis&lt;/strong&gt; throughout the 20th century, that contributed to the stereotypical public image of the shrink doodling while listening to a neurotic patient. But that&amp;rsquo;s a distorted and old-fashioned view, not really representative of the future of psychology.&lt;/p&gt;
&lt;p&gt;The fact is that psychology is very closely connected with &lt;strong&gt;statistics&lt;/strong&gt;. Many great statistical advances were made by psychologists, and all true psychological discoveries are backed by statistical findings. And this importance of statistics is - and will be - growing further, partly due to the recent realization of some major issues in the field due to improper statistical procedures (coined the &amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/Replication_crisis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;replicability crisis&lt;/strong&gt;&lt;/a&gt;&amp;rdquo;). Moreover, psychology is more and more relying on advanced data-acquiring methods (smartphone apps, website behaviour data, online surveys, physiological and brain recording devices like EEG, MRI, etc.). And these new formats often require specialized knowledge (web-scraping, database querying, neuroimaging, signal processing, machine learning, &amp;hellip;). &lt;em&gt;And with great data-power comes great data-analysis-responsibilities&lt;/em&gt;. Even in the most applied kind of &lt;strong&gt;clinical&lt;/strong&gt; or &lt;strong&gt;psychotherapeutic&lt;/strong&gt; specializations, where you&amp;rsquo;d think you&amp;rsquo;d be safe, they are starting to use data intensive methods like neuro-feedback, virtual reality, experience sampling, and other forms of smartphone sensing and surveying.&lt;/p&gt;
&lt;p&gt;Long story short, no matter which branch of psychology you specialize in, you &lt;em&gt;will&lt;/em&gt; be confronted with some technical aspects that won&amp;rsquo;t be able to solve with &lt;em&gt;Excel&lt;/em&gt;. Moreover, these technical skills are the ones that will make the most difference between students, and that will matter a lot if you want to pursue research or want to go work in the private sector. The golden era where people were recruited in research based on their theoretical expertise is over: technical skills are now the golden ticket to enter - &lt;em&gt;and successfully leave&lt;/em&gt; - academia.&lt;/p&gt;
&lt;p&gt;So, &lt;strong&gt;ready to dive into programming?&lt;/strong&gt; Fear not! It&amp;rsquo;s not that complicated. Moreover, it&amp;rsquo;s &lt;strong&gt;one of the most rewarding skill&lt;/strong&gt; you can develop. I can assure you that you won&amp;rsquo;t regret the time invested in learning it 😊&lt;/p&gt;
&lt;p&gt;But where should you start?&lt;/p&gt;
&lt;h2 id=&#34;learn-both-r-and-python&#34;&gt;Learn both R and Python&lt;/h2&gt;
&lt;p&gt;This increasing relationship between psychology and statistics on the one hand, and other more general technical aspects on the other, is the reason why R and Python are so popular in psychology. Both languages are &lt;strong&gt;free&lt;/strong&gt;, &lt;strong&gt;open-source&lt;/strong&gt;, suited for &lt;strong&gt;beginners&lt;/strong&gt;, and have a large base of users with a ton of &lt;strong&gt;learning material&lt;/strong&gt; online. What&amp;rsquo;s the difference between them?&lt;/p&gt;
&lt;p&gt;Put simply, &lt;strong&gt;R is for statistics, Python is for the rest&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So why is there a virulent debate going on, and a choice to make? It&amp;rsquo;s true that I, &lt;em&gt;in theory&lt;/em&gt;, would agree with some popular recommandations and suggest &lt;strong&gt;learning both&lt;/strong&gt;, as they are complementary and have their own strengths and weaknesses. I myself use both on a daily basis, so why would preach what I practice?&lt;/p&gt;
&lt;p&gt;That said, many opinionated people are also arguing in favour of one &lt;strong&gt;or&lt;/strong&gt; the other (usually the only one they know&amp;hellip;) will say that learning both is essentially a waste of time. They will put forth a strong argument: &lt;strong&gt;you can do whatever you do in R in Python, and &lt;em&gt;vice-versa&lt;/em&gt;&lt;/strong&gt;. In other words, both languages can be used to achieve your goals, so it&amp;rsquo;s &lt;strong&gt;better to specialize in one than have a limited knowledge of both&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Although I do not agree with that statement, I do acknowledge that people have limited time and resources to learn. Saying &lt;strong&gt;&amp;ldquo;just learn both&amp;rdquo;&lt;/strong&gt; is easy, but is arguably an unrealistic expectation for the vast majority of people. So why learning both can be a long-term goal (especially if you want to do research), you have to start somewhere. So, &lt;strong&gt;what starter language should you select?&lt;/strong&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;pokemon.png&#34; alt=&#34;r or python&#34;/&gt;
  &lt;figcaption&gt;Ash choosing his starter programming language. He has the choice between R, Python and Bulbasaur, i.e, Matlab - the one that no one likes.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&#34;what-about-matlab&#34;&gt;What about Matlab?&lt;/h2&gt;
&lt;p&gt;There was a time when &lt;em&gt;Matlab&lt;/em&gt; was the boss. It was used everywhere and had the best functionalities for neuroimaging, signal processing and maths. But &lt;strong&gt;that time is over&lt;/strong&gt;. Matlab is already a zombie language, which burial process will continue in the years to come. Why is it dead? Because it is &lt;strong&gt;expensive&lt;/strong&gt;, &lt;strong&gt;closed&lt;/strong&gt;, &lt;strong&gt;ugly&lt;/strong&gt;, and most importantly because the alternatives (namely R and Python) are now more powerful and featured than Matlab.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;https://media.giphy.com/media/sDOhzJBsFvjMY/giphy.gif&#34; alt=&#34;matlab&#34;/&gt;
  &lt;figcaption&gt;Agamemnon reacting to king Priam saying &#34;The city of Matlab will never be conquered&#34;.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The truth is, there are only two reasons people still use Matlab: &lt;strong&gt;habit&lt;/strong&gt; (it&amp;rsquo;s hard to learn a new approach if your old way of doing things still works) and &lt;strong&gt;SPM&lt;/strong&gt; (a toolbox for neuroimaging that is still - &lt;em&gt;for now&lt;/em&gt; - the leader in the field).&lt;/p&gt;
&lt;p&gt;But seriously, don&amp;rsquo;t waste time on it if you have limited resources, it&amp;rsquo;s just not worth it. You will learn an outdated tool that you won&amp;rsquo;t be able to use in another lab if they don&amp;rsquo;t agree to pay for an expensive license (unless you&amp;rsquo;re a pirate ☠️). Whereas with open and free languages like R or Python, you have access to the best tools and can use them freely everywhere. Also, it makes you a &lt;strong&gt;supporter of open-science&lt;/strong&gt;, which is good 😁.&lt;/p&gt;
&lt;h2 id=&#34;how-to-decide-between-r-and-python&#34;&gt;How to decide between R and Python&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Time has come to make a decision.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Despite what people say, &lt;strong&gt;R and Python are not equivalent&lt;/strong&gt;. You can argue as much as you want, but doing statistics and data visualization in Python is not as fast, easy and neat as it is in R. And signal processing or neuroimaging is not as powerful in R as compared to Python. Note that both languages are still growing and changing, and they are influencing themselves: for instance, many popular Python modules (e.g., &lt;strong&gt;pandas&lt;/strong&gt;, &lt;strong&gt;statsmodels&lt;/strong&gt;, &lt;strong&gt;seaborn&lt;/strong&gt;, &amp;hellip;) have been directly inspired by R. As such, the boundaries between the two languages are fading (and I&amp;rsquo;m not even mentioning the great advances in interoperability, with tools like &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;reticulate&lt;/strong&gt;&lt;/a&gt; that allow you to use one language directly inside the other).&lt;/p&gt;
&lt;p&gt;That being said, Python and R remain very different languages at their core, with a different feel and vibe to it. R was made by statisticians for statistics, and the majority of its users are academics and researchers. On the contrary, Python is a true general-purpose &amp;ldquo;programming&amp;rdquo; language, widely used outside of academia, in the private sector.&lt;/p&gt;
&lt;p&gt;Here are some things to consider when deciding on what language to learn:&lt;/p&gt;
&lt;h3 id=&#34;reasons-to-choose-python&#34;&gt;Reasons to choose Python&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You have some basic knowledge or familiarity with programming&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For instance, you know what a &lt;em&gt;logical loop&lt;/em&gt; is. Python being a true programming language, having any prior experience will be useful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You are good with logic and spatial representation (like imagining shapes in 3D, rotating them, etc.)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In Python, you will have to think with a &amp;ldquo;programming&amp;rdquo; mindset. That means perceiving things in terms of logical statements and blocks, understanding data as 2D or 3D tables that you have to slice and recombine.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You are comfortable with maths&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In Python, numbers and numbers combinations are used a lot. Paradoxically, you will typically see a lot more maths in Python than in R.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You plan to do signal processing or experimental tasks creation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are some of the domains where Python is well-established (which doesn&amp;rsquo;t mean that R doesn&amp;rsquo;t have some great tools in development).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You are good at googling and don&amp;rsquo;t mind spending time looking for the right answer&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Python has so much material online that it&amp;rsquo;s sometimes hard to find the appropriate thing. Harder than in R, in my opinion, which has more well-defined &amp;ldquo;gold-standard&amp;rdquo; textbooks and tutorials.&lt;/p&gt;
&lt;h3 id=&#34;reasons-to-choose-r&#34;&gt;Reasons to choose R&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You have no experience with programming whatsoever&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R is not made to be used as a traditional &lt;em&gt;programming&lt;/em&gt; language. It&amp;rsquo;s more of finding what functions to apply to what, and that makes it easy for beginners.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You are interested in statistical analyses, modelling things, and making inferences from data&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R excels at this. You can create powerful models super easily and jump into their understanding and interpretation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You like making nice figures and plots&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R, through the &lt;a href=&#34;https://ggplot2.tidyverse.org/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;ggplot&lt;/strong&gt;&lt;/a&gt; ecosystem, has hands down the best tools for visualization. Your imagination is the limit, and you can even create art (check-out the artworks by &lt;a href=&#34;https://www.data-imaginist.com/art&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Lin Pedersen&lt;/a&gt; and &lt;a href=&#34;https://art.djnavarro.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Danielle Navarro&lt;/a&gt; 😍).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You are &lt;em&gt;not&lt;/em&gt; so good with stats or maths&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You heard it right! To start with R you don&amp;rsquo;t need to know stats or maths like a boss. R, in fact, will help you to become proficient at it, by slowly opening more and more layers of complexity to you, if you are deemed worthy.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;You are interested in joining the academic community&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because most of its users are academics, R has a fantastic community online, for instance on &lt;a href=&#34;https://twitter.com/hashtag/rstats&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Twitter #rstats&lt;/strong&gt;&lt;/a&gt;. It&amp;rsquo;s also super inclusive (e.g., the &lt;a href=&#34;https://rladies.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R-Ladies&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&#34;other-considerations&#34;&gt;Other considerations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What your peers are learning&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s easier to learn together, so try to discuss it with your class or lab mates if you can.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What your lab is using&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It might be easier if you have mentors that can understand what you are doing and guide you. But that should not be a priority, as it can lead to &lt;a href=&#34;https://en.wikipedia.org/wiki/Cargo_cult&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cargo cult&lt;/a&gt;-like old habits reproduction (especially if your lab has a tradition of Matlab 🤭). Instead of submitting to the tradition, assess what the goals and objectives are, and pick the best tool to achieve them. And if you have any issue convincing your boss / supervisor about it, ask some help on Twitter, I bet you&amp;rsquo;ll get a lot of it.&lt;/p&gt;
&lt;h2 id=&#34;see-also&#34;&gt;See Also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/matloff/R-vs.-Python-for-Data-Science&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R vs. Python for Data Science&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hands-on&#34;&gt;Hands on!&lt;/h2&gt;
&lt;p&gt;👉 Looking for places to start? Check out this &lt;a href=&#34;https://neurokit2.readthedocs.io/en/latest/tutorials/learnpython.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;10-min crash course introduction to Python&lt;/strong&gt;&lt;/a&gt; and this &lt;a href=&#34;https://easystats.github.io/blog/resources/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;collection of resources for R&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt; 🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; (&lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;) &lt;em&gt;and leave a comment below&lt;/em&gt; 👇&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to correctly analyze reaction time (RT) data</title>
      <link>https://realitybending.github.io/post/2020-05-18-analyze_rt/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-05-18-analyze_rt/</guid>
      <description>&lt;p&gt;This is a very, very important topic given the widespread usage of reaction times in psychology. Most of the time, we analyze it as a regular variable, using traditional models such as &lt;em&gt;linear models&lt;/em&gt;, &lt;em&gt;ANOVAs&lt;/em&gt; etc. The problem is that these models &lt;strong&gt;assume that the RT is normally distributed, which is false&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This leads us to adjustements like &lt;strong&gt;outliers removal&lt;/strong&gt; or &lt;strong&gt;log-transformation&lt;/strong&gt;, distorting the data because of our non-appropriate models.&lt;/p&gt;
&lt;p&gt;The good news is, it&amp;rsquo;s very easy to use better models, that account for the non-normal distribution of RT. And these alternatives are beautifully presented by &lt;a href=&#34;https://vbn.aau.dk/da/persons/117060&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonas K. Lindeløv&lt;/a&gt; in the guide below:&lt;/p&gt;
&lt;p&gt;👉 &lt;a href=&#34;https://lindeloev.github.io/shiny-rt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Reaction time distributions: an interactive overview&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;p&gt;It is a must-read for all psychologist. Do check-it out!!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;And don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>One Python code line for a Mandelbrot fractal</title>
      <link>https://realitybending.github.io/post/2020-05-16-python_mandelbrot/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-05-16-python_mandelbrot/</guid>
      <description>&lt;h2 id=&#34;mandelbrot-set&#34;&gt;Mandelbrot Set&lt;/h2&gt;
&lt;p&gt;I wrote a small Python function to easily generate and plot a &lt;a href=&#34;https://en.wikipedia.org/wiki/Mandelbrot_set&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mandelbrot set&lt;/a&gt;. This function is now available through the &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit#quick-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;NeuroKit2 package&lt;/strong&gt;&lt;/a&gt;, and can be used as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;neurokit2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nk&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fractal_mandelbrot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The Mandelbrot set is defined in the between &lt;code&gt;-2&lt;/code&gt; and &lt;code&gt;2&lt;/code&gt; on the &lt;em&gt;x&lt;/em&gt; (real) and &lt;em&gt;y&lt;/em&gt; (imaginary) axes. Following that, the image can be cropped accodingly by changing the coordinates. Moreover, the colors can be tweaked by changing the the colormap (&lt;code&gt;cmap&lt;/code&gt;).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fractal_mandelbrot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;real_range&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.75&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imaginary_range&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imshow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cmap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;viridis&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;off&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;buddhabrot-set&#34;&gt;Buddhabrot Set&lt;/h2&gt;
&lt;p&gt;It is also possible to generate a &lt;a href=&#34;https://en.wikipedia.org/wiki/Buddhabrot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Buddhabrot&lt;/strong&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fractal_mandelbrot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          &lt;span class=&#34;n&#34;&gt;real_range&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.75&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imaginary_range&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          &lt;span class=&#34;n&#34;&gt;buddha&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iterations&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imshow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cmap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gray&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;off&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Added the option to return a so-called &amp;#39;Buddhabrot&amp;#39;🧘 Amazing to see these shapes emerging from such a simple formula 🤯 &lt;a href=&#34;https://twitter.com/hashtag/fractalart?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#fractalart&lt;/a&gt; &lt;a href=&#34;https://t.co/7nzxsvQa6R&#34;&gt;pic.twitter.com/7nzxsvQa6R&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dominique Makowski 🧙 (@Dom_Makowski) &lt;a href=&#34;https://twitter.com/Dom_Makowski/status/1258376273451053056?ref_src=twsrc%5Etfw&#34;&gt;May 7, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Althoug the NeuroKit Python package is primarily devoted at physiological signal processing, in also includes tons of other useful features.&lt;/p&gt;
&lt;p&gt;👉 &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit#quick-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Discover more about NeuroKit here&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;p&gt;Have fun!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>In defence of the 95% CI</title>
      <link>https://realitybending.github.io/post/2020-05-15-defence_ci95/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-05-15-defence_ci95/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;BayestestR&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;currently uses a 89% threshold by default for Credible Intervals (CI). Should we change that? If so, by what?&lt;/strong&gt; &lt;a href=&#34;https://github.com/easystats/bayestestR/issues/250&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;&lt;strong&gt;Join the discussion here.&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Magical numbers, or conventional thresholds, have bad press in statistics, and there are many of them. For instance, &lt;strong&gt;.05&lt;/strong&gt; (for the &lt;em&gt;p&lt;/em&gt;-value), or the &lt;strong&gt;95%&lt;/strong&gt; range for the &lt;strong&gt;Confidence Interval&lt;/strong&gt; (CI). Indeed, why 95 and not 94 or 90?&lt;/p&gt;
&lt;p&gt;👉 &lt;a href=&#34;https://easystats.github.io/blog/posts/bayestestr_95/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Read my complete post on the easystats&amp;rsquo; blog&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Bayesian statistics with R</title>
      <link>https://realitybending.github.io/post/2020-05-14-intro_bayestestr/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2020-05-14-intro_bayestestr/</guid>
      <description>&lt;p&gt;You are a student or a researcher interested in Bayesian statistics and R? But all the tutorials and courses that you have found are too intimidating?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fear no more!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With the &lt;a href=&#34;https://github.com/easystats/easystats&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;easystats team&lt;/a&gt;, we have created a very &lt;strong&gt;gentle&lt;/strong&gt; and &lt;strong&gt;introductory&lt;/strong&gt; course for beginners.&lt;/p&gt;
&lt;p&gt;You can find the link here:&lt;/p&gt;
&lt;p&gt;👉 &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Get Started with Bayesian Statistics using R&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The impact of state and dispositional mindfulness on prospective memory: A virtual reality study</title>
      <link>https://realitybending.github.io/publication/girardeau2020impact/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/girardeau2020impact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Indices of Effect Existence and Significance in the Bayesian Framework</title>
      <link>https://realitybending.github.io/publication/makowski2019indices/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2019indices/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adaptation and Validation of a Short French Version of the Affective Style Questionnaire</title>
      <link>https://realitybending.github.io/publication/makowski2019adaptation/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2019adaptation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>bayestestR: Describing effects and their uncertainty, existence and significance within the Bayesian framework</title>
      <link>https://realitybending.github.io/publication/makowski2019bayestestr/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2019bayestestr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>insight: A Unified Interface to Access Information from Model Objects in R</title>
      <link>https://realitybending.github.io/publication/ludecke2019insight/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/ludecke2019insight/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The heart of cognitive control: Cardiac phase modulates processing speed and inhibition</title>
      <link>https://realitybending.github.io/publication/makowski2019heart/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2019heart/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Generate an articial ECG signal in Python</title>
      <link>https://realitybending.github.io/post/2019-05-17-simulate_ecg/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2019-05-17-simulate_ecg/</guid>
      <description>&lt;h1 id=&#34;create-a-natural-ecg-signal&#34;&gt;Create a natural ECG signal&lt;/h1&gt;
&lt;p&gt;Generating artificial physiological signals can be very useful to build, test your analysis pipeline or develop and validate a new algorithm.&lt;/p&gt;
&lt;p&gt;Generating a synthetic, yet realistic, ECG signal in Python can be easily achieved with the &lt;code&gt;ecg_simulate()&lt;/code&gt; function available in the &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit#quick-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;NeuroKit2&lt;/strong&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;In the example below, we will generate &lt;strong&gt;8&lt;/strong&gt; seconds of ECG, sampled at &lt;strong&gt;200 Hz&lt;/strong&gt; (i.e., 200 points per second) - hence the length of the signal will be &lt;code&gt;8 * 200 = 1600&lt;/code&gt; data points. We can also specify the average heart rate, although note that there will be some natural variability (which is a good thing, because it makes it realistic).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;neurokit2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nk&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Load the package&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ecg_simulate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;duration&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;heart_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;signal_plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Visualize the signal&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;png&#34; srcset=&#34;
               /post/2019-05-17-simulate_ecg/output_1_0_hu11787761316039790519.webp 400w,
               /post/2019-05-17-simulate_ecg/output_1_0_hu17967129268425577069.webp 760w,
               /post/2019-05-17-simulate_ecg/output_1_0_hu14732170511832305770.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2019-05-17-simulate_ecg/output_1_0_hu11787761316039790519.webp&#34;
               width=&#34;760&#34;
               height=&#34;389&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The simulation is based on the &lt;strong&gt;ECGSYN&lt;/strong&gt; algorithm (McSharry et al., 2003).&lt;/p&gt;
&lt;p&gt;However, for fast and stable results (as the realistic algorithm naturally generates some variability), one can approximate the QRS complex by a &lt;strong&gt;Daubechies&lt;/strong&gt; wavelet. An ECG based on this method can also be obtained in &lt;strong&gt;NeuroKit&lt;/strong&gt; by changing the &lt;code&gt;method&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ecg_simulate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;duration&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;method&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;daubechies&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;signal_plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;png&#34; srcset=&#34;
               /post/2019-05-17-simulate_ecg/output_2_0_hu8319302088129654127.webp 400w,
               /post/2019-05-17-simulate_ecg/output_2_0_hu11479398410743596389.webp 760w,
               /post/2019-05-17-simulate_ecg/output_2_0_hu3121488328096077602.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2019-05-17-simulate_ecg/output_2_0_hu8319302088129654127.webp&#34;
               width=&#34;760&#34;
               height=&#34;393&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;While faster and stable, the generated ECG is far from being realistic.&lt;/p&gt;
&lt;p&gt;👉 &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit#quick-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Discover more about NeuroKit here&lt;/strong&gt;&lt;/a&gt; 👈&lt;/p&gt;
&lt;p&gt;Have fun!&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;McSharry, P. E., Clifford, G. D., Tarassenko, L., &amp;amp; Smith, L. A. (2003). A dynamical model for generating synthetic electrocardiogram signals. IEEE transactions on biomedical engineering, 50(3), 289-294.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;🐦 &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dispositional mindfulness attenuates the emotional attentional blink</title>
      <link>https://realitybending.github.io/publication/makowski2019dispositional/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2019dispositional/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Phenomenal, bodily and brain correlates of fictional reappraisal as an implicit emotion regulation strategy</title>
      <link>https://realitybending.github.io/publication/makowski2019phenomenal/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2019phenomenal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The psycho Package: an Efficient and Publishing-Oriented Workflow for Psychological Science</title>
      <link>https://realitybending.github.io/publication/makowski2018psycho/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2018psycho/</guid>
      <description></description>
    </item>
    
    <item>
      <title>&#34;Being there&#34; and remembering it: Presence improves memory encoding</title>
      <link>https://realitybending.github.io/publication/makowski2017being/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2017being/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Centenaire Ribot (première partie). La réception de l&#39;oeuvre de Théodule Ribot publiée chez l’éditeur Ladrange (1870-1873)</title>
      <link>https://realitybending.github.io/publication/nicolas2017centenaire/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/nicolas2017centenaire/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How virtual embodiment affects episodic memory functioning: a proof-of-concept study</title>
      <link>https://realitybending.github.io/publication/tuena2017virtual/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/tuena2017virtual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interaction between attentional systems and episodic memory encoding: the impact of conflict on binding of information</title>
      <link>https://realitybending.github.io/publication/sperduti2017interaction/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/sperduti2017interaction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meditation and successful aging: can meditative practices counteract age-related cognitive decline?</title>
      <link>https://realitybending.github.io/publication/sperduti2017meditation/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/sperduti2017meditation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neuropsydia.py: A Python Module for Creating Experiments, Tasks and Questionnaires</title>
      <link>https://realitybending.github.io/publication/makowski2017neuropsydia/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2017neuropsydia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The distinctive role of executive functions in implicit emotion regulation</title>
      <link>https://realitybending.github.io/publication/sperduti2017distinctive/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/sperduti2017distinctive/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Can mental fatigue be measured by Weber&#39;s compass? Alfred Binet&#39;s answer on the value of aesthesiometry (tactile sensitivity) as an objective measure of mental fatigue</title>
      <link>https://realitybending.github.io/publication/nicolas2016can/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/nicolas2016can/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The paradox of fiction: Emotional response toward fiction and the modulatory role of self-relevance</title>
      <link>https://realitybending.github.io/publication/sperduti2016paradox/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/sperduti2016paradox/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The protective role of long-term meditation on the decline of the executive component of attention in aging: a preliminary cross-sectional study</title>
      <link>https://realitybending.github.io/publication/sperduti2016protective/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/sperduti2016protective/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion regulation and the cognitive decline in aging: beyond the paradox</title>
      <link>https://realitybending.github.io/publication/makowski2015emotion/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/publication/makowski2015emotion/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
