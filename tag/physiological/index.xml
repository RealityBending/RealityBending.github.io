<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Physiological | Reality Bending Lab</title>
    <link>https://realitybending.github.io/tag/physiological/</link>
      <atom:link href="https://realitybending.github.io/tag/physiological/index.xml" rel="self" type="application/rss+xml" />
    <description>Physiological</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 02 Nov 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://realitybending.github.io/media/icon_hu43f9474a7b47cfb59c41895962a4d3bc_15500_512x512_fill_lanczos_center_3.png</url>
      <title>Physiological</title>
      <link>https://realitybending.github.io/tag/physiological/</link>
    </image>
    
    <item>
      <title>Junior Research Assistant (JRA) at Sussex: is it worth it?</title>
      <link>https://realitybending.github.io/post/2024-03-12-jingjra/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2024-03-12-jingjra/</guid>
      <description>&lt;p&gt;Hi all, I am &lt;a href=&#34;https://realitybending.github.io/authors/jingxiong-xu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jing&lt;/a&gt;, and I thought I would share my experience as a Psychology Junior Research Assistant (JRA) at the University of Sussex, as many students might wonder how it is really like. Obviously, I cannot speak for all the labs, but I hope my experience can give you a general idea of what to expect.&lt;/p&gt;
&lt;p&gt;I worked as a JRA during summer 2023 at the Reality Bending Lab (ReBeL). And to put it simply, I think it was &lt;strong&gt;the most valuable experience&lt;/strong&gt; during my undergraduate journey &lt;em&gt;(PS: I have &lt;strong&gt;not&lt;/strong&gt; written this at gunpoint)&lt;/em&gt;. During these three months, I was supervised by Dr Makowski to work on a piece of original research, that thought me a lot about programming, cognitive neuropsychology, physio recordings and how real research is done. Additionally, know that it is possible to stay in the same lab next academic year, to do your final year &lt;strong&gt;dissertation with a strong head start&lt;/strong&gt; in terms of skills and knowledge.&lt;/p&gt;
&lt;img src=&#34;poster.jpg&#34; align=&#34;right&#34; width=&#34;40%&#34;&gt; 
&lt;p&gt;I had the pleasure of joining the Reality Bending Lab (ReBeL) along with &lt;a href=&#34;https://realitybending.github.io/authors/auz-moore/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Auz&lt;/a&gt;, as the first two members since the lab moved to the UK. The title of my project was &lt;strong&gt;&amp;ldquo;Exploring the Correlation between Interoception and Primal World Beliefs&amp;rdquo;&lt;/strong&gt;, which involved collecting &lt;strong&gt;physiological data&lt;/strong&gt; (e.g., heart rate, respiration, &amp;hellip;) in various tasks, analysing them, and investigating the relationship between various measures. The project started from scratch, where I learned how to use the &lt;strong&gt;JavaScript package JsPsych&lt;/strong&gt; to build the entire paradigm via coding. I also received detailed training on how to run a lab-based experiment, something I used to be worried but am now &lt;strong&gt;extremely confident about&lt;/strong&gt;. After collecting the data from 20 participants (&lt;em&gt;summer time goes by veryyyy fast!&lt;/em&gt;), I learned how to make and visualize Bayesian correlations in R. The output of this project was made into an academic poster, where I had to be creative and selective, to be presented at the poster session (see below). Additionally, we created the &lt;a href=&#34;https://github.com/RealityBending/SussexPhysioProtocol&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;&amp;ldquo;Sussex Psychophysiological Research Protocol&amp;rdquo;&lt;/em&gt;&lt;/a&gt;, a document aiming at providing guidelines for the best practices in psychophysiological research, to benefit future research done at Sussex. It might not seem like much, but it felt like doing real contributions to research, which was great!&lt;/p&gt;
&lt;p&gt;Something important I learned is, beyond pure academic excellence, research is also about community and networking. It was a great occasion to &lt;strong&gt;informally meet many researchers&lt;/strong&gt;, and make bonds with other students. What is cool is that the JRA journey doesn&amp;rsquo;t stop abruptly and continues into the next academic year, as all candidates are invited to present their work at the &lt;strong&gt;JRA conference&lt;/strong&gt; held by the university in October. This was an amazing opportunity to get a glimpse of what a scientific conference might be, feel proud about your work, connecting with fellow students, learning how to talk about research with other staff members, and gaining public speaking skills. For those who are more ambitious, why not submit your work to the national level, and present it in the British Conference for Undergraduate Research (BCUR)?&lt;/p&gt;
&lt;p&gt;In summary, I see the JRA as a golden key to open countless possibilities for your &lt;strong&gt;future career path&lt;/strong&gt;. For those considering applying to &lt;strong&gt;postgraduate studies&lt;/strong&gt; or research assistants, the strong research experience you gained will &lt;strong&gt;put you at the top of the list&lt;/strong&gt;. Even for those who decided to not do research in the future, it will still be rewarding as it gives a clear idea of what career you do not want. Don&amp;rsquo;t miss on it!&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;- Jing&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2024-03-12-jingjra/ceremony_hu52204439f5c1756e8349efd667fa6c2d_188105_7f340d8ece4b80410ae1430d18d4878e.webp 400w,
               /post/2024-03-12-jingjra/ceremony_hu52204439f5c1756e8349efd667fa6c2d_188105_b5953f80453972f87d5263d3cd069e1d.webp 760w,
               /post/2024-03-12-jingjra/ceremony_hu52204439f5c1756e8349efd667fa6c2d_188105_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2024-03-12-jingjra/ceremony_hu52204439f5c1756e8349efd667fa6c2d_188105_7f340d8ece4b80410ae1430d18d4878e.webp&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generate an articial ECG signal in Python</title>
      <link>https://realitybending.github.io/post/2019-05-17-simulate_ecg/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2019-05-17-simulate_ecg/</guid>
      <description>&lt;h1 id=&#34;create-a-natural-ecg-signal&#34;&gt;Create a natural ECG signal&lt;/h1&gt;
&lt;p&gt;Generating artificial physiological signals can be very useful to build, test your analysis pipeline or develop and validate a new algorithm.&lt;/p&gt;
&lt;p&gt;Generating a synthetic, yet realistic, ECG signal in Python can be easily achieved with the &lt;code&gt;ecg_simulate()&lt;/code&gt; function available in the &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit#quick-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;NeuroKit2&lt;/strong&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;In the example below, we will generate &lt;strong&gt;8&lt;/strong&gt; seconds of ECG, sampled at &lt;strong&gt;200 Hz&lt;/strong&gt; (i.e., 200 points per second) - hence the length of the signal will be &lt;code&gt;8 * 200 = 1600&lt;/code&gt; data points. We can also specify the average heart rate, although note that there will be some natural variability (which is a good thing, because it makes it realistic).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;neurokit2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nk&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Load the package&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ecg_simulate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;duration&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;heart_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;signal_plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Visualize the signal&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;png&#34; srcset=&#34;
               /post/2019-05-17-simulate_ecg/output_1_0_hu301c55808c524ccedc27d6987a9931d0_65591_b5ca2926495077c56fd26dba70b5d3c2.webp 400w,
               /post/2019-05-17-simulate_ecg/output_1_0_hu301c55808c524ccedc27d6987a9931d0_65591_70748bdd2eee43ebc1f6443f086cb17a.webp 760w,
               /post/2019-05-17-simulate_ecg/output_1_0_hu301c55808c524ccedc27d6987a9931d0_65591_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2019-05-17-simulate_ecg/output_1_0_hu301c55808c524ccedc27d6987a9931d0_65591_b5ca2926495077c56fd26dba70b5d3c2.webp&#34;
               width=&#34;760&#34;
               height=&#34;389&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The simulation is based on the &lt;strong&gt;ECGSYN&lt;/strong&gt; algorithm (McSharry et al., 2003).&lt;/p&gt;
&lt;p&gt;However, for fast and stable results (as the realistic algorithm naturally generates some variability), one can approximate the QRS complex by a &lt;strong&gt;Daubechies&lt;/strong&gt; wavelet. An ECG based on this method can also be obtained in &lt;strong&gt;NeuroKit&lt;/strong&gt; by changing the &lt;code&gt;method&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ecg_simulate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;duration&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;method&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;daubechies&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;nk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;signal_plot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simulated_ecg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sampling_rate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;png&#34; srcset=&#34;
               /post/2019-05-17-simulate_ecg/output_2_0_hu1de2e204eb6440421cb1558530d93b9a_48080_a708d7209ac46563378e6dcd1c4b6431.webp 400w,
               /post/2019-05-17-simulate_ecg/output_2_0_hu1de2e204eb6440421cb1558530d93b9a_48080_d4463a34939a81d13c14cf0c782b5a19.webp 760w,
               /post/2019-05-17-simulate_ecg/output_2_0_hu1de2e204eb6440421cb1558530d93b9a_48080_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://realitybending.github.io/post/2019-05-17-simulate_ecg/output_2_0_hu1de2e204eb6440421cb1558530d93b9a_48080_a708d7209ac46563378e6dcd1c4b6431.webp&#34;
               width=&#34;760&#34;
               height=&#34;393&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;While faster and stable, the generated ECG is far from being realistic.&lt;/p&gt;
&lt;p&gt;üëâ &lt;a href=&#34;https://github.com/neuropsychology/NeuroKit#quick-example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Discover more about NeuroKit here&lt;/strong&gt;&lt;/a&gt; üëà&lt;/p&gt;
&lt;p&gt;Have fun!&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;McSharry, P. E., Clifford, G. D., Tarassenko, L., &amp;amp; Smith, L. A. (2003). A dynamical model for generating synthetic electrocardiogram signals. IEEE transactions on biomedical engineering, 50(3), 289-294.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Thanks for reading! Do not hesitate to tweet and share this post, and leave a comment below&lt;/em&gt; &amp;#x1f917;&lt;/p&gt;
&lt;p&gt;üê¶ &lt;em&gt;Don&amp;rsquo;t forget to join me on Twitter&lt;/em&gt; &lt;a href=&#34;https://twitter.com/Dom_Makowski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@Dom_Makowski&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
