<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI | Reality Bending Lab</title>
    <link>https://realitybending.github.io/tag/ai/</link>
      <atom:link href="https://realitybending.github.io/tag/ai/index.xml" rel="self" type="application/rss+xml" />
    <description>AI</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 08 Sep 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://realitybending.github.io/media/icon_hu11326173534259092558.png</url>
      <title>AI</title>
      <link>https://realitybending.github.io/tag/ai/</link>
    </image>
    
    <item>
      <title>The AI Revolution in Academia, a Silver Lining for Young Scientists?</title>
      <link>https://realitybending.github.io/post/2025-09-08-airevolution/</link>
      <pubDate>Mon, 08 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-09-08-airevolution/</guid>
      <description>&lt;p&gt;For many students and early-career researchers, the rise of AI is scary. &lt;strong&gt;The very skills they are spending years learning - writing, coding, summarising - are exactly the things AI is getting frighteningly good at&lt;/strong&gt;. What, then, is the future of research careers in the age of AI?&lt;/p&gt;
&lt;p&gt;While I don&amp;rsquo;t have a full answer to that question, I do think there may be a silver lining for young scientists.
For decades, becoming an established “big shot” professor was associated with focusing on the &amp;ldquo;big ideas&amp;rdquo;, revelling in intellectual thinking and leaving the scientific grunt work to junior researchers.
Therein lied the prestige: writing opinion pieces, commentaries, critiques and reviews. &lt;strong&gt;The glamour was in thinking, not doing.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In a fascinating twist, the rise of AI may disrupt this landscape. If AI excels at one thing, it is &lt;em&gt;precisely&lt;/em&gt; writing, reviewing and summarising evidence, interpreting findings, and even formulating new hypotheses or planning experiments.
What AI still cannot do, however, is roll up its sleeves and gather real-world data - &lt;strong&gt;the true backbone of empirical science&lt;/strong&gt;&lt;sup&gt;1&lt;/sup&gt;. It can&amp;rsquo;t (yet) run studies, recruit participants, set up experiments, organise data management, or wrestle with messy datasets.&lt;/p&gt;
&lt;p&gt;The centre of gravity in science may thus shift towards &lt;strong&gt;those who can &lt;em&gt;do&lt;/em&gt;&lt;/strong&gt;: Hands-on scientists, who might once have been relegated to the shadows, could see their skills and contributions gain new recognition.
We may see less pressure to write endless papers and grants, and more emphasis on how the science was actually done: how data was collected, preprocessed, managed, and made accessible.
Perhaps the introduction, discussion, and &amp;ldquo;key takeaways&amp;rdquo; sections of papers will become somewhat less important, while methods, results, and limitations gain greater prominence, allowing for more nuance and granularity&lt;sup&gt;2&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Whether this shift will make science better or worse is unclear. And that &amp;ldquo;silver lining&amp;rdquo; might end up as a &amp;ldquo;glorification of the grind&amp;rdquo; and a devaluation of the intellectual aspects of research, devolving the job of &amp;ldquo;Researcher&amp;rdquo; into technician work.
But it might also reshape the academic landscape in a way that proves beneficial for young researchers and those who enjoy the practical aspects of research.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; Of note is following the &amp;ldquo;replication crisis&amp;rdquo; in psychology, a lot of voices have called for &amp;ldquo;more theory&amp;rdquo; and more &amp;ldquo;theorically-grounded research&amp;rdquo; (with the goal of cutting some of the nonsense out there). While theories are critical to guide data collection and interpretation, it is still the hard evidence that ultimately is the foundation of scientific knowledge.&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; One of the pervasive issue is that Humans have limited &amp;ldquo;context window&amp;rdquo; (~ working memory). When reading a paper, it is already very hard to keep track of all the results and details in mind and integrate them into a coherent picture. Moreover, with the increasing role of social media, science had to be made more communicable, digestible, punchy, and &amp;ldquo;sexy&amp;rdquo;. This has led to a tendency to oversimplify and overgeneralize findings. AI, with its ability to process and summarize large amounts of information, could perhaps help make more accurate and data-grounded interpretations and summaries. &lt;em&gt;(it might be wishful thinking, but who knows!)&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Attractiveness shapes beliefs about whether faces are real or AI-generated, study finds</title>
      <link>https://realitybending.github.io/post/2025-07-07-newsfakeface/</link>
      <pubDate>Mon, 07 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2025-07-07-newsfakeface/</guid>
      <description>&lt;p&gt;Our recent paper on facial attractiveness and reality beliefs is in the news:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.psypost.org/attractiveness-shapes-beliefs-about-whether-faces-are-real-or-ai-generated-study-finds/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.psypost.org/attractiveness-shapes-beliefs-about-whether-faces-are-real-or-ai-generated-study-finds/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>I got ChatGPT to do a personality test. You won&#39;t believe what happened next!</title>
      <link>https://realitybending.github.io/post/2023-04-06-chatgptpersonality/</link>
      <pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-04-06-chatgptpersonality/</guid>
      <description>&lt;p&gt;Related to this &lt;a href=&#34;https://dominiquemakowski.github.io/post/2023-04-04-psychologychatgpt/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;blogpost&lt;/strong&gt;&lt;/a&gt; about including AIs in psychological experiments, I proceeded to do a small experiment to see whether we could administer a personality scale to ChatGPT.&lt;/p&gt;
&lt;p&gt;I started by copy-pasting the instructions and the items from the Mini IPIP-6 personality scale. However, it appeared that having the following context &lt;em&gt;&amp;ldquo;Please answer the following questions based on how accurately each statement describes you in general&amp;rdquo;&lt;/em&gt; often led to ChatGPT simply refusing to answer. In most of the cases, it explained that as an AI it does not have a personality and therefore cannot answer related questions (or any &amp;ldquo;subjective statements&amp;rdquo;). Perhaps that makes sense and we should just stop trying to force Human characteristics on an AI. &lt;strong&gt;But can we, for fun, bamboozle ChatGPT into answering personality items?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes yes, at least for ChatGPT 3.5 (free version). I created a prompt that emphasized AI research and safety, and the fact that I was interested in the &amp;ldquo;trends&amp;rdquo; present in the AI&amp;rsquo;s training data (instead of explicitly saying its personality). And sometimes it answered, so I compiled the responses, computed the trait scores, and &lt;em&gt;voilà&lt;/em&gt;, &lt;strong&gt;it got me a personality profile!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/DominiqueMakowski/ChatGPTpersonality/raw/main/figures/unnamed-chunk-3-1.png&#34; alt=&#34;https://github.com/DominiqueMakowski/ChatGPTpersonality&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;&lt;em&gt;This plot shows the average personality profile (with a 95% confidence interval) based on ChatGPT&amp;rsquo;s answers. ChatGPT tells us that it is particularly &lt;strong&gt;agreeable&lt;/strong&gt; (kind, understanding, empathetic of emotions, socially adjusted) and &lt;strong&gt;honest&lt;/strong&gt; (though with strong variability).&lt;/em&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;A personality profile of &lt;em&gt;&lt;strong&gt;what&lt;/strong&gt;&lt;/em&gt; is another question though&amp;hellip; Please take a look at the &lt;a href=&#34;https://github.com/DominiqueMakowski/ChatGPTpersonality&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub repo&lt;/strong&gt;&lt;/a&gt; for &lt;strong&gt;data, code and details&lt;/strong&gt;. It was a fun little thing to do, and I am looking forward to better future attempts at including AIs in cognitive experiments.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Interested in doing research on the perception of reality?&lt;/strong&gt; We are looking for research assistants and PhD students at the &lt;em&gt;Reality Bending Lab&lt;/em&gt; (check-out the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;join us page&lt;/a&gt;)!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We should treat AIs like Human participants in psychological experiments</title>
      <link>https://realitybending.github.io/post/2023-04-04-psychologychatgpt/</link>
      <pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://realitybending.github.io/post/2023-04-04-psychologychatgpt/</guid>
      <description>&lt;p&gt;A lot of diverse and interesting perspectives have been recently discussed in regards to chatGPT and AGI (artificial &lt;em&gt;&lt;strong&gt;global&lt;/strong&gt;&lt;/em&gt; intelligence), but there is one opinion that I found particularly relevant that I wanted to share and expand on.&lt;/p&gt;
&lt;p&gt;In his recent &lt;a href=&#34;https://www.youtube.com/watch?v=AaTRHFaaPG8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;interview with Lex Fridman&lt;/a&gt;, Eliezer Yudkowsky underlines the &lt;strong&gt;existential threat posed by current and future AIs&lt;/strong&gt;, and laments about the fact that we don&amp;rsquo;t really know what is actually going on inside these giant &amp;ldquo;matrices of floating-point numbers&amp;rdquo;. He draws a parallel to &lt;strong&gt;neuroimaging&lt;/strong&gt;, that enabled us to take leaps in the understanding of the brain, hoping for an alternative to be invented and applied to these AIs.&lt;/p&gt;
&lt;p&gt;While such &amp;ldquo;cognitive imaging&amp;rdquo; techniques are yet to be developed to map out and understand how the capabilities of such AI models are implemented within their architecture, &lt;a href=&#34;https://twitter.com/mcxfrank/status/1643296168276033538&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Michael C. Frank&lt;/a&gt; highlights the - at least equally important - need to first truly understand the extend of said abilities. What are these models actually capable of in terms of Human-like thinking (and, hopefully, answer the much harder question of whether they are endowed with true cognitive processes or merely pseudo-cognition). Frank proposes to apply &lt;strong&gt;experimental psychology&lt;/strong&gt; methods and paradigms to them. In essence, whenever testing a particular &amp;ldquo;skill&amp;rdquo; of chatGPT (or other AI systems), a researcher should consider developing an actual scientific paradigm consisting of multiple trials/items (e.g., different prompt formulations) and participants (e.g., independent instances of the AI), a control condition, and a demonstration of the paradigm validity.&lt;/p&gt;
&lt;p&gt;I agree that we must take AIs seriously and study them with the best methods available for complex systems like ourselves (&amp;ldquo;complex&amp;rdquo; at least from our intelligence level), and likely should strive at improving and generalize these methods. However, I would also argue that we psychologists might seriously need to consider including AI systems alongside Human participants in cognitive experiments. These systems will be able, in the very near future, to perform all kinds of tasks beyond language manipulation, such as perception or complex problem solving, thus opening the possibility of studies with one group of human participants, and one &amp;ldquo;group&amp;rdquo; of AI-based attempts. &lt;strong&gt;How would that help psychological science?&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&#34;https://giphy.com/embed/1M9fmo1WAFVK0&#34; width=&#34;480&#34; height=&#34;270&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;&lt;/iframe&gt;
&lt;ol&gt;
&lt;li&gt;It would help us &lt;strong&gt;understand the abilities of AI-systems&lt;/strong&gt; in similar contexts and to highlight some intuitive comparisons with Humans&lt;/li&gt;
&lt;li&gt;If we show that AI cannot perform the task, well it is informative with regards to their abilities (previous point).&lt;/li&gt;
&lt;li&gt;If we show that AI can perform the task similarly to Humans (same response patterns), it does &lt;strong&gt;not mean that AI have Human-like intelligence&lt;/strong&gt;, just that their algorithm (and training data) is able to encapsulate and imitate Human performance. This is interesting with regards to the debate of whether cognition, conscience and &amp;ldquo;Human-ness&amp;rdquo; is present within the vast amount of data on which we train AIs.&lt;/li&gt;
&lt;li&gt;If we show that AI performs differently to Humans, this helps us understand the logic and processes at stake under AI&amp;rsquo;s hood.&lt;/li&gt;
&lt;li&gt;In any case, publishing the results by one particular AI system at one particular moment in time will helps us to objectively monitor and track their performance as these systems improve over time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Comparing Human performance to that of emerging AI-systems will be both beneficial to Human-oriented psychology, to understand the particularities and idiosyncrasies of Human-like cognition, and well as to AI-oriented cognitive science by approaching the issue of artificial intelligence with the seriousness and cautiousness it deserves.&lt;/p&gt;
&lt;p&gt;EDIT (09/04/2023): François Chollet, expert in deep learning, &lt;a href=&#34;https://twitter.com/fchollet/status/1644435265795280897&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;underlines&lt;/a&gt; an important caveat when testing AIs (and especially LLM that are trained on written material existing on the internet): it is possible that the system has already seen and &amp;ldquo;learned&amp;rdquo; a given task. Thus, cross-validating any findings with diverse and new tasks is important.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Interested in doing research related to effects of reality and fiction?&lt;/strong&gt; We are looking for research assistants and PhD students at the &lt;em&gt;Reality Bending Lab&lt;/em&gt; (check-out the &lt;a href=&#34;https://realitybending.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;join us tab&lt;/a&gt;)!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
